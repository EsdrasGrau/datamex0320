<!DOCTYPE html>
<html class="client-nojs" dir="ltr" lang="en">
<head>
<meta charset="utf-8"/>
<title>Expectation–maximization algorithm - Wikipedia</title>
<script>document.documentElement.className="client-js";RLCONF={"wgBreakFrames":!1,"wgSeparatorTransformTable":["",""],"wgDigitTransformTable":["",""],"wgDefaultDateFormat":"dmy","wgMonthNames":["","January","February","March","April","May","June","July","August","September","October","November","December"],"wgRequestId":"XozGfgpAIEIAAEixmNMAAAAL","wgCSPNonce":!1,"wgCanonicalNamespace":"","wgCanonicalSpecialPageName":!1,"wgNamespaceNumber":0,"wgPageName":"Expectation–maximization_algorithm","wgTitle":"Expectation–maximization algorithm","wgCurRevisionId":949604842,"wgRevisionId":949604842,"wgArticleId":470752,"wgIsArticle":!0,"wgIsRedirect":!1,"wgAction":"view","wgUserName":null,"wgUserGroups":["*"],"wgCategories":["CS1 maint: multiple names: authors list","Articles with short description","All articles with unsourced statements","Articles with unsourced statements from November 2017","Articles with unsourced statements from April 2019","CS1 errors: missing periodical",
"Estimation methods","Machine learning algorithms","Missing data","Statistical algorithms","Optimization algorithms and methods","Cluster analysis algorithms"],"wgPageContentLanguage":"en","wgPageContentModel":"wikitext","wgRelevantPageName":"Expectation–maximization_algorithm","wgRelevantArticleId":470752,"wgIsProbablyEditable":!0,"wgRelevantPageIsProbablyEditable":!0,"wgRestrictionEdit":[],"wgRestrictionMove":[],"wgMediaViewerOnClick":!0,"wgMediaViewerEnabledByDefault":!0,"wgPopupsReferencePreviews":!1,"wgPopupsConflictsWithNavPopupGadget":!1,"wgVisualEditor":{"pageLanguageCode":"en","pageLanguageDir":"ltr","pageVariantFallbacks":"en"},"wgMFDisplayWikibaseDescriptions":{"search":!0,"nearby":!0,"watchlist":!0,"tagline":!1},"wgWMESchemaEditAttemptStepOversample":!1,"wgULSCurrentAutonym":"English","wgNoticeProject":"wikipedia","wgWikibaseItemId":"Q1275153","wgCentralAuthMobileDomain":!1,"wgEditSubmitButtonLabelPublish":!0};RLSTATE={
"ext.globalCssJs.user.styles":"ready","site.styles":"ready","noscript":"ready","user.styles":"ready","ext.globalCssJs.user":"ready","user":"ready","user.options":"loading","ext.cite.styles":"ready","ext.math.styles":"ready","mediawiki.toc.styles":"ready","skins.vector.styles.legacy":"ready","wikibase.client.init":"ready","ext.visualEditor.desktopArticleTarget.noscript":"ready","ext.uls.interlanguage":"ready","ext.wikimediaBadges":"ready"};RLPAGEMODULES=["ext.cite.ux-enhancements","ext.math.scripts","site","mediawiki.page.startup","skins.vector.js","mediawiki.page.ready","mediawiki.toc","ext.gadget.ReferenceTooltips","ext.gadget.charinsert","ext.gadget.refToolbar","ext.gadget.extra-toolbar-buttons","ext.gadget.switcher","ext.centralauth.centralautologin","mmv.head","mmv.bootstrap.autostart","ext.popups","ext.visualEditor.desktopArticleTarget.init","ext.visualEditor.targetLoader","ext.eventLogging","ext.wikimediaEvents","ext.navigationTiming","ext.uls.compactlinks","ext.uls.interface",
"ext.cx.eventlogging.campaigns","ext.quicksurveys.init","ext.centralNotice.geoIP","ext.centralNotice.startUp"];</script>
<script>(RLQ=window.RLQ||[]).push(function(){mw.loader.implement("user.options@1hzgi",function($,jQuery,require,module){/*@nomin*/mw.user.tokens.set({"patrolToken":"+\\","watchToken":"+\\","csrfToken":"+\\"});
});});</script>
<link href="/w/load.php?lang=en&amp;modules=ext.cite.styles%7Cext.math.styles%7Cext.uls.interlanguage%7Cext.visualEditor.desktopArticleTarget.noscript%7Cext.wikimediaBadges%7Cmediawiki.toc.styles%7Cskins.vector.styles.legacy%7Cwikibase.client.init&amp;only=styles&amp;skin=vector" rel="stylesheet"/>
<script async="" src="/w/load.php?lang=en&amp;modules=startup&amp;only=scripts&amp;raw=1&amp;skin=vector"></script>
<meta content="" name="ResourceLoaderDynamicStyles"/>
<link href="/w/load.php?lang=en&amp;modules=site.styles&amp;only=styles&amp;skin=vector" rel="stylesheet"/>
<meta content="MediaWiki 1.35.0-wmf.26" name="generator"/>
<meta content="origin" name="referrer"/>
<meta content="origin-when-crossorigin" name="referrer"/>
<meta content="origin-when-cross-origin" name="referrer"/>
<meta content="https://upload.wikimedia.org/wikipedia/commons/6/69/EM_Clustering_of_Old_Faithful_data.gif" property="og:image"/>
<link href="/w/index.php?title=Expectation%E2%80%93maximization_algorithm&amp;action=edit" rel="alternate" title="Edit this page" type="application/x-wiki"/>
<link href="/w/index.php?title=Expectation%E2%80%93maximization_algorithm&amp;action=edit" rel="edit" title="Edit this page"/>
<link href="/static/apple-touch/wikipedia.png" rel="apple-touch-icon"/>
<link href="/static/favicon/wikipedia.ico" rel="shortcut icon"/>
<link href="/w/opensearch_desc.php" rel="search" title="Wikipedia (en)" type="application/opensearchdescription+xml"/>
<link href="//en.wikipedia.org/w/api.php?action=rsd" rel="EditURI" type="application/rsd+xml"/>
<link href="//creativecommons.org/licenses/by-sa/3.0/" rel="license"/>
<link href="/w/index.php?title=Special:RecentChanges&amp;feed=atom" rel="alternate" title="Wikipedia Atom feed" type="application/atom+xml"/>
<link href="https://en.wikipedia.org/wiki/Expectation%E2%80%93maximization_algorithm" rel="canonical"/>
<link href="//login.wikimedia.org" rel="dns-prefetch"/>
<link href="//meta.wikimedia.org" rel="dns-prefetch"/>
<!--[if lt IE 9]><script src="/w/resources/lib/html5shiv/html5shiv.js"></script><![endif]-->
</head>
<body class="mediawiki ltr sitedir-ltr mw-hide-empty-elt ns-0 ns-subject mw-editable page-Expectation–maximization_algorithm rootpage-Expectation–maximization_algorithm skin-vector action-view">
<div class="noprint" id="mw-page-base"></div>
<div class="noprint" id="mw-head-base"></div>
<div class="mw-body" id="content" role="main">
<a id="top"></a>
<div class="mw-body-content" id="siteNotice"><!-- CentralNotice --></div>
<div class="mw-indicators mw-body-content">
</div>
<h1 class="firstHeading" id="firstHeading" lang="en">Expectation–maximization algorithm</h1>
<div class="mw-body-content" id="bodyContent">
<div class="noprint" id="siteSub">From Wikipedia, the free encyclopedia</div>
<div id="contentSub"></div>
<div id="jump-to-nav"></div>
<a class="mw-jump-link" href="#mw-head">Jump to navigation</a>
<a class="mw-jump-link" href="#p-search">Jump to search</a>
<div class="mw-content-ltr" dir="ltr" id="mw-content-text" lang="en"><div class="mw-parser-output"><div class="shortdescription nomobile noexcerpt noprint searchaux" style="display:none">Iterative method for finding maximum likelihood estimates in statistical models</div>
<table class="vertical-navbox nowraplinks" style="float:right;clear:right;width:22.0em;margin:0 0 1.0em 1.0em;background:#f9f9f9;border:1px solid #aaa;padding:0.2em;border-spacing:0.4em 0;text-align:center;line-height:1.4em;font-size:88%"><tbody><tr><th style="padding:0.2em 0.4em 0.2em;font-size:145%;line-height:1.2em"><a href="/wiki/Machine_learning" title="Machine learning">Machine learning</a> and<br/><a href="/wiki/Data_mining" title="Data mining">data mining</a></th></tr><tr><td style="padding:0.2em 0 0.4em;padding:0.25em 0.25em 0.75em;"><a class="image" href="/wiki/File:Kernel_Machine.svg"><img alt="Kernel Machine.svg" data-file-height="233" data-file-width="512" decoding="async" height="100" src="//upload.wikimedia.org/wikipedia/commons/thumb/f/fe/Kernel_Machine.svg/220px-Kernel_Machine.svg.png" srcset="//upload.wikimedia.org/wikipedia/commons/thumb/f/fe/Kernel_Machine.svg/330px-Kernel_Machine.svg.png 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/f/fe/Kernel_Machine.svg/440px-Kernel_Machine.svg.png 2x" width="220"/></a></td></tr><tr><td style="padding:0 0.1em 0.4em">
<div class="NavFrame collapsed" style="border:none;padding:0"><div class="NavHead" style="font-size:105%;background:transparent;text-align:left">Problems</div><div class="NavContent" style="font-size:105%;padding:0.2em 0 0.4em;text-align:center"><div class="hlist">
<ul><li><a href="/wiki/Statistical_classification" title="Statistical classification">Classification</a></li>
<li><a href="/wiki/Cluster_analysis" title="Cluster analysis">Clustering</a></li>
<li><a href="/wiki/Regression_analysis" title="Regression analysis">Regression</a></li>
<li><a href="/wiki/Anomaly_detection" title="Anomaly detection">Anomaly detection</a></li>
<li><a href="/wiki/Automated_machine_learning" title="Automated machine learning">AutoML</a></li>
<li><a href="/wiki/Association_rule_learning" title="Association rule learning">Association rules</a></li>
<li><a href="/wiki/Reinforcement_learning" title="Reinforcement learning">Reinforcement learning</a></li>
<li><a href="/wiki/Structured_prediction" title="Structured prediction">Structured prediction</a></li>
<li><a href="/wiki/Feature_engineering" title="Feature engineering">Feature engineering</a></li>
<li><a href="/wiki/Feature_learning" title="Feature learning">Feature learning</a></li>
<li><a href="/wiki/Online_machine_learning" title="Online machine learning">Online learning</a></li>
<li><a href="/wiki/Semi-supervised_learning" title="Semi-supervised learning">Semi-supervised learning</a></li>
<li><a href="/wiki/Unsupervised_learning" title="Unsupervised learning">Unsupervised learning</a></li>
<li><a href="/wiki/Learning_to_rank" title="Learning to rank">Learning to rank</a></li>
<li><a href="/wiki/Grammar_induction" title="Grammar induction">Grammar induction</a></li></ul>
</div></div></div></td>
</tr><tr><td style="padding:0 0.1em 0.4em">
<div class="NavFrame collapsed" style="border:none;padding:0"><div class="NavHead" style="font-size:105%;background:transparent;text-align:left"><div style="padding:0.1em 0;line-height:1.2em;"><a href="/wiki/Supervised_learning" title="Supervised learning">Supervised learning</a><br/><style data-mw-deduplicate="TemplateStyles:r886047488">.mw-parser-output .nobold{font-weight:normal}</style><span class="nobold"><span style="font-size:85%;">(<b><a href="/wiki/Statistical_classification" title="Statistical classification">classification</a></b> • <b><a href="/wiki/Regression_analysis" title="Regression analysis">regression</a></b>)</span></span> </div></div><div class="NavContent" style="font-size:105%;padding:0.2em 0 0.4em;text-align:center"><div class="hlist">
<ul><li><a href="/wiki/Decision_tree_learning" title="Decision tree learning">Decision trees</a></li>
<li><a href="/wiki/Ensemble_learning" title="Ensemble learning">Ensembles</a>
<ul><li><a href="/wiki/Bootstrap_aggregating" title="Bootstrap aggregating">Bagging</a></li>
<li><a href="/wiki/Boosting_(machine_learning)" title="Boosting (machine learning)">Boosting</a></li>
<li><a href="/wiki/Random_forest" title="Random forest">Random forest</a></li></ul></li>
<li><a href="/wiki/K-nearest_neighbors_algorithm" title="K-nearest neighbors algorithm"><i>k</i>-NN</a></li>
<li><a href="/wiki/Linear_regression" title="Linear regression">Linear regression</a></li>
<li><a href="/wiki/Naive_Bayes_classifier" title="Naive Bayes classifier">Naive Bayes</a></li>
<li><a href="/wiki/Artificial_neural_network" title="Artificial neural network">Artificial neural networks</a></li>
<li><a href="/wiki/Logistic_regression" title="Logistic regression">Logistic regression</a></li>
<li><a href="/wiki/Perceptron" title="Perceptron">Perceptron</a></li>
<li><a href="/wiki/Relevance_vector_machine" title="Relevance vector machine">Relevance vector machine (RVM)</a></li>
<li><a href="/wiki/Support-vector_machine" title="Support-vector machine">Support vector machine (SVM)</a></li></ul>
</div></div></div></td>
</tr><tr><td style="padding:0 0.1em 0.4em">
<div class="NavFrame collapsed" style="border:none;padding:0"><div class="NavHead" style="font-size:105%;background:transparent;text-align:left"><a href="/wiki/Cluster_analysis" title="Cluster analysis">Clustering</a></div><div class="NavContent" style="font-size:105%;padding:0.2em 0 0.4em;text-align:center"><div class="hlist">
<ul><li><a href="/wiki/BIRCH" title="BIRCH">BIRCH</a></li>
<li><a class="mw-redirect" href="/wiki/CURE_data_clustering_algorithm" title="CURE data clustering algorithm">CURE</a></li>
<li><a href="/wiki/Hierarchical_clustering" title="Hierarchical clustering">Hierarchical</a></li>
<li><a href="/wiki/K-means_clustering" title="K-means clustering"><i>k</i>-means</a></li>
<li><a class="mw-selflink selflink">Expectation–maximization (EM)</a></li>
<li><br/><a href="/wiki/DBSCAN" title="DBSCAN">DBSCAN</a></li>
<li><a href="/wiki/OPTICS_algorithm" title="OPTICS algorithm">OPTICS</a></li>
<li><a class="mw-redirect" href="/wiki/Mean-shift" title="Mean-shift">Mean-shift</a></li></ul>
</div></div></div></td>
</tr><tr><td style="padding:0 0.1em 0.4em">
<div class="NavFrame collapsed" style="border:none;padding:0"><div class="NavHead" style="font-size:105%;background:transparent;text-align:left"><a href="/wiki/Dimensionality_reduction" title="Dimensionality reduction">Dimensionality reduction</a></div><div class="NavContent" style="font-size:105%;padding:0.2em 0 0.4em;text-align:center"><div class="hlist">
<ul><li><a href="/wiki/Factor_analysis" title="Factor analysis">Factor analysis</a></li>
<li><a href="/wiki/Canonical_correlation" title="Canonical correlation">CCA</a></li>
<li><a href="/wiki/Independent_component_analysis" title="Independent component analysis">ICA</a></li>
<li><a href="/wiki/Linear_discriminant_analysis" title="Linear discriminant analysis">LDA</a></li>
<li><a href="/wiki/Non-negative_matrix_factorization" title="Non-negative matrix factorization">NMF</a></li>
<li><a href="/wiki/Principal_component_analysis" title="Principal component analysis">PCA</a></li>
<li><a href="/wiki/Proper_generalized_decomposition" title="Proper generalized decomposition">PGD</a></li>
<li><a href="/wiki/T-distributed_stochastic_neighbor_embedding" title="T-distributed stochastic neighbor embedding">t-SNE</a></li></ul>
</div></div></div></td>
</tr><tr><td style="padding:0 0.1em 0.4em">
<div class="NavFrame collapsed" style="border:none;padding:0"><div class="NavHead" style="font-size:105%;background:transparent;text-align:left"><a href="/wiki/Structured_prediction" title="Structured prediction">Structured prediction</a></div><div class="NavContent" style="font-size:105%;padding:0.2em 0 0.4em;text-align:center"><div class="hlist">
<ul><li><a href="/wiki/Graphical_model" title="Graphical model">Graphical models</a>
<ul><li><a href="/wiki/Bayesian_network" title="Bayesian network">Bayes net</a></li>
<li><a href="/wiki/Conditional_random_field" title="Conditional random field">Conditional random field</a></li>
<li><a href="/wiki/Hidden_Markov_model" title="Hidden Markov model">Hidden Markov</a></li></ul></li></ul>
</div></div></div></td>
</tr><tr><td style="padding:0 0.1em 0.4em">
<div class="NavFrame collapsed" style="border:none;padding:0"><div class="NavHead" style="font-size:105%;background:transparent;text-align:left"><a href="/wiki/Anomaly_detection" title="Anomaly detection">Anomaly detection</a></div><div class="NavContent" style="font-size:105%;padding:0.2em 0 0.4em;text-align:center"><div class="hlist">
<ul><li><a class="mw-redirect" href="/wiki/K-nearest_neighbors_classification" title="K-nearest neighbors classification"><i>k</i>-NN</a></li>
<li><a href="/wiki/Local_outlier_factor" title="Local outlier factor">Local outlier factor</a></li></ul>
</div></div></div></td>
</tr><tr><td style="padding:0 0.1em 0.4em">
<div class="NavFrame collapsed" style="border:none;padding:0"><div class="NavHead" style="font-size:105%;background:transparent;text-align:left"><a href="/wiki/Artificial_neural_network" title="Artificial neural network">Artificial neural network</a></div><div class="NavContent" style="font-size:105%;padding:0.2em 0 0.4em;text-align:center"><div class="hlist">
<ul><li><a href="/wiki/Autoencoder" title="Autoencoder">Autoencoder</a></li>
<li><a href="/wiki/Deep_learning" title="Deep learning">Deep learning</a></li>
<li><a href="/wiki/DeepDream" title="DeepDream">DeepDream</a></li>
<li><a href="/wiki/Multilayer_perceptron" title="Multilayer perceptron">Multilayer perceptron</a></li>
<li><a href="/wiki/Recurrent_neural_network" title="Recurrent neural network">RNN</a>
<ul><li><a href="/wiki/Long_short-term_memory" title="Long short-term memory">LSTM</a></li>
<li><a href="/wiki/Gated_recurrent_unit" title="Gated recurrent unit">GRU</a></li></ul></li>
<li><a href="/wiki/Restricted_Boltzmann_machine" title="Restricted Boltzmann machine">Restricted Boltzmann machine</a></li>
<li><a href="/wiki/Generative_adversarial_network" title="Generative adversarial network">GAN</a></li>
<li><a href="/wiki/Self-organizing_map" title="Self-organizing map">SOM</a></li>
<li><a href="/wiki/Convolutional_neural_network" title="Convolutional neural network">Convolutional neural network</a>
<ul><li><a href="/wiki/U-Net" title="U-Net">U-Net</a></li></ul></li></ul>
</div></div></div></td>
</tr><tr><td style="padding:0 0.1em 0.4em">
<div class="NavFrame collapsed" style="border:none;padding:0"><div class="NavHead" style="font-size:105%;background:transparent;text-align:left"><a href="/wiki/Reinforcement_learning" title="Reinforcement learning">Reinforcement learning</a></div><div class="NavContent" style="font-size:105%;padding:0.2em 0 0.4em;text-align:center"><div class="hlist">
<ul><li><a href="/wiki/Q-learning" title="Q-learning">Q-learning</a></li>
<li><a href="/wiki/State%E2%80%93action%E2%80%93reward%E2%80%93state%E2%80%93action" title="State–action–reward–state–action">SARSA</a></li>
<li><a href="/wiki/Temporal_difference_learning" title="Temporal difference learning">Temporal difference (TD)</a></li></ul>
</div></div></div></td>
</tr><tr><td style="padding:0 0.1em 0.4em">
<div class="NavFrame collapsed" style="border:none;padding:0"><div class="NavHead" style="font-size:105%;background:transparent;text-align:left">Theory</div><div class="NavContent" style="font-size:105%;padding:0.2em 0 0.4em;text-align:center"><div class="hlist">
<ul><li><a class="mw-redirect" href="/wiki/Bias%E2%80%93variance_dilemma" title="Bias–variance dilemma">Bias–variance dilemma</a></li>
<li><a href="/wiki/Computational_learning_theory" title="Computational learning theory">Computational learning theory</a></li>
<li><a href="/wiki/Empirical_risk_minimization" title="Empirical risk minimization">Empirical risk minimization</a></li>
<li><a href="/wiki/Occam_learning" title="Occam learning">Occam learning</a></li>
<li><a href="/wiki/Probably_approximately_correct_learning" title="Probably approximately correct learning">PAC learning</a></li>
<li><a href="/wiki/Statistical_learning_theory" title="Statistical learning theory">Statistical learning</a></li>
<li><a href="/wiki/Vapnik%E2%80%93Chervonenkis_theory" title="Vapnik–Chervonenkis theory">VC theory</a></li></ul>
</div></div></div></td>
</tr><tr><td style="padding:0 0.1em 0.4em">
<div class="NavFrame collapsed" style="border:none;padding:0"><div class="NavHead" style="font-size:105%;background:transparent;text-align:left">Machine-learning venues</div><div class="NavContent" style="font-size:105%;padding:0.2em 0 0.4em;text-align:center"><div class="hlist">
<ul><li><a href="/wiki/Conference_on_Neural_Information_Processing_Systems" title="Conference on Neural Information Processing Systems">NeurIPS</a></li>
<li><a href="/wiki/International_Conference_on_Machine_Learning" title="International Conference on Machine Learning">ICML</a></li>
<li><a href="/wiki/Machine_Learning_(journal)" title="Machine Learning (journal)">ML</a></li>
<li><a href="/wiki/Journal_of_Machine_Learning_Research" title="Journal of Machine Learning Research">JMLR</a></li>
<li><a class="external text" href="https://arxiv.org/list/cs.LG/recent" rel="nofollow">ArXiv:cs.LG</a></li></ul>
</div></div></div></td>
</tr><tr><td style="padding:0 0.1em 0.4em">
<div class="NavFrame collapsed" style="border:none;padding:0"><div class="NavHead" style="font-size:105%;background:transparent;text-align:left"><a href="/wiki/Glossary_of_artificial_intelligence" title="Glossary of artificial intelligence">Glossary of artificial intelligence</a></div><div class="NavContent" style="font-size:105%;padding:0.2em 0 0.4em;text-align:center"><div class="hlist">
<ul><li><a href="/wiki/Glossary_of_artificial_intelligence" title="Glossary of artificial intelligence">Glossary of artificial intelligence</a></li></ul>
</div></div></div></td>
</tr><tr><td style="padding:0 0.1em 0.4em">
<div class="NavFrame collapsed" style="border:none;padding:0"><div class="NavHead" style="font-size:105%;background:transparent;text-align:left">Related articles</div><div class="NavContent" style="font-size:105%;padding:0.2em 0 0.4em;text-align:center"><div class="hlist">
<ul><li><a href="/wiki/List_of_datasets_for_machine-learning_research" title="List of datasets for machine-learning research">List of datasets for machine-learning research</a></li>
<li><a href="/wiki/Outline_of_machine_learning" title="Outline of machine learning">Outline of machine learning</a></li></ul>
</div></div></div></td>
</tr><tr><td style="text-align:right;font-size:115%;padding-top: 0.6em;"><div class="plainlinks hlist navbar mini"><ul><li class="nv-view"><a href="/wiki/Template:Machine_learning_bar" title="Template:Machine learning bar"><abbr title="View this template">v</abbr></a></li><li class="nv-talk"><a href="/wiki/Template_talk:Machine_learning_bar" title="Template talk:Machine learning bar"><abbr title="Discuss this template">t</abbr></a></li><li class="nv-edit"><a class="external text" href="https://en.wikipedia.org/w/index.php?title=Template:Machine_learning_bar&amp;action=edit"><abbr title="Edit this template">e</abbr></a></li></ul></div></td></tr></tbody></table>
<p>In <a href="/wiki/Statistics" title="Statistics">statistics</a>, an <b>expectation–maximization</b> (<b>EM</b>) <b>algorithm</b> is an <a href="/wiki/Iterative_method" title="Iterative method">iterative method</a> to find <a class="mw-redirect" href="/wiki/Maximum_likelihood" title="Maximum likelihood">maximum likelihood</a> or <a class="mw-redirect" href="/wiki/Maximum_a_posteriori" title="Maximum a posteriori">maximum a posteriori</a> (MAP) estimates of <a href="/wiki/Parameter" title="Parameter">parameters</a> in <a href="/wiki/Statistical_model" title="Statistical model">statistical models</a>, where the model depends on unobserved <a href="/wiki/Latent_variable" title="Latent variable">latent variables</a>. The EM iteration alternates between performing an expectation (E) step, which creates a function for the expectation of the <a href="/wiki/Likelihood_function#Log-likelihood" title="Likelihood function">log-likelihood</a> evaluated using the current estimate for the parameters, and a maximization (M) step, which computes parameters maximizing the expected log-likelihood found on the <i>E</i> step. These parameter-estimates are then used to determine the distribution of the latent variables in the next E step.
</p>
<div class="thumb tright"><div class="thumbinner" style="width:362px;"><a class="image" href="/wiki/File:EM_Clustering_of_Old_Faithful_data.gif"><img alt="" class="thumbimage" data-file-height="309" data-file-width="360" decoding="async" height="309" src="//upload.wikimedia.org/wikipedia/commons/6/69/EM_Clustering_of_Old_Faithful_data.gif" width="360"/></a> <div class="thumbcaption">EM clustering of <a href="/wiki/Old_Faithful" title="Old Faithful">Old Faithful</a> eruption data. The random initial model (which, due to the different scales of the axes, appears to be two very flat and wide spheres) is fit to the observed data. In the first iterations, the model changes substantially, but then converges to the two modes of the <a href="/wiki/Geyser" title="Geyser">geyser</a>. Visualized using <a href="/wiki/ELKI" title="ELKI">ELKI</a>.</div></div></div>
<div aria-labelledby="mw-toc-heading" class="toc" id="toc" role="navigation"><input class="toctogglecheckbox" id="toctogglecheckbox" role="button" style="display:none" type="checkbox"/><div class="toctitle" dir="ltr" lang="en"><h2 id="mw-toc-heading">Contents</h2><span class="toctogglespan"><label class="toctogglelabel" for="toctogglecheckbox"></label></span></div>
<ul>
<li class="toclevel-1 tocsection-1"><a href="#History"><span class="tocnumber">1</span> <span class="toctext">History</span></a></li>
<li class="toclevel-1 tocsection-2"><a href="#Introduction"><span class="tocnumber">2</span> <span class="toctext">Introduction</span></a></li>
<li class="toclevel-1 tocsection-3"><a href="#Description"><span class="tocnumber">3</span> <span class="toctext">Description</span></a></li>
<li class="toclevel-1 tocsection-4"><a href="#Properties"><span class="tocnumber">4</span> <span class="toctext">Properties</span></a></li>
<li class="toclevel-1 tocsection-5"><a href="#Proof_of_correctness"><span class="tocnumber">5</span> <span class="toctext">Proof of correctness</span></a></li>
<li class="toclevel-1 tocsection-6"><a href="#As_a_maximization–maximization_procedure"><span class="tocnumber">6</span> <span class="toctext">As a maximization–maximization procedure</span></a></li>
<li class="toclevel-1 tocsection-7"><a href="#Applications"><span class="tocnumber">7</span> <span class="toctext">Applications</span></a></li>
<li class="toclevel-1 tocsection-8"><a href="#Filtering_and_smoothing_EM_algorithms"><span class="tocnumber">8</span> <span class="toctext">Filtering and smoothing EM algorithms</span></a></li>
<li class="toclevel-1 tocsection-9"><a href="#Variants"><span class="tocnumber">9</span> <span class="toctext">Variants</span></a>
<ul>
<li class="toclevel-2 tocsection-10"><a href="#α-EM_algorithm"><span class="tocnumber">9.1</span> <span class="toctext">α-EM algorithm</span></a></li>
</ul>
</li>
<li class="toclevel-1 tocsection-11"><a href="#Relation_to_variational_Bayes_methods"><span class="tocnumber">10</span> <span class="toctext">Relation to variational Bayes methods</span></a></li>
<li class="toclevel-1 tocsection-12"><a href="#Geometric_interpretation"><span class="tocnumber">11</span> <span class="toctext">Geometric interpretation</span></a></li>
<li class="toclevel-1 tocsection-13"><a href="#Examples"><span class="tocnumber">12</span> <span class="toctext">Examples</span></a>
<ul>
<li class="toclevel-2 tocsection-14"><a href="#Gaussian_mixture"><span class="tocnumber">12.1</span> <span class="toctext">Gaussian mixture</span></a>
<ul>
<li class="toclevel-3 tocsection-15"><a href="#E_step"><span class="tocnumber">12.1.1</span> <span class="toctext">E step</span></a></li>
<li class="toclevel-3 tocsection-16"><a href="#M_step"><span class="tocnumber">12.1.2</span> <span class="toctext">M step</span></a></li>
<li class="toclevel-3 tocsection-17"><a href="#Termination"><span class="tocnumber">12.1.3</span> <span class="toctext">Termination</span></a></li>
<li class="toclevel-3 tocsection-18"><a href="#Generalization"><span class="tocnumber">12.1.4</span> <span class="toctext">Generalization</span></a></li>
</ul>
</li>
<li class="toclevel-2 tocsection-19"><a href="#Truncated_and_censored_regression"><span class="tocnumber">12.2</span> <span class="toctext">Truncated and censored regression</span></a></li>
</ul>
</li>
<li class="toclevel-1 tocsection-20"><a href="#Alternatives"><span class="tocnumber">13</span> <span class="toctext">Alternatives</span></a></li>
<li class="toclevel-1 tocsection-21"><a href="#See_also"><span class="tocnumber">14</span> <span class="toctext">See also</span></a></li>
<li class="toclevel-1 tocsection-22"><a href="#References"><span class="tocnumber">15</span> <span class="toctext">References</span></a></li>
<li class="toclevel-1 tocsection-23"><a href="#Further_reading"><span class="tocnumber">16</span> <span class="toctext">Further reading</span></a></li>
<li class="toclevel-1 tocsection-24"><a href="#External_links"><span class="tocnumber">17</span> <span class="toctext">External links</span></a></li>
</ul>
</div>
<h2><span class="mw-headline" id="History">History</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Expectation%E2%80%93maximization_algorithm&amp;action=edit&amp;section=1" title="Edit section: History">edit</a><span class="mw-editsection-bracket">]</span></span></h2>
<p>The EM algorithm was explained and given its name in a classic 1977 paper by <a href="/wiki/Arthur_P._Dempster" title="Arthur P. Dempster">Arthur Dempster</a>, <a href="/wiki/Nan_Laird" title="Nan Laird">Nan Laird</a>, and <a href="/wiki/Donald_Rubin" title="Donald Rubin">Donald Rubin</a>.<sup class="reference" id="cite_ref-Dempster1977_1-0"><a href="#cite_note-Dempster1977-1">[1]</a></sup> They pointed out that the method had been "proposed many times in special circumstances" by earlier authors. One of the earliest is the gene-counting method for estimating allele frequencies by Cedric Smith.<sup class="reference" id="cite_ref-2"><a href="#cite_note-2">[2]</a></sup>  A very detailed treatment of the EM method for exponential families was published by Rolf Sundberg in his thesis and several papers<sup class="reference" id="cite_ref-Sundberg1974_3-0"><a href="#cite_note-Sundberg1974-3">[3]</a></sup><sup class="reference" id="cite_ref-Sundberg1971_4-0"><a href="#cite_note-Sundberg1971-4">[4]</a></sup><sup class="reference" id="cite_ref-Sundberg1976_5-0"><a href="#cite_note-Sundberg1976-5">[5]</a></sup> following his collaboration with <a href="/wiki/Per_Martin-L%C3%B6f" title="Per Martin-Löf">Per Martin-Löf</a> and <a href="/wiki/Anders_Martin-L%C3%B6f" title="Anders Martin-Löf">Anders Martin-Löf</a>.<sup class="reference" id="cite_ref-6"><a href="#cite_note-6">[6]</a></sup><sup class="reference" id="cite_ref-7"><a href="#cite_note-7">[7]</a></sup><sup class="reference" id="cite_ref-Martin-Löf1963_8-0"><a href="#cite_note-Martin-Löf1963-8">[8]</a></sup><sup class="reference" id="cite_ref-Martin-Löf1966_9-0"><a href="#cite_note-Martin-Löf1966-9">[9]</a></sup><sup class="reference" id="cite_ref-Martin-Löf1970_10-0"><a href="#cite_note-Martin-Löf1970-10">[10]</a></sup><sup class="reference" id="cite_ref-Martin-Löf1974a_11-0"><a href="#cite_note-Martin-Löf1974a-11">[11]</a></sup><sup class="reference" id="cite_ref-Martin-Löf1974b_12-0"><a href="#cite_note-Martin-Löf1974b-12">[12]</a></sup> The Dempster–Laird–Rubin paper in 1977 generalized the method and sketched a convergence analysis for a wider class of problems. Regardless of earlier inventions, the innovative Dempster–Laird–Rubin paper in the <i>Journal of the Royal Statistical Society</i> received an enthusiastic discussion at the Royal Statistical Society meeting with Sundberg calling the paper "brilliant". The Dempster–Laird–Rubin paper established the EM method as an important tool of statistical analysis.
</p><p>The convergence analysis of the Dempster–Laird–Rubin algorithm was flawed and a correct convergence analysis was published by <a href="/wiki/C._F._Jeff_Wu" title="C. F. Jeff Wu">C. F. Jeff Wu</a> in 1983.<sup class="reference" id="cite_ref-Wu_13-0"><a href="#cite_note-Wu-13">[13]</a></sup>
Wu's proof established the EM method's convergence outside of the <a href="/wiki/Exponential_family" title="Exponential family">exponential family</a>, as claimed by Dempster–Laird–Rubin.<sup class="reference" id="cite_ref-Wu_13-1"><a href="#cite_note-Wu-13">[13]</a></sup>
</p>
<h2><span class="mw-headline" id="Introduction">Introduction</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Expectation%E2%80%93maximization_algorithm&amp;action=edit&amp;section=2" title="Edit section: Introduction">edit</a><span class="mw-editsection-bracket">]</span></span></h2>
<p>The EM algorithm is used to find (local) <a class="mw-redirect" href="/wiki/Maximum_likelihood" title="Maximum likelihood">maximum likelihood</a> parameters of a <a href="/wiki/Statistical_model" title="Statistical model">statistical model</a> in cases where the equations cannot be solved directly.  Typically these models involve <a href="/wiki/Latent_variable" title="Latent variable">latent variables</a> in addition to unknown <a class="mw-redirect" href="/wiki/Parameters" title="Parameters">parameters</a> and known data observations.  That is, either <a class="mw-redirect" href="/wiki/Missing_values" title="Missing values">missing values</a> exist among the data, or the model can be formulated more simply by assuming the existence of further unobserved data points. For example, a <a href="/wiki/Mixture_model" title="Mixture model">mixture model</a> can be described more simply by assuming that each observed data point has a corresponding unobserved data point, or latent variable, specifying the mixture component to which each data point belongs.
</p><p>Finding a maximum likelihood solution typically requires taking the <a href="/wiki/Derivative" title="Derivative">derivatives</a> of the <a href="/wiki/Likelihood_function" title="Likelihood function">likelihood function</a> with respect to all the unknown values, the parameters and the latent variables, and simultaneously solving the resulting equations. In statistical models with latent variables, this is usually impossible. Instead, the result is typically a set of interlocking equations in which the solution to the parameters requires the values of the latent variables and vice versa, but substituting one set of equations into the other produces an unsolvable equation.
</p><p>The EM algorithm proceeds from the observation that there is a way to solve these two sets of equations numerically. One can simply pick arbitrary values for one of the two sets of unknowns, use them to estimate the second set, then use these new values to find a better estimate of the first set, and then keep alternating between the two until the resulting values both converge to fixed points.  It's not obvious that this will work, but it can be proven that in this context it does, and that the derivative of the likelihood is (arbitrarily close to) zero at that point, which in turn means that the point is either a maximum or a <a href="/wiki/Saddle_point" title="Saddle point">saddle point</a>.<sup class="reference" id="cite_ref-Wu_13-2"><a href="#cite_note-Wu-13">[13]</a></sup> In general, multiple maxima may occur, with no guarantee that the global maximum will be found.  Some likelihoods also have <a class="mw-redirect" href="/wiki/Mathematical_singularity" title="Mathematical singularity">singularities</a> in them, i.e., nonsensical maxima.  For example, one of the <i>solutions</i> that may be found by EM in a mixture model involves setting one of the components to have zero variance and the mean parameter for the same component to be equal to one of the data points.
</p>
<h2><span class="mw-headline" id="Description">Description</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Expectation%E2%80%93maximization_algorithm&amp;action=edit&amp;section=3" title="Edit section: Description">edit</a><span class="mw-editsection-bracket">]</span></span></h2>
<p>Given the <a href="/wiki/Statistical_model" title="Statistical model">statistical model</a> which generates a set <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\displaystyle \mathbf {X} }" xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="true" scriptlevel="0">
<mrow class="MJX-TeXAtom-ORD">
<mi mathvariant="bold">X</mi>
</mrow>
</mstyle>
</mrow>
<annotation encoding="application/x-tex">{\displaystyle \mathbf {X} }</annotation>
</semantics>
</math></span><img alt="\mathbf {X} " aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/9f75966a2f9d5672136fa9401ee1e75008f95ffd" style="vertical-align: -0.338ex; width:2.019ex; height:2.176ex;"/></span> of observed data, a set of unobserved latent data or <a class="mw-redirect" href="/wiki/Missing_values" title="Missing values">missing values</a> <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\displaystyle \mathbf {Z} }" xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="true" scriptlevel="0">
<mrow class="MJX-TeXAtom-ORD">
<mi mathvariant="bold">Z</mi>
</mrow>
</mstyle>
</mrow>
<annotation encoding="application/x-tex">{\displaystyle \mathbf {Z} }</annotation>
</semantics>
</math></span><img alt="\mathbf {Z} " aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/b776aaf12c2da4b78ca777cb8295c2000bfd51f5" style="vertical-align: -0.338ex; width:1.634ex; height:2.176ex;"/></span>, and a vector of unknown parameters <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\displaystyle {\boldsymbol {\theta }}}" xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="true" scriptlevel="0">
<mrow class="MJX-TeXAtom-ORD">
<mi mathvariant="bold-italic">θ<!-- θ --></mi>
</mrow>
</mstyle>
</mrow>
<annotation encoding="application/x-tex">{\displaystyle {\boldsymbol {\theta }}}</annotation>
</semantics>
</math></span><img alt="{\boldsymbol {\theta }}" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/33b025a6bf54ec02e65c871dc3e5897c921419cf" style="vertical-align: -0.338ex; width:1.306ex; height:2.176ex;"/></span>, along with a <a href="/wiki/Likelihood_function" title="Likelihood function">likelihood function</a> <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\displaystyle L({\boldsymbol {\theta }};\mathbf {X} ,\mathbf {Z} )=p(\mathbf {X} ,\mathbf {Z} \mid {\boldsymbol {\theta }})}" xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="true" scriptlevel="0">
<mi>L</mi>
<mo stretchy="false">(</mo>
<mrow class="MJX-TeXAtom-ORD">
<mi mathvariant="bold-italic">θ<!-- θ --></mi>
</mrow>
<mo>;</mo>
<mrow class="MJX-TeXAtom-ORD">
<mi mathvariant="bold">X</mi>
</mrow>
<mo>,</mo>
<mrow class="MJX-TeXAtom-ORD">
<mi mathvariant="bold">Z</mi>
</mrow>
<mo stretchy="false">)</mo>
<mo>=</mo>
<mi>p</mi>
<mo stretchy="false">(</mo>
<mrow class="MJX-TeXAtom-ORD">
<mi mathvariant="bold">X</mi>
</mrow>
<mo>,</mo>
<mrow class="MJX-TeXAtom-ORD">
<mi mathvariant="bold">Z</mi>
</mrow>
<mo>∣<!-- ∣ --></mo>
<mrow class="MJX-TeXAtom-ORD">
<mi mathvariant="bold-italic">θ<!-- θ --></mi>
</mrow>
<mo stretchy="false">)</mo>
</mstyle>
</mrow>
<annotation encoding="application/x-tex">{\displaystyle L({\boldsymbol {\theta }};\mathbf {X} ,\mathbf {Z} )=p(\mathbf {X} ,\mathbf {Z} \mid {\boldsymbol {\theta }})}</annotation>
</semantics>
</math></span><img alt="{\displaystyle L({\boldsymbol {\theta }};\mathbf {X} ,\mathbf {Z} )=p(\mathbf {X} ,\mathbf {Z} \mid {\boldsymbol {\theta }})}" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/d4a774eb5746942b5a8bb44632c83f9a50bf39ef" style="vertical-align: -0.838ex; width:24.428ex; height:2.843ex;"/></span>, the <a class="mw-redirect" href="/wiki/Maximum_likelihood_estimate" title="Maximum likelihood estimate">maximum likelihood estimate</a> (MLE) of the unknown parameters is determined by maximizing the <a href="/wiki/Marginal_likelihood" title="Marginal likelihood">marginal likelihood</a> of the observed data
</p>
<dl><dd><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\displaystyle L({\boldsymbol {\theta }};\mathbf {X} )=p(\mathbf {X} \mid {\boldsymbol {\theta }})=\int p(\mathbf {X} ,\mathbf {Z} \mid {\boldsymbol {\theta }})\,d\mathbf {Z} }" xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="true" scriptlevel="0">
<mi>L</mi>
<mo stretchy="false">(</mo>
<mrow class="MJX-TeXAtom-ORD">
<mi mathvariant="bold-italic">θ<!-- θ --></mi>
</mrow>
<mo>;</mo>
<mrow class="MJX-TeXAtom-ORD">
<mi mathvariant="bold">X</mi>
</mrow>
<mo stretchy="false">)</mo>
<mo>=</mo>
<mi>p</mi>
<mo stretchy="false">(</mo>
<mrow class="MJX-TeXAtom-ORD">
<mi mathvariant="bold">X</mi>
</mrow>
<mo>∣<!-- ∣ --></mo>
<mrow class="MJX-TeXAtom-ORD">
<mi mathvariant="bold-italic">θ<!-- θ --></mi>
</mrow>
<mo stretchy="false">)</mo>
<mo>=</mo>
<mo>∫<!-- ∫ --></mo>
<mi>p</mi>
<mo stretchy="false">(</mo>
<mrow class="MJX-TeXAtom-ORD">
<mi mathvariant="bold">X</mi>
</mrow>
<mo>,</mo>
<mrow class="MJX-TeXAtom-ORD">
<mi mathvariant="bold">Z</mi>
</mrow>
<mo>∣<!-- ∣ --></mo>
<mrow class="MJX-TeXAtom-ORD">
<mi mathvariant="bold-italic">θ<!-- θ --></mi>
</mrow>
<mo stretchy="false">)</mo>
<mspace width="thinmathspace"></mspace>
<mi>d</mi>
<mrow class="MJX-TeXAtom-ORD">
<mi mathvariant="bold">Z</mi>
</mrow>
</mstyle>
</mrow>
<annotation encoding="application/x-tex">{\displaystyle L({\boldsymbol {\theta }};\mathbf {X} )=p(\mathbf {X} \mid {\boldsymbol {\theta }})=\int p(\mathbf {X} ,\mathbf {Z} \mid {\boldsymbol {\theta }})\,d\mathbf {Z} }</annotation>
</semantics>
</math></span><img alt="{\displaystyle L({\boldsymbol {\theta }};\mathbf {X} )=p(\mathbf {X} \mid {\boldsymbol {\theta }})=\int p(\mathbf {X} ,\mathbf {Z} \mid {\boldsymbol {\theta }})\,d\mathbf {Z} }" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/717cf5ca655793a8498f3a2b443eb8b90bf3a0e7" style="vertical-align: -2.338ex; width:38.918ex; height:5.676ex;"/></span></dd></dl>
<p>However, this quantity is often intractable (e.g. if <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\displaystyle \mathbf {Z} }" xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="true" scriptlevel="0">
<mrow class="MJX-TeXAtom-ORD">
<mi mathvariant="bold">Z</mi>
</mrow>
</mstyle>
</mrow>
<annotation encoding="application/x-tex">{\displaystyle \mathbf {Z} }</annotation>
</semantics>
</math></span><img alt="\mathbf {Z} " aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/b776aaf12c2da4b78ca777cb8295c2000bfd51f5" style="vertical-align: -0.338ex; width:1.634ex; height:2.176ex;"/></span> is a sequence of events, so that the number of values grows exponentially with the sequence length, the exact calculation of the sum will be extremely difficult).
</p><p>The EM algorithm seeks to find the MLE of the marginal likelihood by iteratively applying these two steps:
</p>
<dl><dd><i>Expectation step (E step)</i>: Define <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\displaystyle Q({\boldsymbol {\theta }}\mid {\boldsymbol {\theta }}^{(t)})}" xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="true" scriptlevel="0">
<mi>Q</mi>
<mo stretchy="false">(</mo>
<mrow class="MJX-TeXAtom-ORD">
<mi mathvariant="bold-italic">θ<!-- θ --></mi>
</mrow>
<mo>∣<!-- ∣ --></mo>
<msup>
<mrow class="MJX-TeXAtom-ORD">
<mi mathvariant="bold-italic">θ<!-- θ --></mi>
</mrow>
<mrow class="MJX-TeXAtom-ORD">
<mo stretchy="false">(</mo>
<mi>t</mi>
<mo stretchy="false">)</mo>
</mrow>
</msup>
<mo stretchy="false">)</mo>
</mstyle>
</mrow>
<annotation encoding="application/x-tex">{\displaystyle Q({\boldsymbol {\theta }}\mid {\boldsymbol {\theta }}^{(t)})}</annotation>
</semantics>
</math></span><img alt="{\displaystyle Q({\boldsymbol {\theta }}\mid {\boldsymbol {\theta }}^{(t)})}" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/24d245ae1f551d986964bdcfa59ef4bad70079cb" style="vertical-align: -0.838ex; width:10.303ex; height:3.343ex;"/></span> as the <a href="/wiki/Expected_value" title="Expected value">expected value</a> of the log <a href="/wiki/Likelihood_function" title="Likelihood function">likelihood function</a> of <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\displaystyle {\boldsymbol {\theta }}}" xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="true" scriptlevel="0">
<mrow class="MJX-TeXAtom-ORD">
<mi mathvariant="bold-italic">θ<!-- θ --></mi>
</mrow>
</mstyle>
</mrow>
<annotation encoding="application/x-tex">{\displaystyle {\boldsymbol {\theta }}}</annotation>
</semantics>
</math></span><img alt="{\boldsymbol {\theta }}" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/33b025a6bf54ec02e65c871dc3e5897c921419cf" style="vertical-align: -0.338ex; width:1.306ex; height:2.176ex;"/></span>, with respect to the current <a href="/wiki/Conditional_probability_distribution" title="Conditional probability distribution">conditional distribution</a> of <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\displaystyle \mathbf {Z} }" xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="true" scriptlevel="0">
<mrow class="MJX-TeXAtom-ORD">
<mi mathvariant="bold">Z</mi>
</mrow>
</mstyle>
</mrow>
<annotation encoding="application/x-tex">{\displaystyle \mathbf {Z} }</annotation>
</semantics>
</math></span><img alt="\mathbf {Z} " aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/b776aaf12c2da4b78ca777cb8295c2000bfd51f5" style="vertical-align: -0.338ex; width:1.634ex; height:2.176ex;"/></span> given <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\displaystyle \mathbf {X} }" xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="true" scriptlevel="0">
<mrow class="MJX-TeXAtom-ORD">
<mi mathvariant="bold">X</mi>
</mrow>
</mstyle>
</mrow>
<annotation encoding="application/x-tex">{\displaystyle \mathbf {X} }</annotation>
</semantics>
</math></span><img alt="\mathbf {X} " aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/9f75966a2f9d5672136fa9401ee1e75008f95ffd" style="vertical-align: -0.338ex; width:2.019ex; height:2.176ex;"/></span> and the current estimates of the parameters <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\displaystyle {\boldsymbol {\theta }}^{(t)}}" xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="true" scriptlevel="0">
<msup>
<mrow class="MJX-TeXAtom-ORD">
<mi mathvariant="bold-italic">θ<!-- θ --></mi>
</mrow>
<mrow class="MJX-TeXAtom-ORD">
<mo stretchy="false">(</mo>
<mi>t</mi>
<mo stretchy="false">)</mo>
</mrow>
</msup>
</mstyle>
</mrow>
<annotation encoding="application/x-tex">{\displaystyle {\boldsymbol {\theta }}^{(t)}}</annotation>
</semantics>
</math></span><img alt="\boldsymbol\theta^{(t)}" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/4a1c52b206c71daeb0a1208f1f11182d5a90eb9b" style="vertical-align: -0.338ex; width:3.412ex; height:2.843ex;"/></span>:
<dl><dd><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\displaystyle Q({\boldsymbol {\theta }}\mid {\boldsymbol {\theta }}^{(t)})=\operatorname {E} _{\mathbf {Z} \mid \mathbf {X} ,{\boldsymbol {\theta }}^{(t)}}\left[\log L({\boldsymbol {\theta }};\mathbf {X} ,\mathbf {Z} )\right]\,}" xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="true" scriptlevel="0">
<mi>Q</mi>
<mo stretchy="false">(</mo>
<mrow class="MJX-TeXAtom-ORD">
<mi mathvariant="bold-italic">θ<!-- θ --></mi>
</mrow>
<mo>∣<!-- ∣ --></mo>
<msup>
<mrow class="MJX-TeXAtom-ORD">
<mi mathvariant="bold-italic">θ<!-- θ --></mi>
</mrow>
<mrow class="MJX-TeXAtom-ORD">
<mo stretchy="false">(</mo>
<mi>t</mi>
<mo stretchy="false">)</mo>
</mrow>
</msup>
<mo stretchy="false">)</mo>
<mo>=</mo>
<msub>
<mi mathvariant="normal">E</mi>
<mrow class="MJX-TeXAtom-ORD">
<mrow class="MJX-TeXAtom-ORD">
<mi mathvariant="bold">Z</mi>
</mrow>
<mo>∣<!-- ∣ --></mo>
<mrow class="MJX-TeXAtom-ORD">
<mi mathvariant="bold">X</mi>
</mrow>
<mo>,</mo>
<msup>
<mrow class="MJX-TeXAtom-ORD">
<mi mathvariant="bold-italic">θ<!-- θ --></mi>
</mrow>
<mrow class="MJX-TeXAtom-ORD">
<mo stretchy="false">(</mo>
<mi>t</mi>
<mo stretchy="false">)</mo>
</mrow>
</msup>
</mrow>
</msub>
<mo>⁡<!-- ⁡ --></mo>
<mrow>
<mo>[</mo>
<mrow>
<mi>log</mi>
<mo>⁡<!-- ⁡ --></mo>
<mi>L</mi>
<mo stretchy="false">(</mo>
<mrow class="MJX-TeXAtom-ORD">
<mi mathvariant="bold-italic">θ<!-- θ --></mi>
</mrow>
<mo>;</mo>
<mrow class="MJX-TeXAtom-ORD">
<mi mathvariant="bold">X</mi>
</mrow>
<mo>,</mo>
<mrow class="MJX-TeXAtom-ORD">
<mi mathvariant="bold">Z</mi>
</mrow>
<mo stretchy="false">)</mo>
</mrow>
<mo>]</mo>
</mrow>
<mspace width="thinmathspace"></mspace>
</mstyle>
</mrow>
<annotation encoding="application/x-tex">{\displaystyle Q({\boldsymbol {\theta }}\mid {\boldsymbol {\theta }}^{(t)})=\operatorname {E} _{\mathbf {Z} \mid \mathbf {X} ,{\boldsymbol {\theta }}^{(t)}}\left[\log L({\boldsymbol {\theta }};\mathbf {X} ,\mathbf {Z} )\right]\,}</annotation>
</semantics>
</math></span><img alt="{\displaystyle Q({\boldsymbol {\theta }}\mid {\boldsymbol {\theta }}^{(t)})=\operatorname {E} _{\mathbf {Z} \mid \mathbf {X} ,{\boldsymbol {\theta }}^{(t)}}\left[\log L({\boldsymbol {\theta }};\mathbf {X} ,\mathbf {Z} )\right]\,}" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/273a8ef209e0f8cb8b30b120a89218a8f748b9dd" style="vertical-align: -1.505ex; width:36.783ex; height:4.009ex;"/></span></dd></dl></dd></dl>
<dl><dd><i>Maximization step (M step)</i>: Find the parameters that maximize this quantity:
<dl><dd><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\displaystyle {\boldsymbol {\theta }}^{(t+1)}={\underset {\boldsymbol {\theta }}{\operatorname {arg\,max} }}\ Q({\boldsymbol {\theta }}\mid {\boldsymbol {\theta }}^{(t)})\,}" xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="true" scriptlevel="0">
<msup>
<mrow class="MJX-TeXAtom-ORD">
<mi mathvariant="bold-italic">θ<!-- θ --></mi>
</mrow>
<mrow class="MJX-TeXAtom-ORD">
<mo stretchy="false">(</mo>
<mi>t</mi>
<mo>+</mo>
<mn>1</mn>
<mo stretchy="false">)</mo>
</mrow>
</msup>
<mo>=</mo>
<mrow class="MJX-TeXAtom-ORD">
<munder>
<mrow class="MJX-TeXAtom-OP MJX-fixedlimits">
<mi mathvariant="normal">a</mi>
<mi mathvariant="normal">r</mi>
<mi mathvariant="normal">g</mi>
<mspace width="thinmathspace"></mspace>
<mi mathvariant="normal">m</mi>
<mi mathvariant="normal">a</mi>
<mi mathvariant="normal">x</mi>
</mrow>
<mi mathvariant="bold-italic">θ<!-- θ --></mi>
</munder>
</mrow>
<mtext> </mtext>
<mi>Q</mi>
<mo stretchy="false">(</mo>
<mrow class="MJX-TeXAtom-ORD">
<mi mathvariant="bold-italic">θ<!-- θ --></mi>
</mrow>
<mo>∣<!-- ∣ --></mo>
<msup>
<mrow class="MJX-TeXAtom-ORD">
<mi mathvariant="bold-italic">θ<!-- θ --></mi>
</mrow>
<mrow class="MJX-TeXAtom-ORD">
<mo stretchy="false">(</mo>
<mi>t</mi>
<mo stretchy="false">)</mo>
</mrow>
</msup>
<mo stretchy="false">)</mo>
<mspace width="thinmathspace"></mspace>
</mstyle>
</mrow>
<annotation encoding="application/x-tex">{\displaystyle {\boldsymbol {\theta }}^{(t+1)}={\underset {\boldsymbol {\theta }}{\operatorname {arg\,max} }}\ Q({\boldsymbol {\theta }}\mid {\boldsymbol {\theta }}^{(t)})\,}</annotation>
</semantics>
</math></span><img alt="{\displaystyle {\boldsymbol {\theta }}^{(t+1)}={\underset {\boldsymbol {\theta }}{\operatorname {arg\,max} }}\ Q({\boldsymbol {\theta }}\mid {\boldsymbol {\theta }}^{(t)})\,}" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/ec0b048c1c3ec3993dda22954d5024c87c268c7d" style="vertical-align: -2.505ex; width:27.831ex; height:5.009ex;"/></span></dd></dl></dd></dl>
<p>The typical models to which EM is applied use <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\displaystyle \mathbf {Z} }" xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="true" scriptlevel="0">
<mrow class="MJX-TeXAtom-ORD">
<mi mathvariant="bold">Z</mi>
</mrow>
</mstyle>
</mrow>
<annotation encoding="application/x-tex">{\displaystyle \mathbf {Z} }</annotation>
</semantics>
</math></span><img alt="\mathbf {Z} " aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/b776aaf12c2da4b78ca777cb8295c2000bfd51f5" style="vertical-align: -0.338ex; width:1.634ex; height:2.176ex;"/></span> as a latent variable indicating membership in one of a set of groups:
</p>
<ol><li>The observed data points <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\displaystyle \mathbf {X} }" xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="true" scriptlevel="0">
<mrow class="MJX-TeXAtom-ORD">
<mi mathvariant="bold">X</mi>
</mrow>
</mstyle>
</mrow>
<annotation encoding="application/x-tex">{\displaystyle \mathbf {X} }</annotation>
</semantics>
</math></span><img alt="\mathbf {X} " aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/9f75966a2f9d5672136fa9401ee1e75008f95ffd" style="vertical-align: -0.338ex; width:2.019ex; height:2.176ex;"/></span> may be <a class="mw-redirect" href="/wiki/Discrete_random_variable" title="Discrete random variable">discrete</a> (taking values in a finite or countably infinite set) or <a class="mw-redirect" href="/wiki/Continuous_random_variable" title="Continuous random variable">continuous</a> (taking values in an uncountably infinite set). Associated with each data point may be a vector of observations.</li>
<li>The <a class="mw-redirect" href="/wiki/Missing_values" title="Missing values">missing values</a> (aka <a class="mw-redirect" href="/wiki/Latent_variables" title="Latent variables">latent variables</a>) <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\displaystyle \mathbf {Z} }" xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="true" scriptlevel="0">
<mrow class="MJX-TeXAtom-ORD">
<mi mathvariant="bold">Z</mi>
</mrow>
</mstyle>
</mrow>
<annotation encoding="application/x-tex">{\displaystyle \mathbf {Z} }</annotation>
</semantics>
</math></span><img alt="\mathbf {Z} " aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/b776aaf12c2da4b78ca777cb8295c2000bfd51f5" style="vertical-align: -0.338ex; width:1.634ex; height:2.176ex;"/></span> are <a class="mw-redirect" href="/wiki/Discrete_random_variable" title="Discrete random variable">discrete</a>, drawn from a fixed number of values, and with one latent variable per observed unit.</li>
<li>The parameters are continuous, and are of two kinds: Parameters that are associated with all data points, and those associated with a specific value of a latent variable (i.e., associated with all data points which corresponding latent variable has that value).</li></ol>
<p>However, it is possible to apply EM to other sorts of models.
</p><p>The motive is as follows.  If the value of the parameters <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\displaystyle {\boldsymbol {\theta }}}" xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="true" scriptlevel="0">
<mrow class="MJX-TeXAtom-ORD">
<mi mathvariant="bold-italic">θ<!-- θ --></mi>
</mrow>
</mstyle>
</mrow>
<annotation encoding="application/x-tex">{\displaystyle {\boldsymbol {\theta }}}</annotation>
</semantics>
</math></span><img alt="{\boldsymbol {\theta }}" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/33b025a6bf54ec02e65c871dc3e5897c921419cf" style="vertical-align: -0.338ex; width:1.306ex; height:2.176ex;"/></span> is known, usually the value of the latent variables <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\displaystyle \mathbf {Z} }" xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="true" scriptlevel="0">
<mrow class="MJX-TeXAtom-ORD">
<mi mathvariant="bold">Z</mi>
</mrow>
</mstyle>
</mrow>
<annotation encoding="application/x-tex">{\displaystyle \mathbf {Z} }</annotation>
</semantics>
</math></span><img alt="\mathbf {Z} " aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/b776aaf12c2da4b78ca777cb8295c2000bfd51f5" style="vertical-align: -0.338ex; width:1.634ex; height:2.176ex;"/></span> can be found by maximizing the log-likelihood over all possible values of <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\displaystyle \mathbf {Z} }" xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="true" scriptlevel="0">
<mrow class="MJX-TeXAtom-ORD">
<mi mathvariant="bold">Z</mi>
</mrow>
</mstyle>
</mrow>
<annotation encoding="application/x-tex">{\displaystyle \mathbf {Z} }</annotation>
</semantics>
</math></span><img alt="\mathbf {Z} " aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/b776aaf12c2da4b78ca777cb8295c2000bfd51f5" style="vertical-align: -0.338ex; width:1.634ex; height:2.176ex;"/></span>, either simply by iterating over <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\displaystyle \mathbf {Z} }" xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="true" scriptlevel="0">
<mrow class="MJX-TeXAtom-ORD">
<mi mathvariant="bold">Z</mi>
</mrow>
</mstyle>
</mrow>
<annotation encoding="application/x-tex">{\displaystyle \mathbf {Z} }</annotation>
</semantics>
</math></span><img alt="\mathbf {Z} " aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/b776aaf12c2da4b78ca777cb8295c2000bfd51f5" style="vertical-align: -0.338ex; width:1.634ex; height:2.176ex;"/></span> or through an algorithm such as the <a href="/wiki/Baum%E2%80%93Welch_algorithm" title="Baum–Welch algorithm">Baum–Welch algorithm</a> for <a href="/wiki/Hidden_Markov_model" title="Hidden Markov model">hidden Markov models</a>.  Conversely, if we know the value of the latent variables <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\displaystyle \mathbf {Z} }" xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="true" scriptlevel="0">
<mrow class="MJX-TeXAtom-ORD">
<mi mathvariant="bold">Z</mi>
</mrow>
</mstyle>
</mrow>
<annotation encoding="application/x-tex">{\displaystyle \mathbf {Z} }</annotation>
</semantics>
</math></span><img alt="\mathbf {Z} " aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/b776aaf12c2da4b78ca777cb8295c2000bfd51f5" style="vertical-align: -0.338ex; width:1.634ex; height:2.176ex;"/></span>, we can find an estimate of the parameters <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\displaystyle {\boldsymbol {\theta }}}" xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="true" scriptlevel="0">
<mrow class="MJX-TeXAtom-ORD">
<mi mathvariant="bold-italic">θ<!-- θ --></mi>
</mrow>
</mstyle>
</mrow>
<annotation encoding="application/x-tex">{\displaystyle {\boldsymbol {\theta }}}</annotation>
</semantics>
</math></span><img alt="{\boldsymbol {\theta }}" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/33b025a6bf54ec02e65c871dc3e5897c921419cf" style="vertical-align: -0.338ex; width:1.306ex; height:2.176ex;"/></span> fairly easily, typically by simply grouping the observed data points according to the value of the associated latent variable and averaging the values, or some function of the values, of the points in each group.  This suggests an iterative algorithm, in the case where both <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\displaystyle {\boldsymbol {\theta }}}" xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="true" scriptlevel="0">
<mrow class="MJX-TeXAtom-ORD">
<mi mathvariant="bold-italic">θ<!-- θ --></mi>
</mrow>
</mstyle>
</mrow>
<annotation encoding="application/x-tex">{\displaystyle {\boldsymbol {\theta }}}</annotation>
</semantics>
</math></span><img alt="{\boldsymbol {\theta }}" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/33b025a6bf54ec02e65c871dc3e5897c921419cf" style="vertical-align: -0.338ex; width:1.306ex; height:2.176ex;"/></span> and <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\displaystyle \mathbf {Z} }" xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="true" scriptlevel="0">
<mrow class="MJX-TeXAtom-ORD">
<mi mathvariant="bold">Z</mi>
</mrow>
</mstyle>
</mrow>
<annotation encoding="application/x-tex">{\displaystyle \mathbf {Z} }</annotation>
</semantics>
</math></span><img alt="\mathbf {Z} " aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/b776aaf12c2da4b78ca777cb8295c2000bfd51f5" style="vertical-align: -0.338ex; width:1.634ex; height:2.176ex;"/></span> are unknown:
</p>
<ol><li>First, initialize the parameters <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\displaystyle {\boldsymbol {\theta }}}" xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="true" scriptlevel="0">
<mrow class="MJX-TeXAtom-ORD">
<mi mathvariant="bold-italic">θ<!-- θ --></mi>
</mrow>
</mstyle>
</mrow>
<annotation encoding="application/x-tex">{\displaystyle {\boldsymbol {\theta }}}</annotation>
</semantics>
</math></span><img alt="{\boldsymbol {\theta }}" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/33b025a6bf54ec02e65c871dc3e5897c921419cf" style="vertical-align: -0.338ex; width:1.306ex; height:2.176ex;"/></span> to some random values.</li>
<li>Compute the probability of each possible value of <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\displaystyle \mathbf {Z} }" xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="true" scriptlevel="0">
<mrow class="MJX-TeXAtom-ORD">
<mi mathvariant="bold">Z</mi>
</mrow>
</mstyle>
</mrow>
<annotation encoding="application/x-tex">{\displaystyle \mathbf {Z} }</annotation>
</semantics>
</math></span><img alt="\mathbf {Z} " aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/b776aaf12c2da4b78ca777cb8295c2000bfd51f5" style="vertical-align: -0.338ex; width:1.634ex; height:2.176ex;"/></span> , given <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\displaystyle {\boldsymbol {\theta }}}" xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="true" scriptlevel="0">
<mrow class="MJX-TeXAtom-ORD">
<mi mathvariant="bold-italic">θ<!-- θ --></mi>
</mrow>
</mstyle>
</mrow>
<annotation encoding="application/x-tex">{\displaystyle {\boldsymbol {\theta }}}</annotation>
</semantics>
</math></span><img alt="{\boldsymbol {\theta }}" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/33b025a6bf54ec02e65c871dc3e5897c921419cf" style="vertical-align: -0.338ex; width:1.306ex; height:2.176ex;"/></span>.</li>
<li>Then, use the just-computed values of <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\displaystyle \mathbf {Z} }" xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="true" scriptlevel="0">
<mrow class="MJX-TeXAtom-ORD">
<mi mathvariant="bold">Z</mi>
</mrow>
</mstyle>
</mrow>
<annotation encoding="application/x-tex">{\displaystyle \mathbf {Z} }</annotation>
</semantics>
</math></span><img alt="\mathbf {Z} " aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/b776aaf12c2da4b78ca777cb8295c2000bfd51f5" style="vertical-align: -0.338ex; width:1.634ex; height:2.176ex;"/></span> to compute a better estimate for the parameters <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\displaystyle {\boldsymbol {\theta }}}" xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="true" scriptlevel="0">
<mrow class="MJX-TeXAtom-ORD">
<mi mathvariant="bold-italic">θ<!-- θ --></mi>
</mrow>
</mstyle>
</mrow>
<annotation encoding="application/x-tex">{\displaystyle {\boldsymbol {\theta }}}</annotation>
</semantics>
</math></span><img alt="{\boldsymbol {\theta }}" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/33b025a6bf54ec02e65c871dc3e5897c921419cf" style="vertical-align: -0.338ex; width:1.306ex; height:2.176ex;"/></span>.</li>
<li>Iterate steps 2 and 3 until convergence.</li></ol>
<p>The algorithm as just described monotonically approaches a local minimum of the cost function.
</p>
<h2><span class="mw-headline" id="Properties">Properties</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Expectation%E2%80%93maximization_algorithm&amp;action=edit&amp;section=4" title="Edit section: Properties">edit</a><span class="mw-editsection-bracket">]</span></span></h2>
<p>Speaking of an expectation (E) step is a bit of a <a href="/wiki/Misnomer" title="Misnomer">misnomer</a>. What are calculated in the first step are the fixed, data-dependent parameters of the function <i>Q</i>. Once the parameters of <i>Q</i> are known, it is fully determined and is maximized in the second (M) step of an EM algorithm.
</p><p>Although an EM iteration does increase the observed data (i.e., marginal) likelihood function, no guarantee exists that the sequence converges to a <a class="mw-redirect" href="/wiki/Maximum_likelihood_estimator" title="Maximum likelihood estimator">maximum likelihood estimator</a>. For <a class="mw-redirect" href="/wiki/Bimodal_distribution" title="Bimodal distribution">multimodal distributions</a>, this means that an EM algorithm may converge to a <a class="mw-redirect" href="/wiki/Local_maximum" title="Local maximum">local maximum</a> of the observed data likelihood function, depending on starting values. A variety of heuristic or <a href="/wiki/Metaheuristic" title="Metaheuristic">metaheuristic</a> approaches exist to escape a local maximum, such as random-restart <a href="/wiki/Hill_climbing" title="Hill climbing">hill climbing</a> (starting with several different random initial estimates <i>θ</i><sup>(<i>t</i>)</sup>), or applying <a href="/wiki/Simulated_annealing" title="Simulated annealing">simulated annealing</a> methods.
</p><p>EM is especially useful when the likelihood is an <a href="/wiki/Exponential_family" title="Exponential family">exponential family</a>: the E step becomes the sum of expectations of <a href="/wiki/Sufficient_statistic" title="Sufficient statistic">sufficient statistics</a>, and the M step involves maximizing a linear function. In such a case, it is usually possible to derive <a href="/wiki/Closed-form_expression" title="Closed-form expression">closed-form expression</a> updates for each step, using the Sundberg formula (published by Rolf Sundberg using unpublished results of <a href="/wiki/Per_Martin-L%C3%B6f" title="Per Martin-Löf">Per Martin-Löf</a> and <a href="/wiki/Anders_Martin-L%C3%B6f" title="Anders Martin-Löf">Anders Martin-Löf</a>).<sup class="reference" id="cite_ref-Sundberg1971_4-1"><a href="#cite_note-Sundberg1971-4">[4]</a></sup><sup class="reference" id="cite_ref-Sundberg1976_5-1"><a href="#cite_note-Sundberg1976-5">[5]</a></sup><sup class="reference" id="cite_ref-Martin-Löf1963_8-1"><a href="#cite_note-Martin-Löf1963-8">[8]</a></sup><sup class="reference" id="cite_ref-Martin-Löf1966_9-1"><a href="#cite_note-Martin-Löf1966-9">[9]</a></sup><sup class="reference" id="cite_ref-Martin-Löf1970_10-1"><a href="#cite_note-Martin-Löf1970-10">[10]</a></sup><sup class="reference" id="cite_ref-Martin-Löf1974a_11-1"><a href="#cite_note-Martin-Löf1974a-11">[11]</a></sup><sup class="reference" id="cite_ref-Martin-Löf1974b_12-1"><a href="#cite_note-Martin-Löf1974b-12">[12]</a></sup>
</p><p>The EM method was modified to compute <a class="mw-redirect" href="/wiki/Maximum_a_posteriori" title="Maximum a posteriori">maximum a posteriori</a> (MAP) estimates for <a href="/wiki/Bayesian_inference" title="Bayesian inference">Bayesian inference</a> in the original paper by Dempster, Laird, and Rubin.
</p><p>Other methods exist to find maximum likelihood estimates, such as <a href="/wiki/Gradient_descent" title="Gradient descent">gradient descent</a>, <a class="mw-redirect" href="/wiki/Conjugate_gradient" title="Conjugate gradient">conjugate gradient</a>, or variants of the <a href="/wiki/Gauss%E2%80%93Newton_algorithm" title="Gauss–Newton algorithm">Gauss–Newton algorithm</a>. Unlike EM, such methods typically require the evaluation of first and/or second derivatives of the likelihood function.
</p>
<h2><span class="mw-headline" id="Proof_of_correctness">Proof of correctness</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Expectation%E2%80%93maximization_algorithm&amp;action=edit&amp;section=5" title="Edit section: Proof of correctness">edit</a><span class="mw-editsection-bracket">]</span></span></h2>
<p>Expectation-maximization works to improve <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\displaystyle Q({\boldsymbol {\theta }}\mid {\boldsymbol {\theta }}^{(t)})}" xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="true" scriptlevel="0">
<mi>Q</mi>
<mo stretchy="false">(</mo>
<mrow class="MJX-TeXAtom-ORD">
<mi mathvariant="bold-italic">θ<!-- θ --></mi>
</mrow>
<mo>∣<!-- ∣ --></mo>
<msup>
<mrow class="MJX-TeXAtom-ORD">
<mi mathvariant="bold-italic">θ<!-- θ --></mi>
</mrow>
<mrow class="MJX-TeXAtom-ORD">
<mo stretchy="false">(</mo>
<mi>t</mi>
<mo stretchy="false">)</mo>
</mrow>
</msup>
<mo stretchy="false">)</mo>
</mstyle>
</mrow>
<annotation encoding="application/x-tex">{\displaystyle Q({\boldsymbol {\theta }}\mid {\boldsymbol {\theta }}^{(t)})}</annotation>
</semantics>
</math></span><img alt="{\displaystyle Q({\boldsymbol {\theta }}\mid {\boldsymbol {\theta }}^{(t)})}" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/24d245ae1f551d986964bdcfa59ef4bad70079cb" style="vertical-align: -0.838ex; width:10.303ex; height:3.343ex;"/></span> rather than directly improving <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\displaystyle \log p(\mathbf {X} \mid {\boldsymbol {\theta }})}" xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="true" scriptlevel="0">
<mi>log</mi>
<mo>⁡<!-- ⁡ --></mo>
<mi>p</mi>
<mo stretchy="false">(</mo>
<mrow class="MJX-TeXAtom-ORD">
<mi mathvariant="bold">X</mi>
</mrow>
<mo>∣<!-- ∣ --></mo>
<mrow class="MJX-TeXAtom-ORD">
<mi mathvariant="bold-italic">θ<!-- θ --></mi>
</mrow>
<mo stretchy="false">)</mo>
</mstyle>
</mrow>
<annotation encoding="application/x-tex">{\displaystyle \log p(\mathbf {X} \mid {\boldsymbol {\theta }})}</annotation>
</semantics>
</math></span><img alt="{\displaystyle \log p(\mathbf {X} \mid {\boldsymbol {\theta }})}" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/3b1c4eed3feeeca1f0a16cf8a0dd57b2ecc5e6e1" style="vertical-align: -0.838ex; width:11.601ex; height:2.843ex;"/></span>.  Here is shown that improvements to the former imply improvements to the latter.<sup class="reference" id="cite_ref-Little1987_14-0"><a href="#cite_note-Little1987-14">[14]</a></sup>
</p><p>For any <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\displaystyle \mathbf {Z} }" xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="true" scriptlevel="0">
<mrow class="MJX-TeXAtom-ORD">
<mi mathvariant="bold">Z</mi>
</mrow>
</mstyle>
</mrow>
<annotation encoding="application/x-tex">{\displaystyle \mathbf {Z} }</annotation>
</semantics>
</math></span><img alt="\mathbf {Z} " aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/b776aaf12c2da4b78ca777cb8295c2000bfd51f5" style="vertical-align: -0.338ex; width:1.634ex; height:2.176ex;"/></span> with non-zero probability <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\displaystyle p(\mathbf {Z} \mid \mathbf {X} ,{\boldsymbol {\theta }})}" xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="true" scriptlevel="0">
<mi>p</mi>
<mo stretchy="false">(</mo>
<mrow class="MJX-TeXAtom-ORD">
<mi mathvariant="bold">Z</mi>
</mrow>
<mo>∣<!-- ∣ --></mo>
<mrow class="MJX-TeXAtom-ORD">
<mi mathvariant="bold">X</mi>
</mrow>
<mo>,</mo>
<mrow class="MJX-TeXAtom-ORD">
<mi mathvariant="bold-italic">θ<!-- θ --></mi>
</mrow>
<mo stretchy="false">)</mo>
</mstyle>
</mrow>
<annotation encoding="application/x-tex">{\displaystyle p(\mathbf {Z} \mid \mathbf {X} ,{\boldsymbol {\theta }})}</annotation>
</semantics>
</math></span><img alt="{\displaystyle p(\mathbf {Z} \mid \mathbf {X} ,{\boldsymbol {\theta }})}" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/4921aead43c89a940741fbce1a43b20ee9f40aa2" style="vertical-align: -0.838ex; margin-left: -0.089ex; width:10.999ex; height:2.843ex;"/></span>, we can write
</p>
<dl><dd><dl><dd><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\displaystyle \log p(\mathbf {X} \mid {\boldsymbol {\theta }})=\log p(\mathbf {X} ,\mathbf {Z} \mid {\boldsymbol {\theta }})-\log p(\mathbf {Z} \mid \mathbf {X} ,{\boldsymbol {\theta }})\,.}" xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="true" scriptlevel="0">
<mi>log</mi>
<mo>⁡<!-- ⁡ --></mo>
<mi>p</mi>
<mo stretchy="false">(</mo>
<mrow class="MJX-TeXAtom-ORD">
<mi mathvariant="bold">X</mi>
</mrow>
<mo>∣<!-- ∣ --></mo>
<mrow class="MJX-TeXAtom-ORD">
<mi mathvariant="bold-italic">θ<!-- θ --></mi>
</mrow>
<mo stretchy="false">)</mo>
<mo>=</mo>
<mi>log</mi>
<mo>⁡<!-- ⁡ --></mo>
<mi>p</mi>
<mo stretchy="false">(</mo>
<mrow class="MJX-TeXAtom-ORD">
<mi mathvariant="bold">X</mi>
</mrow>
<mo>,</mo>
<mrow class="MJX-TeXAtom-ORD">
<mi mathvariant="bold">Z</mi>
</mrow>
<mo>∣<!-- ∣ --></mo>
<mrow class="MJX-TeXAtom-ORD">
<mi mathvariant="bold-italic">θ<!-- θ --></mi>
</mrow>
<mo stretchy="false">)</mo>
<mo>−<!-- − --></mo>
<mi>log</mi>
<mo>⁡<!-- ⁡ --></mo>
<mi>p</mi>
<mo stretchy="false">(</mo>
<mrow class="MJX-TeXAtom-ORD">
<mi mathvariant="bold">Z</mi>
</mrow>
<mo>∣<!-- ∣ --></mo>
<mrow class="MJX-TeXAtom-ORD">
<mi mathvariant="bold">X</mi>
</mrow>
<mo>,</mo>
<mrow class="MJX-TeXAtom-ORD">
<mi mathvariant="bold-italic">θ<!-- θ --></mi>
</mrow>
<mo stretchy="false">)</mo>
<mspace width="thinmathspace"></mspace>
<mo>.</mo>
</mstyle>
</mrow>
<annotation encoding="application/x-tex">{\displaystyle \log p(\mathbf {X} \mid {\boldsymbol {\theta }})=\log p(\mathbf {X} ,\mathbf {Z} \mid {\boldsymbol {\theta }})-\log p(\mathbf {Z} \mid \mathbf {X} ,{\boldsymbol {\theta }})\,.}</annotation>
</semantics>
</math></span><img alt="{\displaystyle \log p(\mathbf {X} \mid {\boldsymbol {\theta }})=\log p(\mathbf {X} ,\mathbf {Z} \mid {\boldsymbol {\theta }})-\log p(\mathbf {Z} \mid \mathbf {X} ,{\boldsymbol {\theta }})\,.}" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/9d8df43cc7bc423c8d492b5643ff48c80376cb8f" style="vertical-align: -0.838ex; width:47.111ex; height:2.843ex;"/></span></dd></dl></dd></dl>
<p>We take the expectation over possible values of the unknown data <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\displaystyle \mathbf {Z} }" xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="true" scriptlevel="0">
<mrow class="MJX-TeXAtom-ORD">
<mi mathvariant="bold">Z</mi>
</mrow>
</mstyle>
</mrow>
<annotation encoding="application/x-tex">{\displaystyle \mathbf {Z} }</annotation>
</semantics>
</math></span><img alt="\mathbf {Z} " aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/b776aaf12c2da4b78ca777cb8295c2000bfd51f5" style="vertical-align: -0.338ex; width:1.634ex; height:2.176ex;"/></span> under the current parameter estimate <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\displaystyle \theta ^{(t)}}" xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="true" scriptlevel="0">
<msup>
<mi>θ<!-- θ --></mi>
<mrow class="MJX-TeXAtom-ORD">
<mo stretchy="false">(</mo>
<mi>t</mi>
<mo stretchy="false">)</mo>
</mrow>
</msup>
</mstyle>
</mrow>
<annotation encoding="application/x-tex">{\displaystyle \theta ^{(t)}}</annotation>
</semantics>
</math></span><img alt="\theta^{(t)}" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/7dbe79968a27c7b3508260e53b0123a5872b16cc" style="vertical-align: -0.338ex; width:3.196ex; height:2.843ex;"/></span> by multiplying both sides by <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\displaystyle p(\mathbf {Z} \mid \mathbf {X} ,{\boldsymbol {\theta }}^{(t)})}" xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="true" scriptlevel="0">
<mi>p</mi>
<mo stretchy="false">(</mo>
<mrow class="MJX-TeXAtom-ORD">
<mi mathvariant="bold">Z</mi>
</mrow>
<mo>∣<!-- ∣ --></mo>
<mrow class="MJX-TeXAtom-ORD">
<mi mathvariant="bold">X</mi>
</mrow>
<mo>,</mo>
<msup>
<mrow class="MJX-TeXAtom-ORD">
<mi mathvariant="bold-italic">θ<!-- θ --></mi>
</mrow>
<mrow class="MJX-TeXAtom-ORD">
<mo stretchy="false">(</mo>
<mi>t</mi>
<mo stretchy="false">)</mo>
</mrow>
</msup>
<mo stretchy="false">)</mo>
</mstyle>
</mrow>
<annotation encoding="application/x-tex">{\displaystyle p(\mathbf {Z} \mid \mathbf {X} ,{\boldsymbol {\theta }}^{(t)})}</annotation>
</semantics>
</math></span><img alt="{\displaystyle p(\mathbf {Z} \mid \mathbf {X} ,{\boldsymbol {\theta }}^{(t)})}" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/a7c37375a0cfaacb347c7d16a264ff7556aa4607" style="vertical-align: -0.838ex; margin-left: -0.089ex; width:13.104ex; height:3.343ex;"/></span> and summing (or integrating) over <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\displaystyle \mathbf {Z} }" xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="true" scriptlevel="0">
<mrow class="MJX-TeXAtom-ORD">
<mi mathvariant="bold">Z</mi>
</mrow>
</mstyle>
</mrow>
<annotation encoding="application/x-tex">{\displaystyle \mathbf {Z} }</annotation>
</semantics>
</math></span><img alt="\mathbf {Z} " aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/b776aaf12c2da4b78ca777cb8295c2000bfd51f5" style="vertical-align: -0.338ex; width:1.634ex; height:2.176ex;"/></span>.  The left-hand side is the expectation of a constant, so we get:
</p>
<dl><dd><dl><dd><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\displaystyle {\begin{aligned}\log p(\mathbf {X} \mid {\boldsymbol {\theta }})&amp;=\sum _{\mathbf {Z} }p(\mathbf {Z} \mid \mathbf {X} ,{\boldsymbol {\theta }}^{(t)})\log p(\mathbf {X} ,\mathbf {Z} \mid {\boldsymbol {\theta }})-\sum _{\mathbf {Z} }p(\mathbf {Z} \mid \mathbf {X} ,{\boldsymbol {\theta }}^{(t)})\log p(\mathbf {Z} \mid \mathbf {X} ,{\boldsymbol {\theta }})\\&amp;=Q({\boldsymbol {\theta }}\mid {\boldsymbol {\theta }}^{(t)})+H({\boldsymbol {\theta }}\mid {\boldsymbol {\theta }}^{(t)})\,,\end{aligned}}}" xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="true" scriptlevel="0">
<mrow class="MJX-TeXAtom-ORD">
<mtable columnalign="right left right left right left right left right left right left" columnspacing="0em 2em 0em 2em 0em 2em 0em 2em 0em 2em 0em" displaystyle="true" rowspacing="3pt">
<mtr>
<mtd>
<mi>log</mi>
<mo>⁡<!-- ⁡ --></mo>
<mi>p</mi>
<mo stretchy="false">(</mo>
<mrow class="MJX-TeXAtom-ORD">
<mi mathvariant="bold">X</mi>
</mrow>
<mo>∣<!-- ∣ --></mo>
<mrow class="MJX-TeXAtom-ORD">
<mi mathvariant="bold-italic">θ<!-- θ --></mi>
</mrow>
<mo stretchy="false">)</mo>
</mtd>
<mtd>
<mi></mi>
<mo>=</mo>
<munder>
<mo>∑<!-- ∑ --></mo>
<mrow class="MJX-TeXAtom-ORD">
<mrow class="MJX-TeXAtom-ORD">
<mi mathvariant="bold">Z</mi>
</mrow>
</mrow>
</munder>
<mi>p</mi>
<mo stretchy="false">(</mo>
<mrow class="MJX-TeXAtom-ORD">
<mi mathvariant="bold">Z</mi>
</mrow>
<mo>∣<!-- ∣ --></mo>
<mrow class="MJX-TeXAtom-ORD">
<mi mathvariant="bold">X</mi>
</mrow>
<mo>,</mo>
<msup>
<mrow class="MJX-TeXAtom-ORD">
<mi mathvariant="bold-italic">θ<!-- θ --></mi>
</mrow>
<mrow class="MJX-TeXAtom-ORD">
<mo stretchy="false">(</mo>
<mi>t</mi>
<mo stretchy="false">)</mo>
</mrow>
</msup>
<mo stretchy="false">)</mo>
<mi>log</mi>
<mo>⁡<!-- ⁡ --></mo>
<mi>p</mi>
<mo stretchy="false">(</mo>
<mrow class="MJX-TeXAtom-ORD">
<mi mathvariant="bold">X</mi>
</mrow>
<mo>,</mo>
<mrow class="MJX-TeXAtom-ORD">
<mi mathvariant="bold">Z</mi>
</mrow>
<mo>∣<!-- ∣ --></mo>
<mrow class="MJX-TeXAtom-ORD">
<mi mathvariant="bold-italic">θ<!-- θ --></mi>
</mrow>
<mo stretchy="false">)</mo>
<mo>−<!-- − --></mo>
<munder>
<mo>∑<!-- ∑ --></mo>
<mrow class="MJX-TeXAtom-ORD">
<mrow class="MJX-TeXAtom-ORD">
<mi mathvariant="bold">Z</mi>
</mrow>
</mrow>
</munder>
<mi>p</mi>
<mo stretchy="false">(</mo>
<mrow class="MJX-TeXAtom-ORD">
<mi mathvariant="bold">Z</mi>
</mrow>
<mo>∣<!-- ∣ --></mo>
<mrow class="MJX-TeXAtom-ORD">
<mi mathvariant="bold">X</mi>
</mrow>
<mo>,</mo>
<msup>
<mrow class="MJX-TeXAtom-ORD">
<mi mathvariant="bold-italic">θ<!-- θ --></mi>
</mrow>
<mrow class="MJX-TeXAtom-ORD">
<mo stretchy="false">(</mo>
<mi>t</mi>
<mo stretchy="false">)</mo>
</mrow>
</msup>
<mo stretchy="false">)</mo>
<mi>log</mi>
<mo>⁡<!-- ⁡ --></mo>
<mi>p</mi>
<mo stretchy="false">(</mo>
<mrow class="MJX-TeXAtom-ORD">
<mi mathvariant="bold">Z</mi>
</mrow>
<mo>∣<!-- ∣ --></mo>
<mrow class="MJX-TeXAtom-ORD">
<mi mathvariant="bold">X</mi>
</mrow>
<mo>,</mo>
<mrow class="MJX-TeXAtom-ORD">
<mi mathvariant="bold-italic">θ<!-- θ --></mi>
</mrow>
<mo stretchy="false">)</mo>
</mtd>
</mtr>
<mtr>
<mtd></mtd>
<mtd>
<mi></mi>
<mo>=</mo>
<mi>Q</mi>
<mo stretchy="false">(</mo>
<mrow class="MJX-TeXAtom-ORD">
<mi mathvariant="bold-italic">θ<!-- θ --></mi>
</mrow>
<mo>∣<!-- ∣ --></mo>
<msup>
<mrow class="MJX-TeXAtom-ORD">
<mi mathvariant="bold-italic">θ<!-- θ --></mi>
</mrow>
<mrow class="MJX-TeXAtom-ORD">
<mo stretchy="false">(</mo>
<mi>t</mi>
<mo stretchy="false">)</mo>
</mrow>
</msup>
<mo stretchy="false">)</mo>
<mo>+</mo>
<mi>H</mi>
<mo stretchy="false">(</mo>
<mrow class="MJX-TeXAtom-ORD">
<mi mathvariant="bold-italic">θ<!-- θ --></mi>
</mrow>
<mo>∣<!-- ∣ --></mo>
<msup>
<mrow class="MJX-TeXAtom-ORD">
<mi mathvariant="bold-italic">θ<!-- θ --></mi>
</mrow>
<mrow class="MJX-TeXAtom-ORD">
<mo stretchy="false">(</mo>
<mi>t</mi>
<mo stretchy="false">)</mo>
</mrow>
</msup>
<mo stretchy="false">)</mo>
<mspace width="thinmathspace"></mspace>
<mo>,</mo>
</mtd>
</mtr>
</mtable>
</mrow>
</mstyle>
</mrow>
<annotation encoding="application/x-tex">{\displaystyle {\begin{aligned}\log p(\mathbf {X} \mid {\boldsymbol {\theta }})&amp;=\sum _{\mathbf {Z} }p(\mathbf {Z} \mid \mathbf {X} ,{\boldsymbol {\theta }}^{(t)})\log p(\mathbf {X} ,\mathbf {Z} \mid {\boldsymbol {\theta }})-\sum _{\mathbf {Z} }p(\mathbf {Z} \mid \mathbf {X} ,{\boldsymbol {\theta }}^{(t)})\log p(\mathbf {Z} \mid \mathbf {X} ,{\boldsymbol {\theta }})\\&amp;=Q({\boldsymbol {\theta }}\mid {\boldsymbol {\theta }}^{(t)})+H({\boldsymbol {\theta }}\mid {\boldsymbol {\theta }}^{(t)})\,,\end{aligned}}}</annotation>
</semantics>
</math></span><img alt="{\displaystyle {\begin{aligned}\log p(\mathbf {X} \mid {\boldsymbol {\theta }})&amp;=\sum _{\mathbf {Z} }p(\mathbf {Z} \mid \mathbf {X} ,{\boldsymbol {\theta }}^{(t)})\log p(\mathbf {X} ,\mathbf {Z} \mid {\boldsymbol {\theta }})-\sum _{\mathbf {Z} }p(\mathbf {Z} \mid \mathbf {X} ,{\boldsymbol {\theta }}^{(t)})\log p(\mathbf {Z} \mid \mathbf {X} ,{\boldsymbol {\theta }})\\&amp;=Q({\boldsymbol {\theta }}\mid {\boldsymbol {\theta }}^{(t)})+H({\boldsymbol {\theta }}\mid {\boldsymbol {\theta }}^{(t)})\,,\end{aligned}}}" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/8a165aa6dd37a4f3b2ccbff436e19e7290bb4a89" style="vertical-align: -4.005ex; width:81.117ex; height:9.176ex;"/></span></dd></dl></dd></dl>
<p>where <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\displaystyle H({\boldsymbol {\theta }}\mid {\boldsymbol {\theta }}^{(t)})}" xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="true" scriptlevel="0">
<mi>H</mi>
<mo stretchy="false">(</mo>
<mrow class="MJX-TeXAtom-ORD">
<mi mathvariant="bold-italic">θ<!-- θ --></mi>
</mrow>
<mo>∣<!-- ∣ --></mo>
<msup>
<mrow class="MJX-TeXAtom-ORD">
<mi mathvariant="bold-italic">θ<!-- θ --></mi>
</mrow>
<mrow class="MJX-TeXAtom-ORD">
<mo stretchy="false">(</mo>
<mi>t</mi>
<mo stretchy="false">)</mo>
</mrow>
</msup>
<mo stretchy="false">)</mo>
</mstyle>
</mrow>
<annotation encoding="application/x-tex">{\displaystyle H({\boldsymbol {\theta }}\mid {\boldsymbol {\theta }}^{(t)})}</annotation>
</semantics>
</math></span><img alt="{\displaystyle H({\boldsymbol {\theta }}\mid {\boldsymbol {\theta }}^{(t)})}" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/002e61b049741e19c9fb5b0c331b1ec093e334bd" style="vertical-align: -0.838ex; width:10.528ex; height:3.343ex;"/></span> is defined by the negated sum it is replacing.
This last equation holds for every value of <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\displaystyle {\boldsymbol {\theta }}}" xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="true" scriptlevel="0">
<mrow class="MJX-TeXAtom-ORD">
<mi mathvariant="bold-italic">θ<!-- θ --></mi>
</mrow>
</mstyle>
</mrow>
<annotation encoding="application/x-tex">{\displaystyle {\boldsymbol {\theta }}}</annotation>
</semantics>
</math></span><img alt="{\boldsymbol {\theta }}" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/33b025a6bf54ec02e65c871dc3e5897c921419cf" style="vertical-align: -0.338ex; width:1.306ex; height:2.176ex;"/></span> including <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\displaystyle {\boldsymbol {\theta }}={\boldsymbol {\theta }}^{(t)}}" xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="true" scriptlevel="0">
<mrow class="MJX-TeXAtom-ORD">
<mi mathvariant="bold-italic">θ<!-- θ --></mi>
</mrow>
<mo>=</mo>
<msup>
<mrow class="MJX-TeXAtom-ORD">
<mi mathvariant="bold-italic">θ<!-- θ --></mi>
</mrow>
<mrow class="MJX-TeXAtom-ORD">
<mo stretchy="false">(</mo>
<mi>t</mi>
<mo stretchy="false">)</mo>
</mrow>
</msup>
</mstyle>
</mrow>
<annotation encoding="application/x-tex">{\displaystyle {\boldsymbol {\theta }}={\boldsymbol {\theta }}^{(t)}}</annotation>
</semantics>
</math></span><img alt="\boldsymbol\theta = \boldsymbol\theta^{(t)}" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/e25b6d9fac398c249453f943de46eb5b7cac8a09" style="vertical-align: -0.338ex; width:7.817ex; height:2.843ex;"/></span>,
</p>
<dl><dd><dl><dd><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\displaystyle \log p(\mathbf {X} \mid {\boldsymbol {\theta }}^{(t)})=Q({\boldsymbol {\theta }}^{(t)}\mid {\boldsymbol {\theta }}^{(t)})+H({\boldsymbol {\theta }}^{(t)}\mid {\boldsymbol {\theta }}^{(t)})\,,}" xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="true" scriptlevel="0">
<mi>log</mi>
<mo>⁡<!-- ⁡ --></mo>
<mi>p</mi>
<mo stretchy="false">(</mo>
<mrow class="MJX-TeXAtom-ORD">
<mi mathvariant="bold">X</mi>
</mrow>
<mo>∣<!-- ∣ --></mo>
<msup>
<mrow class="MJX-TeXAtom-ORD">
<mi mathvariant="bold-italic">θ<!-- θ --></mi>
</mrow>
<mrow class="MJX-TeXAtom-ORD">
<mo stretchy="false">(</mo>
<mi>t</mi>
<mo stretchy="false">)</mo>
</mrow>
</msup>
<mo stretchy="false">)</mo>
<mo>=</mo>
<mi>Q</mi>
<mo stretchy="false">(</mo>
<msup>
<mrow class="MJX-TeXAtom-ORD">
<mi mathvariant="bold-italic">θ<!-- θ --></mi>
</mrow>
<mrow class="MJX-TeXAtom-ORD">
<mo stretchy="false">(</mo>
<mi>t</mi>
<mo stretchy="false">)</mo>
</mrow>
</msup>
<mo>∣<!-- ∣ --></mo>
<msup>
<mrow class="MJX-TeXAtom-ORD">
<mi mathvariant="bold-italic">θ<!-- θ --></mi>
</mrow>
<mrow class="MJX-TeXAtom-ORD">
<mo stretchy="false">(</mo>
<mi>t</mi>
<mo stretchy="false">)</mo>
</mrow>
</msup>
<mo stretchy="false">)</mo>
<mo>+</mo>
<mi>H</mi>
<mo stretchy="false">(</mo>
<msup>
<mrow class="MJX-TeXAtom-ORD">
<mi mathvariant="bold-italic">θ<!-- θ --></mi>
</mrow>
<mrow class="MJX-TeXAtom-ORD">
<mo stretchy="false">(</mo>
<mi>t</mi>
<mo stretchy="false">)</mo>
</mrow>
</msup>
<mo>∣<!-- ∣ --></mo>
<msup>
<mrow class="MJX-TeXAtom-ORD">
<mi mathvariant="bold-italic">θ<!-- θ --></mi>
</mrow>
<mrow class="MJX-TeXAtom-ORD">
<mo stretchy="false">(</mo>
<mi>t</mi>
<mo stretchy="false">)</mo>
</mrow>
</msup>
<mo stretchy="false">)</mo>
<mspace width="thinmathspace"></mspace>
<mo>,</mo>
</mstyle>
</mrow>
<annotation encoding="application/x-tex">{\displaystyle \log p(\mathbf {X} \mid {\boldsymbol {\theta }}^{(t)})=Q({\boldsymbol {\theta }}^{(t)}\mid {\boldsymbol {\theta }}^{(t)})+H({\boldsymbol {\theta }}^{(t)}\mid {\boldsymbol {\theta }}^{(t)})\,,}</annotation>
</semantics>
</math></span><img alt="{\displaystyle \log p(\mathbf {X} \mid {\boldsymbol {\theta }}^{(t)})=Q({\boldsymbol {\theta }}^{(t)}\mid {\boldsymbol {\theta }}^{(t)})+H({\boldsymbol {\theta }}^{(t)}\mid {\boldsymbol {\theta }}^{(t)})\,,}" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/82903a238a44a9f2e8b6af6a96b0befd10ce682d" style="vertical-align: -0.838ex; width:45.721ex; height:3.343ex;"/></span></dd></dl></dd></dl>
<p>and subtracting this last equation from the previous equation gives
</p>
<dl><dd><dl><dd><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\displaystyle \log p(\mathbf {X} \mid {\boldsymbol {\theta }})-\log p(\mathbf {X} \mid {\boldsymbol {\theta }}^{(t)})=Q({\boldsymbol {\theta }}\mid {\boldsymbol {\theta }}^{(t)})-Q({\boldsymbol {\theta }}^{(t)}\mid {\boldsymbol {\theta }}^{(t)})+H({\boldsymbol {\theta }}\mid {\boldsymbol {\theta }}^{(t)})-H({\boldsymbol {\theta }}^{(t)}\mid {\boldsymbol {\theta }}^{(t)})\,,}" xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="true" scriptlevel="0">
<mi>log</mi>
<mo>⁡<!-- ⁡ --></mo>
<mi>p</mi>
<mo stretchy="false">(</mo>
<mrow class="MJX-TeXAtom-ORD">
<mi mathvariant="bold">X</mi>
</mrow>
<mo>∣<!-- ∣ --></mo>
<mrow class="MJX-TeXAtom-ORD">
<mi mathvariant="bold-italic">θ<!-- θ --></mi>
</mrow>
<mo stretchy="false">)</mo>
<mo>−<!-- − --></mo>
<mi>log</mi>
<mo>⁡<!-- ⁡ --></mo>
<mi>p</mi>
<mo stretchy="false">(</mo>
<mrow class="MJX-TeXAtom-ORD">
<mi mathvariant="bold">X</mi>
</mrow>
<mo>∣<!-- ∣ --></mo>
<msup>
<mrow class="MJX-TeXAtom-ORD">
<mi mathvariant="bold-italic">θ<!-- θ --></mi>
</mrow>
<mrow class="MJX-TeXAtom-ORD">
<mo stretchy="false">(</mo>
<mi>t</mi>
<mo stretchy="false">)</mo>
</mrow>
</msup>
<mo stretchy="false">)</mo>
<mo>=</mo>
<mi>Q</mi>
<mo stretchy="false">(</mo>
<mrow class="MJX-TeXAtom-ORD">
<mi mathvariant="bold-italic">θ<!-- θ --></mi>
</mrow>
<mo>∣<!-- ∣ --></mo>
<msup>
<mrow class="MJX-TeXAtom-ORD">
<mi mathvariant="bold-italic">θ<!-- θ --></mi>
</mrow>
<mrow class="MJX-TeXAtom-ORD">
<mo stretchy="false">(</mo>
<mi>t</mi>
<mo stretchy="false">)</mo>
</mrow>
</msup>
<mo stretchy="false">)</mo>
<mo>−<!-- − --></mo>
<mi>Q</mi>
<mo stretchy="false">(</mo>
<msup>
<mrow class="MJX-TeXAtom-ORD">
<mi mathvariant="bold-italic">θ<!-- θ --></mi>
</mrow>
<mrow class="MJX-TeXAtom-ORD">
<mo stretchy="false">(</mo>
<mi>t</mi>
<mo stretchy="false">)</mo>
</mrow>
</msup>
<mo>∣<!-- ∣ --></mo>
<msup>
<mrow class="MJX-TeXAtom-ORD">
<mi mathvariant="bold-italic">θ<!-- θ --></mi>
</mrow>
<mrow class="MJX-TeXAtom-ORD">
<mo stretchy="false">(</mo>
<mi>t</mi>
<mo stretchy="false">)</mo>
</mrow>
</msup>
<mo stretchy="false">)</mo>
<mo>+</mo>
<mi>H</mi>
<mo stretchy="false">(</mo>
<mrow class="MJX-TeXAtom-ORD">
<mi mathvariant="bold-italic">θ<!-- θ --></mi>
</mrow>
<mo>∣<!-- ∣ --></mo>
<msup>
<mrow class="MJX-TeXAtom-ORD">
<mi mathvariant="bold-italic">θ<!-- θ --></mi>
</mrow>
<mrow class="MJX-TeXAtom-ORD">
<mo stretchy="false">(</mo>
<mi>t</mi>
<mo stretchy="false">)</mo>
</mrow>
</msup>
<mo stretchy="false">)</mo>
<mo>−<!-- − --></mo>
<mi>H</mi>
<mo stretchy="false">(</mo>
<msup>
<mrow class="MJX-TeXAtom-ORD">
<mi mathvariant="bold-italic">θ<!-- θ --></mi>
</mrow>
<mrow class="MJX-TeXAtom-ORD">
<mo stretchy="false">(</mo>
<mi>t</mi>
<mo stretchy="false">)</mo>
</mrow>
</msup>
<mo>∣<!-- ∣ --></mo>
<msup>
<mrow class="MJX-TeXAtom-ORD">
<mi mathvariant="bold-italic">θ<!-- θ --></mi>
</mrow>
<mrow class="MJX-TeXAtom-ORD">
<mo stretchy="false">(</mo>
<mi>t</mi>
<mo stretchy="false">)</mo>
</mrow>
</msup>
<mo stretchy="false">)</mo>
<mspace width="thinmathspace"></mspace>
<mo>,</mo>
</mstyle>
</mrow>
<annotation encoding="application/x-tex">{\displaystyle \log p(\mathbf {X} \mid {\boldsymbol {\theta }})-\log p(\mathbf {X} \mid {\boldsymbol {\theta }}^{(t)})=Q({\boldsymbol {\theta }}\mid {\boldsymbol {\theta }}^{(t)})-Q({\boldsymbol {\theta }}^{(t)}\mid {\boldsymbol {\theta }}^{(t)})+H({\boldsymbol {\theta }}\mid {\boldsymbol {\theta }}^{(t)})-H({\boldsymbol {\theta }}^{(t)}\mid {\boldsymbol {\theta }}^{(t)})\,,}</annotation>
</semantics>
</math></span><img alt="{\displaystyle \log p(\mathbf {X} \mid {\boldsymbol {\theta }})-\log p(\mathbf {X} \mid {\boldsymbol {\theta }}^{(t)})=Q({\boldsymbol {\theta }}\mid {\boldsymbol {\theta }}^{(t)})-Q({\boldsymbol {\theta }}^{(t)}\mid {\boldsymbol {\theta }}^{(t)})+H({\boldsymbol {\theta }}\mid {\boldsymbol {\theta }}^{(t)})-H({\boldsymbol {\theta }}^{(t)}\mid {\boldsymbol {\theta }}^{(t)})\,,}" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/5a972db544746df97d90ce088f4a437616261a54" style="vertical-align: -0.838ex; width:86.674ex; height:3.343ex;"/></span></dd></dl></dd></dl>
<p>However, <a href="/wiki/Jensen%27s_inequality" title="Jensen's inequality">Jensen's inequality</a> tells us that <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\displaystyle H({\boldsymbol {\theta }}\mid {\boldsymbol {\theta }}^{(t)})\geq H({\boldsymbol {\theta }}^{(t)}\mid {\boldsymbol {\theta }}^{(t)})}" xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="true" scriptlevel="0">
<mi>H</mi>
<mo stretchy="false">(</mo>
<mrow class="MJX-TeXAtom-ORD">
<mi mathvariant="bold-italic">θ<!-- θ --></mi>
</mrow>
<mo>∣<!-- ∣ --></mo>
<msup>
<mrow class="MJX-TeXAtom-ORD">
<mi mathvariant="bold-italic">θ<!-- θ --></mi>
</mrow>
<mrow class="MJX-TeXAtom-ORD">
<mo stretchy="false">(</mo>
<mi>t</mi>
<mo stretchy="false">)</mo>
</mrow>
</msup>
<mo stretchy="false">)</mo>
<mo>≥<!-- ≥ --></mo>
<mi>H</mi>
<mo stretchy="false">(</mo>
<msup>
<mrow class="MJX-TeXAtom-ORD">
<mi mathvariant="bold-italic">θ<!-- θ --></mi>
</mrow>
<mrow class="MJX-TeXAtom-ORD">
<mo stretchy="false">(</mo>
<mi>t</mi>
<mo stretchy="false">)</mo>
</mrow>
</msup>
<mo>∣<!-- ∣ --></mo>
<msup>
<mrow class="MJX-TeXAtom-ORD">
<mi mathvariant="bold-italic">θ<!-- θ --></mi>
</mrow>
<mrow class="MJX-TeXAtom-ORD">
<mo stretchy="false">(</mo>
<mi>t</mi>
<mo stretchy="false">)</mo>
</mrow>
</msup>
<mo stretchy="false">)</mo>
</mstyle>
</mrow>
<annotation encoding="application/x-tex">{\displaystyle H({\boldsymbol {\theta }}\mid {\boldsymbol {\theta }}^{(t)})\geq H({\boldsymbol {\theta }}^{(t)}\mid {\boldsymbol {\theta }}^{(t)})}</annotation>
</semantics>
</math></span><img alt="{\displaystyle H({\boldsymbol {\theta }}\mid {\boldsymbol {\theta }}^{(t)})\geq H({\boldsymbol {\theta }}^{(t)}\mid {\boldsymbol {\theta }}^{(t)})}" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/507c40004ea5b6171086fd4b4c0cd25d82b8cf5c" style="vertical-align: -0.838ex; width:26.26ex; height:3.343ex;"/></span>, so we can conclude that
</p>
<dl><dd><dl><dd><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\displaystyle \log p(\mathbf {X} \mid {\boldsymbol {\theta }})-\log p(\mathbf {X} \mid {\boldsymbol {\theta }}^{(t)})\geq Q({\boldsymbol {\theta }}\mid {\boldsymbol {\theta }}^{(t)})-Q({\boldsymbol {\theta }}^{(t)}\mid {\boldsymbol {\theta }}^{(t)})\,.}" xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="true" scriptlevel="0">
<mi>log</mi>
<mo>⁡<!-- ⁡ --></mo>
<mi>p</mi>
<mo stretchy="false">(</mo>
<mrow class="MJX-TeXAtom-ORD">
<mi mathvariant="bold">X</mi>
</mrow>
<mo>∣<!-- ∣ --></mo>
<mrow class="MJX-TeXAtom-ORD">
<mi mathvariant="bold-italic">θ<!-- θ --></mi>
</mrow>
<mo stretchy="false">)</mo>
<mo>−<!-- − --></mo>
<mi>log</mi>
<mo>⁡<!-- ⁡ --></mo>
<mi>p</mi>
<mo stretchy="false">(</mo>
<mrow class="MJX-TeXAtom-ORD">
<mi mathvariant="bold">X</mi>
</mrow>
<mo>∣<!-- ∣ --></mo>
<msup>
<mrow class="MJX-TeXAtom-ORD">
<mi mathvariant="bold-italic">θ<!-- θ --></mi>
</mrow>
<mrow class="MJX-TeXAtom-ORD">
<mo stretchy="false">(</mo>
<mi>t</mi>
<mo stretchy="false">)</mo>
</mrow>
</msup>
<mo stretchy="false">)</mo>
<mo>≥<!-- ≥ --></mo>
<mi>Q</mi>
<mo stretchy="false">(</mo>
<mrow class="MJX-TeXAtom-ORD">
<mi mathvariant="bold-italic">θ<!-- θ --></mi>
</mrow>
<mo>∣<!-- ∣ --></mo>
<msup>
<mrow class="MJX-TeXAtom-ORD">
<mi mathvariant="bold-italic">θ<!-- θ --></mi>
</mrow>
<mrow class="MJX-TeXAtom-ORD">
<mo stretchy="false">(</mo>
<mi>t</mi>
<mo stretchy="false">)</mo>
</mrow>
</msup>
<mo stretchy="false">)</mo>
<mo>−<!-- − --></mo>
<mi>Q</mi>
<mo stretchy="false">(</mo>
<msup>
<mrow class="MJX-TeXAtom-ORD">
<mi mathvariant="bold-italic">θ<!-- θ --></mi>
</mrow>
<mrow class="MJX-TeXAtom-ORD">
<mo stretchy="false">(</mo>
<mi>t</mi>
<mo stretchy="false">)</mo>
</mrow>
</msup>
<mo>∣<!-- ∣ --></mo>
<msup>
<mrow class="MJX-TeXAtom-ORD">
<mi mathvariant="bold-italic">θ<!-- θ --></mi>
</mrow>
<mrow class="MJX-TeXAtom-ORD">
<mo stretchy="false">(</mo>
<mi>t</mi>
<mo stretchy="false">)</mo>
</mrow>
</msup>
<mo stretchy="false">)</mo>
<mspace width="thinmathspace"></mspace>
<mo>.</mo>
</mstyle>
</mrow>
<annotation encoding="application/x-tex">{\displaystyle \log p(\mathbf {X} \mid {\boldsymbol {\theta }})-\log p(\mathbf {X} \mid {\boldsymbol {\theta }}^{(t)})\geq Q({\boldsymbol {\theta }}\mid {\boldsymbol {\theta }}^{(t)})-Q({\boldsymbol {\theta }}^{(t)}\mid {\boldsymbol {\theta }}^{(t)})\,.}</annotation>
</semantics>
</math></span><img alt="{\displaystyle \log p(\mathbf {X} \mid {\boldsymbol {\theta }})-\log p(\mathbf {X} \mid {\boldsymbol {\theta }}^{(t)})\geq Q({\boldsymbol {\theta }}\mid {\boldsymbol {\theta }}^{(t)})-Q({\boldsymbol {\theta }}^{(t)}\mid {\boldsymbol {\theta }}^{(t)})\,.}" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/8cd76cb865a2c85439d14bd945dc74ca014d1a07" style="vertical-align: -0.838ex; width:57.831ex; height:3.343ex;"/></span></dd></dl></dd></dl>
<p>In words, choosing <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\displaystyle {\boldsymbol {\theta }}}" xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="true" scriptlevel="0">
<mrow class="MJX-TeXAtom-ORD">
<mi mathvariant="bold-italic">θ<!-- θ --></mi>
</mrow>
</mstyle>
</mrow>
<annotation encoding="application/x-tex">{\displaystyle {\boldsymbol {\theta }}}</annotation>
</semantics>
</math></span><img alt="{\boldsymbol {\theta }}" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/33b025a6bf54ec02e65c871dc3e5897c921419cf" style="vertical-align: -0.338ex; width:1.306ex; height:2.176ex;"/></span> to improve <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\displaystyle Q({\boldsymbol {\theta }}\mid {\boldsymbol {\theta }}^{(t)})}" xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="true" scriptlevel="0">
<mi>Q</mi>
<mo stretchy="false">(</mo>
<mrow class="MJX-TeXAtom-ORD">
<mi mathvariant="bold-italic">θ<!-- θ --></mi>
</mrow>
<mo>∣<!-- ∣ --></mo>
<msup>
<mrow class="MJX-TeXAtom-ORD">
<mi mathvariant="bold-italic">θ<!-- θ --></mi>
</mrow>
<mrow class="MJX-TeXAtom-ORD">
<mo stretchy="false">(</mo>
<mi>t</mi>
<mo stretchy="false">)</mo>
</mrow>
</msup>
<mo stretchy="false">)</mo>
</mstyle>
</mrow>
<annotation encoding="application/x-tex">{\displaystyle Q({\boldsymbol {\theta }}\mid {\boldsymbol {\theta }}^{(t)})}</annotation>
</semantics>
</math></span><img alt="{\displaystyle Q({\boldsymbol {\theta }}\mid {\boldsymbol {\theta }}^{(t)})}" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/24d245ae1f551d986964bdcfa59ef4bad70079cb" style="vertical-align: -0.838ex; width:10.303ex; height:3.343ex;"/></span> causes <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\displaystyle \log p(\mathbf {X} \mid {\boldsymbol {\theta }})}" xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="true" scriptlevel="0">
<mi>log</mi>
<mo>⁡<!-- ⁡ --></mo>
<mi>p</mi>
<mo stretchy="false">(</mo>
<mrow class="MJX-TeXAtom-ORD">
<mi mathvariant="bold">X</mi>
</mrow>
<mo>∣<!-- ∣ --></mo>
<mrow class="MJX-TeXAtom-ORD">
<mi mathvariant="bold-italic">θ<!-- θ --></mi>
</mrow>
<mo stretchy="false">)</mo>
</mstyle>
</mrow>
<annotation encoding="application/x-tex">{\displaystyle \log p(\mathbf {X} \mid {\boldsymbol {\theta }})}</annotation>
</semantics>
</math></span><img alt="{\displaystyle \log p(\mathbf {X} \mid {\boldsymbol {\theta }})}" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/3b1c4eed3feeeca1f0a16cf8a0dd57b2ecc5e6e1" style="vertical-align: -0.838ex; width:11.601ex; height:2.843ex;"/></span> to improve at least as much.
</p>
<h2><span id="As_a_maximization.E2.80.93maximization_procedure"></span><span class="mw-headline" id="As_a_maximization–maximization_procedure">As a maximization–maximization procedure</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Expectation%E2%80%93maximization_algorithm&amp;action=edit&amp;section=6" title="Edit section: As a maximization–maximization procedure">edit</a><span class="mw-editsection-bracket">]</span></span></h2>
<p>The EM algorithm can be viewed as two alternating maximization steps, that is, as an example of <a href="/wiki/Coordinate_descent" title="Coordinate descent">coordinate ascent</a>.<sup class="reference" id="cite_ref-neal1999_15-0"><a href="#cite_note-neal1999-15">[15]</a></sup><sup class="reference" id="cite_ref-hastie2001_16-0"><a href="#cite_note-hastie2001-16">[16]</a></sup> Consider the function:
</p>
<dl><dd><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\displaystyle F(q,\theta ):=\operatorname {E} _{q}[\log L(\theta ;x,Z)]+H(q),}" xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="true" scriptlevel="0">
<mi>F</mi>
<mo stretchy="false">(</mo>
<mi>q</mi>
<mo>,</mo>
<mi>θ<!-- θ --></mi>
<mo stretchy="false">)</mo>
<mo>:=</mo>
<msub>
<mi mathvariant="normal">E</mi>
<mrow class="MJX-TeXAtom-ORD">
<mi>q</mi>
</mrow>
</msub>
<mo>⁡<!-- ⁡ --></mo>
<mo stretchy="false">[</mo>
<mi>log</mi>
<mo>⁡<!-- ⁡ --></mo>
<mi>L</mi>
<mo stretchy="false">(</mo>
<mi>θ<!-- θ --></mi>
<mo>;</mo>
<mi>x</mi>
<mo>,</mo>
<mi>Z</mi>
<mo stretchy="false">)</mo>
<mo stretchy="false">]</mo>
<mo>+</mo>
<mi>H</mi>
<mo stretchy="false">(</mo>
<mi>q</mi>
<mo stretchy="false">)</mo>
<mo>,</mo>
</mstyle>
</mrow>
<annotation encoding="application/x-tex">{\displaystyle F(q,\theta ):=\operatorname {E} _{q}[\log L(\theta ;x,Z)]+H(q),}</annotation>
</semantics>
</math></span><img alt="{\displaystyle F(q,\theta ):=\operatorname {E} _{q}[\log L(\theta ;x,Z)]+H(q),}" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/f4e0798985f246154015deb375e1494dfa734922" style="vertical-align: -1.005ex; width:35.704ex; height:3.009ex;"/></span></dd></dl>
<p>where <i>q</i> is an arbitrary probability distribution over the unobserved data <i>z</i> and <i>H(q)</i> is the <a href="/wiki/Entropy_(information_theory)" title="Entropy (information theory)">entropy</a> of the distribution <i>q</i>. This function can be written as
</p>
<dl><dd><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\displaystyle F(q,\theta )=-D_{\mathrm {KL} }{\big (}q\parallel p_{Z\mid X}(\cdot \mid x;\theta ){\big )}+\log L(\theta ;x),}" xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="true" scriptlevel="0">
<mi>F</mi>
<mo stretchy="false">(</mo>
<mi>q</mi>
<mo>,</mo>
<mi>θ<!-- θ --></mi>
<mo stretchy="false">)</mo>
<mo>=</mo>
<mo>−<!-- − --></mo>
<msub>
<mi>D</mi>
<mrow class="MJX-TeXAtom-ORD">
<mrow class="MJX-TeXAtom-ORD">
<mi mathvariant="normal">K</mi>
<mi mathvariant="normal">L</mi>
</mrow>
</mrow>
</msub>
<mrow class="MJX-TeXAtom-ORD">
<mrow class="MJX-TeXAtom-ORD">
<mo maxsize="1.2em" minsize="1.2em">(</mo>
</mrow>
</mrow>
<mi>q</mi>
<mo>∥<!-- ∥ --></mo>
<msub>
<mi>p</mi>
<mrow class="MJX-TeXAtom-ORD">
<mi>Z</mi>
<mo>∣<!-- ∣ --></mo>
<mi>X</mi>
</mrow>
</msub>
<mo stretchy="false">(</mo>
<mo>⋅<!-- ⋅ --></mo>
<mo>∣<!-- ∣ --></mo>
<mi>x</mi>
<mo>;</mo>
<mi>θ<!-- θ --></mi>
<mo stretchy="false">)</mo>
<mrow class="MJX-TeXAtom-ORD">
<mrow class="MJX-TeXAtom-ORD">
<mo maxsize="1.2em" minsize="1.2em">)</mo>
</mrow>
</mrow>
<mo>+</mo>
<mi>log</mi>
<mo>⁡<!-- ⁡ --></mo>
<mi>L</mi>
<mo stretchy="false">(</mo>
<mi>θ<!-- θ --></mi>
<mo>;</mo>
<mi>x</mi>
<mo stretchy="false">)</mo>
<mo>,</mo>
</mstyle>
</mrow>
<annotation encoding="application/x-tex">{\displaystyle F(q,\theta )=-D_{\mathrm {KL} }{\big (}q\parallel p_{Z\mid X}(\cdot \mid x;\theta ){\big )}+\log L(\theta ;x),}</annotation>
</semantics>
</math></span><img alt="{\displaystyle F(q,\theta )=-D_{\mathrm {KL} }{\big (}q\parallel p_{Z\mid X}(\cdot \mid x;\theta ){\big )}+\log L(\theta ;x),}" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/57e86296710dd8d5759ee0d751bb662620b2c13c" style="vertical-align: -1.171ex; width:47.752ex; height:3.343ex;"/></span></dd></dl>
<p>where  <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\displaystyle p_{Z\mid X}(\cdot \mid x;\theta )}" xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="true" scriptlevel="0">
<msub>
<mi>p</mi>
<mrow class="MJX-TeXAtom-ORD">
<mi>Z</mi>
<mo>∣<!-- ∣ --></mo>
<mi>X</mi>
</mrow>
</msub>
<mo stretchy="false">(</mo>
<mo>⋅<!-- ⋅ --></mo>
<mo>∣<!-- ∣ --></mo>
<mi>x</mi>
<mo>;</mo>
<mi>θ<!-- θ --></mi>
<mo stretchy="false">)</mo>
</mstyle>
</mrow>
<annotation encoding="application/x-tex">{\displaystyle p_{Z\mid X}(\cdot \mid x;\theta )}</annotation>
</semantics>
</math></span><img alt="{\displaystyle p_{Z\mid X}(\cdot \mid x;\theta )}" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/5e674aed2f32feeb6eb547964af3618c9c2a9b24" style="vertical-align: -1.171ex; margin-left: -0.089ex; width:12.384ex; height:3.176ex;"/></span> is the conditional distribution of the unobserved data given the observed data <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\displaystyle x}" xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="true" scriptlevel="0">
<mi>x</mi>
</mstyle>
</mrow>
<annotation encoding="application/x-tex">{\displaystyle x}</annotation>
</semantics>
</math></span><img alt="x" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/87f9e315fd7e2ba406057a97300593c4802b53e4" style="vertical-align: -0.338ex; width:1.33ex; height:1.676ex;"/></span> and <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\displaystyle D_{KL}}" xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="true" scriptlevel="0">
<msub>
<mi>D</mi>
<mrow class="MJX-TeXAtom-ORD">
<mi>K</mi>
<mi>L</mi>
</mrow>
</msub>
</mstyle>
</mrow>
<annotation encoding="application/x-tex">{\displaystyle D_{KL}}</annotation>
</semantics>
</math></span><img alt="{\displaystyle D_{KL}}" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/b6eb7f08e9495f990043ebb7a3da95cb9bdb37f2" style="vertical-align: -0.671ex; width:4.737ex; height:2.509ex;"/></span> is the <a href="/wiki/Kullback%E2%80%93Leibler_divergence" title="Kullback–Leibler divergence">Kullback–Leibler divergence</a>.
</p><p>Then the steps in the EM algorithm may be viewed as:
</p>
<dl><dd><i>Expectation step</i>: Choose <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\displaystyle q}" xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="true" scriptlevel="0">
<mi>q</mi>
</mstyle>
</mrow>
<annotation encoding="application/x-tex">{\displaystyle q}</annotation>
</semantics>
</math></span><img alt="q" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/06809d64fa7c817ffc7e323f85997f783dbdf71d" style="vertical-align: -0.671ex; width:1.07ex; height:2.009ex;"/></span> to maximize <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\displaystyle F}" xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="true" scriptlevel="0">
<mi>F</mi>
</mstyle>
</mrow>
<annotation encoding="application/x-tex">{\displaystyle F}</annotation>
</semantics>
</math></span><img alt="F" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/545fd099af8541605f7ee55f08225526be88ce57" style="vertical-align: -0.338ex; width:1.741ex; height:2.176ex;"/></span>:
<dl><dd><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\displaystyle q^{(t)}=\operatorname {arg\,max} _{q}\ F(q,\theta ^{(t)})}" xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="true" scriptlevel="0">
<msup>
<mi>q</mi>
<mrow class="MJX-TeXAtom-ORD">
<mo stretchy="false">(</mo>
<mi>t</mi>
<mo stretchy="false">)</mo>
</mrow>
</msup>
<mo>=</mo>
<msub>
<mrow class="MJX-TeXAtom-OP MJX-fixedlimits">
<mi mathvariant="normal">a</mi>
<mi mathvariant="normal">r</mi>
<mi mathvariant="normal">g</mi>
<mspace width="thinmathspace"></mspace>
<mi mathvariant="normal">m</mi>
<mi mathvariant="normal">a</mi>
<mi mathvariant="normal">x</mi>
</mrow>
<mrow class="MJX-TeXAtom-ORD">
<mi>q</mi>
</mrow>
</msub>
<mo>⁡<!-- ⁡ --></mo>
<mtext> </mtext>
<mi>F</mi>
<mo stretchy="false">(</mo>
<mi>q</mi>
<mo>,</mo>
<msup>
<mi>θ<!-- θ --></mi>
<mrow class="MJX-TeXAtom-ORD">
<mo stretchy="false">(</mo>
<mi>t</mi>
<mo stretchy="false">)</mo>
</mrow>
</msup>
<mo stretchy="false">)</mo>
</mstyle>
</mrow>
<annotation encoding="application/x-tex">{\displaystyle q^{(t)}=\operatorname {arg\,max} _{q}\ F(q,\theta ^{(t)})}</annotation>
</semantics>
</math></span><img alt="{\displaystyle q^{(t)}=\operatorname {arg\,max} _{q}\ F(q,\theta ^{(t)})}" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/ec388559464783fb600754a399c9a6172fa10bee" style="vertical-align: -1.171ex; width:25.038ex; height:3.676ex;"/></span></dd></dl></dd>
<dd><i>Maximization step</i>: Choose <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\displaystyle \theta }" xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="true" scriptlevel="0">
<mi>θ<!-- θ --></mi>
</mstyle>
</mrow>
<annotation encoding="application/x-tex">{\displaystyle \theta }</annotation>
</semantics>
</math></span><img alt="\theta " aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/6e5ab2664b422d53eb0c7df3b87e1360d75ad9af" style="vertical-align: -0.338ex; width:1.09ex; height:2.176ex;"/></span> to maximize <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\displaystyle F}" xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="true" scriptlevel="0">
<mi>F</mi>
</mstyle>
</mrow>
<annotation encoding="application/x-tex">{\displaystyle F}</annotation>
</semantics>
</math></span><img alt="F" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/545fd099af8541605f7ee55f08225526be88ce57" style="vertical-align: -0.338ex; width:1.741ex; height:2.176ex;"/></span>:
<dl><dd><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\displaystyle \theta ^{(t+1)}=\operatorname {arg\,max} _{\theta }\ F(q^{(t)},\theta )}" xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="true" scriptlevel="0">
<msup>
<mi>θ<!-- θ --></mi>
<mrow class="MJX-TeXAtom-ORD">
<mo stretchy="false">(</mo>
<mi>t</mi>
<mo>+</mo>
<mn>1</mn>
<mo stretchy="false">)</mo>
</mrow>
</msup>
<mo>=</mo>
<msub>
<mrow class="MJX-TeXAtom-OP MJX-fixedlimits">
<mi mathvariant="normal">a</mi>
<mi mathvariant="normal">r</mi>
<mi mathvariant="normal">g</mi>
<mspace width="thinmathspace"></mspace>
<mi mathvariant="normal">m</mi>
<mi mathvariant="normal">a</mi>
<mi mathvariant="normal">x</mi>
</mrow>
<mrow class="MJX-TeXAtom-ORD">
<mi>θ<!-- θ --></mi>
</mrow>
</msub>
<mo>⁡<!-- ⁡ --></mo>
<mtext> </mtext>
<mi>F</mi>
<mo stretchy="false">(</mo>
<msup>
<mi>q</mi>
<mrow class="MJX-TeXAtom-ORD">
<mo stretchy="false">(</mo>
<mi>t</mi>
<mo stretchy="false">)</mo>
</mrow>
</msup>
<mo>,</mo>
<mi>θ<!-- θ --></mi>
<mo stretchy="false">)</mo>
</mstyle>
</mrow>
<annotation encoding="application/x-tex">{\displaystyle \theta ^{(t+1)}=\operatorname {arg\,max} _{\theta }\ F(q^{(t)},\theta )}</annotation>
</semantics>
</math></span><img alt="{\displaystyle \theta ^{(t+1)}=\operatorname {arg\,max} _{\theta }\ F(q^{(t)},\theta )}" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/696d87c8260b868730707884aa48c0db4bbaaae4" style="vertical-align: -0.838ex; width:27.175ex; height:3.343ex;"/></span></dd></dl></dd></dl>
<h2><span class="mw-headline" id="Applications">Applications</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Expectation%E2%80%93maximization_algorithm&amp;action=edit&amp;section=7" title="Edit section: Applications">edit</a><span class="mw-editsection-bracket">]</span></span></h2>
<p>EM is frequently used for <a class="mw-redirect" href="/wiki/Data_clustering" title="Data clustering">data clustering</a> in <a href="/wiki/Machine_learning" title="Machine learning">machine learning</a> and <a href="/wiki/Computer_vision" title="Computer vision">computer vision</a>. In <a href="/wiki/Natural_language_processing" title="Natural language processing">natural language processing</a>, two prominent instances of the algorithm are the <a href="/wiki/Baum%E2%80%93Welch_algorithm" title="Baum–Welch algorithm">Baum–Welch algorithm</a> for <a class="mw-redirect" href="/wiki/Hidden_Markov_models" title="Hidden Markov models">hidden Markov models</a>, and the <a class="mw-redirect" href="/wiki/Inside-outside_algorithm" title="Inside-outside algorithm">inside-outside algorithm</a> for unsupervised induction of <a href="/wiki/Probabilistic_context-free_grammar" title="Probabilistic context-free grammar">probabilistic context-free grammars</a>.
</p><p>EM is frequently used for parameter estimation of <a href="/wiki/Mixed_model" title="Mixed model">mixed models</a>,<sup class="reference" id="cite_ref-17"><a href="#cite_note-17">[17]</a></sup><sup class="reference" id="cite_ref-18"><a href="#cite_note-18">[18]</a></sup> notably in <a href="/wiki/Quantitative_genetics" title="Quantitative genetics">quantitative genetics</a>.<sup class="reference" id="cite_ref-19"><a href="#cite_note-19">[19]</a></sup>
</p><p>In <a href="/wiki/Psychometrics" title="Psychometrics">psychometrics</a>, EM is almost indispensable for estimating item parameters and latent abilities of <a href="/wiki/Item_response_theory" title="Item response theory">item response theory</a> models.
</p><p>With the ability to deal with missing data and observe unidentified variables, EM is becoming a useful tool to price and manage risk of a portfolio.<sup class="noprint Inline-Template Template-Fact" style="white-space:nowrap;">[<i><a href="/wiki/Wikipedia:Citation_needed" title="Wikipedia:Citation needed"><span title="This claim needs references to reliable sources. (November 2017)">citation needed</span></a></i>]</sup>
</p><p>The EM algorithm (and its faster variant <a href="/wiki/Ordered_subset_expectation_maximization" title="Ordered subset expectation maximization">ordered subset expectation maximization</a>) is also widely used in <a href="/wiki/Medical_imaging" title="Medical imaging">medical image</a> reconstruction, especially in <a href="/wiki/Positron_emission_tomography" title="Positron emission tomography">positron emission tomography</a>, <a class="mw-redirect" href="/wiki/Single_photon_emission_computed_tomography" title="Single photon emission computed tomography">single photon emission computed tomography</a>, and x-ray <a class="mw-redirect" href="/wiki/Computed_tomography" title="Computed tomography">computed tomography</a>. See below for other faster variants of EM.
</p><p>In <a href="/wiki/Structural_engineering" title="Structural engineering">structural engineering</a>, the Structural Identification using Expectation Maximization (STRIDE)  <sup class="reference" id="cite_ref-20"><a href="#cite_note-20">[20]</a></sup> algorithm is an output-only method for identifying natural vibration properties of a structural system using sensor data (see <a href="/wiki/Operational_Modal_Analysis" title="Operational Modal Analysis">Operational Modal Analysis</a>).
</p>
<h2><span class="mw-headline" id="Filtering_and_smoothing_EM_algorithms">Filtering and smoothing EM algorithms</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Expectation%E2%80%93maximization_algorithm&amp;action=edit&amp;section=8" title="Edit section: Filtering and smoothing EM algorithms">edit</a><span class="mw-editsection-bracket">]</span></span></h2>
<p>A <a href="/wiki/Kalman_filter" title="Kalman filter">Kalman filter</a> is typically used for on-line state estimation and a minimum-variance smoother may be employed for off-line or batch state estimation. However, these minimum-variance solutions require estimates of the state-space model parameters. EM algorithms can be used for solving joint state and parameter estimation problems.
</p><p>Filtering and smoothing EM algorithms arise by repeating this two-step procedure:
</p>
<dl><dt>E-step</dt>
<dd>Operate a Kalman filter or a minimum-variance smoother designed with current parameter estimates to obtain updated state estimates.</dd></dl>
<dl><dt>M-step</dt>
<dd>Use the filtered or smoothed state estimates within maximum-likelihood calculations to obtain updated parameter estimates.</dd></dl>
<p>Suppose that a <a href="/wiki/Kalman_filter" title="Kalman filter">Kalman filter</a> or minimum-variance smoother operates on measurements of a single-input-single-output system that possess additive white noise. An updated measurement noise variance estimate can be obtained from the <a class="mw-redirect" href="/wiki/Maximum_likelihood" title="Maximum likelihood">maximum likelihood</a> calculation
</p>
<dl><dd><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\displaystyle {\widehat {\sigma }}_{v}^{2}={\frac {1}{N}}\sum _{k=1}^{N}{(z_{k}-{\widehat {x}}_{k})}^{2}}" xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="true" scriptlevel="0">
<msubsup>
<mrow class="MJX-TeXAtom-ORD">
<mrow class="MJX-TeXAtom-ORD">
<mover>
<mi>σ<!-- σ --></mi>
<mo>^<!-- ^ --></mo>
</mover>
</mrow>
</mrow>
<mrow class="MJX-TeXAtom-ORD">
<mi>v</mi>
</mrow>
<mrow class="MJX-TeXAtom-ORD">
<mn>2</mn>
</mrow>
</msubsup>
<mo>=</mo>
<mrow class="MJX-TeXAtom-ORD">
<mfrac>
<mn>1</mn>
<mi>N</mi>
</mfrac>
</mrow>
<munderover>
<mo>∑<!-- ∑ --></mo>
<mrow class="MJX-TeXAtom-ORD">
<mi>k</mi>
<mo>=</mo>
<mn>1</mn>
</mrow>
<mrow class="MJX-TeXAtom-ORD">
<mi>N</mi>
</mrow>
</munderover>
<msup>
<mrow class="MJX-TeXAtom-ORD">
<mo stretchy="false">(</mo>
<msub>
<mi>z</mi>
<mrow class="MJX-TeXAtom-ORD">
<mi>k</mi>
</mrow>
</msub>
<mo>−<!-- − --></mo>
<msub>
<mrow class="MJX-TeXAtom-ORD">
<mrow class="MJX-TeXAtom-ORD">
<mover>
<mi>x</mi>
<mo>^<!-- ^ --></mo>
</mover>
</mrow>
</mrow>
<mrow class="MJX-TeXAtom-ORD">
<mi>k</mi>
</mrow>
</msub>
<mo stretchy="false">)</mo>
</mrow>
<mrow class="MJX-TeXAtom-ORD">
<mn>2</mn>
</mrow>
</msup>
</mstyle>
</mrow>
<annotation encoding="application/x-tex">{\displaystyle {\widehat {\sigma }}_{v}^{2}={\frac {1}{N}}\sum _{k=1}^{N}{(z_{k}-{\widehat {x}}_{k})}^{2}}</annotation>
</semantics>
</math></span><img alt="{\displaystyle {\widehat {\sigma }}_{v}^{2}={\frac {1}{N}}\sum _{k=1}^{N}{(z_{k}-{\widehat {x}}_{k})}^{2}}" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/f88452faee0d349f3977b9a4b0a32ac2f7d53d89" style="vertical-align: -3.005ex; width:22.85ex; height:7.343ex;"/></span></dd></dl>
<p>where <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\displaystyle {\widehat {x}}_{k}}" xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="true" scriptlevel="0">
<msub>
<mrow class="MJX-TeXAtom-ORD">
<mrow class="MJX-TeXAtom-ORD">
<mover>
<mi>x</mi>
<mo>^<!-- ^ --></mo>
</mover>
</mrow>
</mrow>
<mrow class="MJX-TeXAtom-ORD">
<mi>k</mi>
</mrow>
</msub>
</mstyle>
</mrow>
<annotation encoding="application/x-tex">{\displaystyle {\widehat {x}}_{k}}</annotation>
</semantics>
</math></span><img alt="{\displaystyle {\widehat {x}}_{k}}" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/a18153ee206f0216802fb91fcaed7ba3a170490a" style="vertical-align: -0.671ex; width:2.464ex; height:2.676ex;"/></span> are scalar output estimates calculated by a filter or a smoother from N scalar measurements <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\displaystyle z_{k}}" xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="true" scriptlevel="0">
<msub>
<mi>z</mi>
<mrow class="MJX-TeXAtom-ORD">
<mi>k</mi>
</mrow>
</msub>
</mstyle>
</mrow>
<annotation encoding="application/x-tex">{\displaystyle z_{k}}</annotation>
</semantics>
</math></span><img alt="z_{k}" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/a51cdfac24f8b95ed711f11ea9502da4087b6a24" style="vertical-align: -0.671ex; width:2.17ex; height:2.009ex;"/></span>. The above update can also be applied to updating a Poisson measurement noise intensity. Similarly, for a first-order auto-regressive process, an updated process noise variance estimate can be calculated by
</p>
<dl><dd><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\displaystyle {\widehat {\sigma }}_{w}^{2}={\frac {1}{N}}\sum _{k=1}^{N}{({\widehat {x}}_{k+1}-{\widehat {F}}{\widehat {x}}_{k})}^{2}}" xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="true" scriptlevel="0">
<msubsup>
<mrow class="MJX-TeXAtom-ORD">
<mrow class="MJX-TeXAtom-ORD">
<mover>
<mi>σ<!-- σ --></mi>
<mo>^<!-- ^ --></mo>
</mover>
</mrow>
</mrow>
<mrow class="MJX-TeXAtom-ORD">
<mi>w</mi>
</mrow>
<mrow class="MJX-TeXAtom-ORD">
<mn>2</mn>
</mrow>
</msubsup>
<mo>=</mo>
<mrow class="MJX-TeXAtom-ORD">
<mfrac>
<mn>1</mn>
<mi>N</mi>
</mfrac>
</mrow>
<munderover>
<mo>∑<!-- ∑ --></mo>
<mrow class="MJX-TeXAtom-ORD">
<mi>k</mi>
<mo>=</mo>
<mn>1</mn>
</mrow>
<mrow class="MJX-TeXAtom-ORD">
<mi>N</mi>
</mrow>
</munderover>
<msup>
<mrow class="MJX-TeXAtom-ORD">
<mo stretchy="false">(</mo>
<msub>
<mrow class="MJX-TeXAtom-ORD">
<mrow class="MJX-TeXAtom-ORD">
<mover>
<mi>x</mi>
<mo>^<!-- ^ --></mo>
</mover>
</mrow>
</mrow>
<mrow class="MJX-TeXAtom-ORD">
<mi>k</mi>
<mo>+</mo>
<mn>1</mn>
</mrow>
</msub>
<mo>−<!-- − --></mo>
<mrow class="MJX-TeXAtom-ORD">
<mrow class="MJX-TeXAtom-ORD">
<mover>
<mi>F</mi>
<mo>^<!-- ^ --></mo>
</mover>
</mrow>
</mrow>
<msub>
<mrow class="MJX-TeXAtom-ORD">
<mrow class="MJX-TeXAtom-ORD">
<mover>
<mi>x</mi>
<mo>^<!-- ^ --></mo>
</mover>
</mrow>
</mrow>
<mrow class="MJX-TeXAtom-ORD">
<mi>k</mi>
</mrow>
</msub>
<mo stretchy="false">)</mo>
</mrow>
<mrow class="MJX-TeXAtom-ORD">
<mn>2</mn>
</mrow>
</msup>
</mstyle>
</mrow>
<annotation encoding="application/x-tex">{\displaystyle {\widehat {\sigma }}_{w}^{2}={\frac {1}{N}}\sum _{k=1}^{N}{({\widehat {x}}_{k+1}-{\widehat {F}}{\widehat {x}}_{k})}^{2}}</annotation>
</semantics>
</math></span><img alt="{\displaystyle {\widehat {\sigma }}_{w}^{2}={\frac {1}{N}}\sum _{k=1}^{N}{({\widehat {x}}_{k+1}-{\widehat {F}}{\widehat {x}}_{k})}^{2}}" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/f245a24721d55f3f2fdef2201a7a5817c6ef9524" style="vertical-align: -3.005ex; width:27.47ex; height:7.343ex;"/></span></dd></dl>
<p>where <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\displaystyle {\widehat {x}}_{k}}" xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="true" scriptlevel="0">
<msub>
<mrow class="MJX-TeXAtom-ORD">
<mrow class="MJX-TeXAtom-ORD">
<mover>
<mi>x</mi>
<mo>^<!-- ^ --></mo>
</mover>
</mrow>
</mrow>
<mrow class="MJX-TeXAtom-ORD">
<mi>k</mi>
</mrow>
</msub>
</mstyle>
</mrow>
<annotation encoding="application/x-tex">{\displaystyle {\widehat {x}}_{k}}</annotation>
</semantics>
</math></span><img alt="{\displaystyle {\widehat {x}}_{k}}" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/a18153ee206f0216802fb91fcaed7ba3a170490a" style="vertical-align: -0.671ex; width:2.464ex; height:2.676ex;"/></span> and <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\displaystyle {\widehat {x}}_{k+1}}" xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="true" scriptlevel="0">
<msub>
<mrow class="MJX-TeXAtom-ORD">
<mrow class="MJX-TeXAtom-ORD">
<mover>
<mi>x</mi>
<mo>^<!-- ^ --></mo>
</mover>
</mrow>
</mrow>
<mrow class="MJX-TeXAtom-ORD">
<mi>k</mi>
<mo>+</mo>
<mn>1</mn>
</mrow>
</msub>
</mstyle>
</mrow>
<annotation encoding="application/x-tex">{\displaystyle {\widehat {x}}_{k+1}}</annotation>
</semantics>
</math></span><img alt="{\displaystyle {\widehat {x}}_{k+1}}" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/74df0419c9808d257d9a4addec6ee67bb8b3d2f3" style="vertical-align: -0.671ex; width:4.565ex; height:2.676ex;"/></span> are scalar state estimates calculated by a filter or a smoother. The updated model coefficient estimate is obtained via
</p>
<dl><dd><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\displaystyle {\widehat {F}}={\frac {\sum _{k=1}^{N}({\widehat {x}}_{k+1}-{\widehat {F}}{\widehat {x}}_{k})}{\sum _{k=1}^{N}{\widehat {x}}_{k}^{2}}}.}" xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="true" scriptlevel="0">
<mrow class="MJX-TeXAtom-ORD">
<mrow class="MJX-TeXAtom-ORD">
<mover>
<mi>F</mi>
<mo>^<!-- ^ --></mo>
</mover>
</mrow>
</mrow>
<mo>=</mo>
<mrow class="MJX-TeXAtom-ORD">
<mfrac>
<mrow>
<munderover>
<mo>∑<!-- ∑ --></mo>
<mrow class="MJX-TeXAtom-ORD">
<mi>k</mi>
<mo>=</mo>
<mn>1</mn>
</mrow>
<mrow class="MJX-TeXAtom-ORD">
<mi>N</mi>
</mrow>
</munderover>
<mo stretchy="false">(</mo>
<msub>
<mrow class="MJX-TeXAtom-ORD">
<mrow class="MJX-TeXAtom-ORD">
<mover>
<mi>x</mi>
<mo>^<!-- ^ --></mo>
</mover>
</mrow>
</mrow>
<mrow class="MJX-TeXAtom-ORD">
<mi>k</mi>
<mo>+</mo>
<mn>1</mn>
</mrow>
</msub>
<mo>−<!-- − --></mo>
<mrow class="MJX-TeXAtom-ORD">
<mrow class="MJX-TeXAtom-ORD">
<mover>
<mi>F</mi>
<mo>^<!-- ^ --></mo>
</mover>
</mrow>
</mrow>
<msub>
<mrow class="MJX-TeXAtom-ORD">
<mrow class="MJX-TeXAtom-ORD">
<mover>
<mi>x</mi>
<mo>^<!-- ^ --></mo>
</mover>
</mrow>
</mrow>
<mrow class="MJX-TeXAtom-ORD">
<mi>k</mi>
</mrow>
</msub>
<mo stretchy="false">)</mo>
</mrow>
<mrow>
<munderover>
<mo>∑<!-- ∑ --></mo>
<mrow class="MJX-TeXAtom-ORD">
<mi>k</mi>
<mo>=</mo>
<mn>1</mn>
</mrow>
<mrow class="MJX-TeXAtom-ORD">
<mi>N</mi>
</mrow>
</munderover>
<msubsup>
<mrow class="MJX-TeXAtom-ORD">
<mrow class="MJX-TeXAtom-ORD">
<mover>
<mi>x</mi>
<mo>^<!-- ^ --></mo>
</mover>
</mrow>
</mrow>
<mrow class="MJX-TeXAtom-ORD">
<mi>k</mi>
</mrow>
<mrow class="MJX-TeXAtom-ORD">
<mn>2</mn>
</mrow>
</msubsup>
</mrow>
</mfrac>
</mrow>
<mo>.</mo>
</mstyle>
</mrow>
<annotation encoding="application/x-tex">{\displaystyle {\widehat {F}}={\frac {\sum _{k=1}^{N}({\widehat {x}}_{k+1}-{\widehat {F}}{\widehat {x}}_{k})}{\sum _{k=1}^{N}{\widehat {x}}_{k}^{2}}}.}</annotation>
</semantics>
</math></span><img alt="{\displaystyle {\widehat {F}}={\frac {\sum _{k=1}^{N}({\widehat {x}}_{k+1}-{\widehat {F}}{\widehat {x}}_{k})}{\sum _{k=1}^{N}{\widehat {x}}_{k}^{2}}}.}" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/fd1658e029365b3cedc36fead646e2f57d89e70e" style="vertical-align: -3.171ex; width:25.644ex; height:7.676ex;"/></span></dd></dl>
<p>The convergence of parameter estimates such as those above are well studied.<sup class="reference" id="cite_ref-21"><a href="#cite_note-21">[21]</a></sup><sup class="reference" id="cite_ref-22"><a href="#cite_note-22">[22]</a></sup><sup class="reference" id="cite_ref-23"><a href="#cite_note-23">[23]</a></sup><sup class="reference" id="cite_ref-24"><a href="#cite_note-24">[24]</a></sup>
</p>
<h2><span class="mw-headline" id="Variants">Variants</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Expectation%E2%80%93maximization_algorithm&amp;action=edit&amp;section=9" title="Edit section: Variants">edit</a><span class="mw-editsection-bracket">]</span></span></h2>
<p>A number of methods have been proposed to accelerate the sometimes slow convergence of the EM algorithm, such as those using <a class="mw-redirect" href="/wiki/Conjugate_gradient" title="Conjugate gradient">conjugate gradient</a> and modified <a href="/wiki/Newton%27s_method" title="Newton's method">Newton's methods</a> (Newton–Raphson).<sup class="reference" id="cite_ref-25"><a href="#cite_note-25">[25]</a></sup> Also, EM can be used with constrained estimation methods.
</p><p><i>Parameter-expanded expectation maximization (PX-EM)</i> algorithm often provides speed up by "us[ing] a `covariance adjustment' to correct the analysis of the M step, capitalising on extra information captured in the imputed complete data".<sup class="reference" id="cite_ref-26"><a href="#cite_note-26">[26]</a></sup>
</p><p><i>Expectation conditional maximization (ECM)</i> replaces each M step with a sequence of conditional maximization (CM) steps in which each parameter <i>θ</i><sub><i>i</i></sub> is maximized individually, conditionally on the other parameters remaining fixed.<sup class="reference" id="cite_ref-27"><a href="#cite_note-27">[27]</a></sup> Itself can be extended into the <i>Expectation conditional maximization either (ECME)</i> algorithm.<sup class="reference" id="cite_ref-28"><a href="#cite_note-28">[28]</a></sup>
</p><p>This idea is further extended in <i>generalized expectation maximization (GEM)</i> algorithm, in which is sought only an increase in the objective function <i>F</i> for both the E step and M step as described in the <a href="#As_a_maximization-maximization_procedure">As a maximization-maximization procedure</a> section.<sup class="reference" id="cite_ref-neal1999_15-1"><a href="#cite_note-neal1999-15">[15]</a></sup> GEM is further developed in a distributed environment and shows promising results.<sup class="reference" id="cite_ref-29"><a href="#cite_note-29">[29]</a></sup>
</p><p>It is also possible to consider the EM algorithm as a subclass of the <b><a href="/wiki/MM_algorithm" title="MM algorithm">MM</a></b> (Majorize/Minimize or Minorize/Maximize, depending on context) algorithm,<sup class="reference" id="cite_ref-30"><a href="#cite_note-30">[30]</a></sup> and therefore use any machinery developed in the more general case.
</p>
<h3><span id=".CE.B1-EM_algorithm"></span><span class="mw-headline" id="α-EM_algorithm">α-EM algorithm</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Expectation%E2%80%93maximization_algorithm&amp;action=edit&amp;section=10" title="Edit section: α-EM algorithm">edit</a><span class="mw-editsection-bracket">]</span></span></h3>
<p>The Q-function used in the EM algorithm is based on the log likelihood. Therefore, it is regarded as the log-EM algorithm. The use of the log likelihood can be generalized to that of the α-log likelihood ratio. Then, the α-log likelihood ratio of the observed data can be exactly expressed as equality by using the Q-function of the α-log likelihood ratio and the α-divergence. Obtaining this Q-function is a generalized E step. Its maximization is a generalized M step. This pair is called the α-EM algorithm
<sup class="reference" id="cite_ref-31"><a href="#cite_note-31">[31]</a></sup>
which contains the log-EM algorithm as its subclass. Thus, the α-EM algorithm by <a href="/wiki/Yasuo_Matsuyama" title="Yasuo Matsuyama">Yasuo Matsuyama</a> is an exact generalization of the log-EM algorithm. No computation of gradient or Hessian matrix is needed. The α-EM shows faster convergence than the log-EM algorithm by choosing an appropriate α. The α-EM algorithm leads to a faster version of the Hidden Markov model estimation algorithm α-HMM.
<sup class="reference" id="cite_ref-32"><a href="#cite_note-32">[32]</a></sup>
</p>
<h2><span class="mw-headline" id="Relation_to_variational_Bayes_methods">Relation to variational Bayes methods</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Expectation%E2%80%93maximization_algorithm&amp;action=edit&amp;section=11" title="Edit section: Relation to variational Bayes methods">edit</a><span class="mw-editsection-bracket">]</span></span></h2>
<p>EM is a partially non-Bayesian, maximum likelihood method.  Its final result gives a <a href="/wiki/Probability_distribution" title="Probability distribution">probability distribution</a> over the latent variables (in the Bayesian style) together with a point estimate for <i>θ</i> (either a <a href="/wiki/Maximum_likelihood_estimation" title="Maximum likelihood estimation">maximum likelihood estimate</a> or a posterior mode). A fully Bayesian version of this may be wanted, giving a probability distribution over <i>θ</i> and the latent variables.  The Bayesian approach to inference is simply to treat <i>θ</i> as another latent variable.  In this paradigm, the distinction between the E and M steps disappears.  If using the factorized Q approximation as described above (<a class="mw-redirect" href="/wiki/Variational_Bayes" title="Variational Bayes">variational Bayes</a>), solving can iterate over each latent variable (now including <i>θ</i>) and optimize them one at a time.  Now, <i>k</i> steps per iteration are needed, where <i>k</i> is the number of latent variables.  For <a class="mw-redirect" href="/wiki/Graphical_models" title="Graphical models">graphical models</a> this is easy to do as each variable's new <i>Q</i> depends only on its <a href="/wiki/Markov_blanket" title="Markov blanket">Markov blanket</a>, so local <a class="mw-disambig" href="/wiki/Message_passing_(disambiguation)" title="Message passing (disambiguation)">message passing</a> can be used for efficient inference.
</p>
<h2><span class="mw-headline" id="Geometric_interpretation">Geometric interpretation</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Expectation%E2%80%93maximization_algorithm&amp;action=edit&amp;section=12" title="Edit section: Geometric interpretation">edit</a><span class="mw-editsection-bracket">]</span></span></h2>
<div class="hatnote navigation-not-searchable" role="note">Further information: <a href="/wiki/Information_geometry" title="Information geometry">Information geometry</a></div>
<p>In <a href="/wiki/Information_geometry" title="Information geometry">information geometry</a>, the E step and the M step are interpreted as projections under dual <a href="/wiki/Affine_connection" title="Affine connection">affine connections</a>, called the e-connection and the m-connection; the <a href="/wiki/Kullback%E2%80%93Leibler_divergence" title="Kullback–Leibler divergence">Kullback–Leibler divergence</a> can also be understood in these terms.
</p>
<h2><span class="mw-headline" id="Examples">Examples</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Expectation%E2%80%93maximization_algorithm&amp;action=edit&amp;section=13" title="Edit section: Examples">edit</a><span class="mw-editsection-bracket">]</span></span></h2>
<h3><span class="mw-headline" id="Gaussian_mixture">Gaussian mixture</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Expectation%E2%80%93maximization_algorithm&amp;action=edit&amp;section=14" title="Edit section: Gaussian mixture">edit</a><span class="mw-editsection-bracket">]</span></span></h3>
<div class="thumb tright"><div class="thumbinner" style="width:402px;"><a class="image" href="/wiki/File:ClusterAnalysis_Mouse.svg"><img alt="" class="thumbimage" data-file-height="547" data-file-width="1355" decoding="async" height="161" src="//upload.wikimedia.org/wikipedia/commons/thumb/0/09/ClusterAnalysis_Mouse.svg/400px-ClusterAnalysis_Mouse.svg.png" srcset="//upload.wikimedia.org/wikipedia/commons/thumb/0/09/ClusterAnalysis_Mouse.svg/600px-ClusterAnalysis_Mouse.svg.png 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/0/09/ClusterAnalysis_Mouse.svg/800px-ClusterAnalysis_Mouse.svg.png 2x" width="400"/></a> <div class="thumbcaption"><div class="magnify"><a class="internal" href="/wiki/File:ClusterAnalysis_Mouse.svg" title="Enlarge"></a></div>Comparison of <a href="/wiki/K-means_clustering" title="K-means clustering">k-means</a> and EM on artificial data  visualized with <a class="mw-redirect" href="/wiki/Environment_for_DeveLoping_KDD-Applications_Supported_by_Index-Structures" title="Environment for DeveLoping KDD-Applications Supported by Index-Structures">ELKI</a>. Using the variances, the EM algorithm can describe the normal distributions exactly, while k-means splits the data in <a href="/wiki/Voronoi_diagram" title="Voronoi diagram">Voronoi</a>-cells. The cluster center is indicated by the lighter, bigger symbol.</div></div></div>
<div class="thumb tright"><div class="thumbinner" style="width:242px;"><a class="image" href="/wiki/File:Em_old_faithful.gif"><img alt="" class="thumbimage" data-file-height="360" data-file-width="360" decoding="async" height="240" src="//upload.wikimedia.org/wikipedia/commons/thumb/a/a7/Em_old_faithful.gif/240px-Em_old_faithful.gif" srcset="//upload.wikimedia.org/wikipedia/commons/a/a7/Em_old_faithful.gif 1.5x" width="240"/></a> <div class="thumbcaption"><div class="magnify"><a class="internal" href="/wiki/File:Em_old_faithful.gif" title="Enlarge"></a></div>An animation demonstrating the EM algorithm fitting a two component Gaussian <a href="/wiki/Mixture_model" title="Mixture model">mixture model</a> to the <a href="/wiki/Old_Faithful" title="Old Faithful">Old Faithful</a> dataset. The algorithm steps through from a random initialization to convergence.</div></div></div>
<p>Let <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\displaystyle \mathbf {x} =(\mathbf {x} _{1},\mathbf {x} _{2},\ldots ,\mathbf {x} _{n})}" xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="true" scriptlevel="0">
<mrow class="MJX-TeXAtom-ORD">
<mi mathvariant="bold">x</mi>
</mrow>
<mo>=</mo>
<mo stretchy="false">(</mo>
<msub>
<mrow class="MJX-TeXAtom-ORD">
<mi mathvariant="bold">x</mi>
</mrow>
<mrow class="MJX-TeXAtom-ORD">
<mn>1</mn>
</mrow>
</msub>
<mo>,</mo>
<msub>
<mrow class="MJX-TeXAtom-ORD">
<mi mathvariant="bold">x</mi>
</mrow>
<mrow class="MJX-TeXAtom-ORD">
<mn>2</mn>
</mrow>
</msub>
<mo>,</mo>
<mo>…<!-- … --></mo>
<mo>,</mo>
<msub>
<mrow class="MJX-TeXAtom-ORD">
<mi mathvariant="bold">x</mi>
</mrow>
<mrow class="MJX-TeXAtom-ORD">
<mi>n</mi>
</mrow>
</msub>
<mo stretchy="false">)</mo>
</mstyle>
</mrow>
<annotation encoding="application/x-tex">{\displaystyle \mathbf {x} =(\mathbf {x} _{1},\mathbf {x} _{2},\ldots ,\mathbf {x} _{n})}</annotation>
</semantics>
</math></span><img alt="\mathbf{x} = (\mathbf{x}_1,\mathbf{x}_2,\ldots,\mathbf{x}_n)" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/61e9345a73e716032dfe920da2ef9d9265e6226b" style="vertical-align: -0.838ex; width:20.091ex; height:2.843ex;"/></span> be a sample of <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\displaystyle n}" xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="true" scriptlevel="0">
<mi>n</mi>
</mstyle>
</mrow>
<annotation encoding="application/x-tex">{\displaystyle n}</annotation>
</semantics>
</math></span><img alt="n" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/a601995d55609f2d9f5e233e36fbe9ea26011b3b" style="vertical-align: -0.338ex; width:1.395ex; height:1.676ex;"/></span> independent observations from a <a href="/wiki/Mixture_model" title="Mixture model">mixture</a> of two <a href="/wiki/Multivariate_normal_distribution" title="Multivariate normal distribution">multivariate normal distributions</a> of dimension <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\displaystyle d}" xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="true" scriptlevel="0">
<mi>d</mi>
</mstyle>
</mrow>
<annotation encoding="application/x-tex">{\displaystyle d}</annotation>
</semantics>
</math></span><img alt="d" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/e85ff03cbe0c7341af6b982e47e9f90d235c66ab" style="vertical-align: -0.338ex; width:1.216ex; height:2.176ex;"/></span>, and let <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\displaystyle \mathbf {z} =(z_{1},z_{2},\ldots ,z_{n})}" xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="true" scriptlevel="0">
<mrow class="MJX-TeXAtom-ORD">
<mi mathvariant="bold">z</mi>
</mrow>
<mo>=</mo>
<mo stretchy="false">(</mo>
<msub>
<mi>z</mi>
<mrow class="MJX-TeXAtom-ORD">
<mn>1</mn>
</mrow>
</msub>
<mo>,</mo>
<msub>
<mi>z</mi>
<mrow class="MJX-TeXAtom-ORD">
<mn>2</mn>
</mrow>
</msub>
<mo>,</mo>
<mo>…<!-- … --></mo>
<mo>,</mo>
<msub>
<mi>z</mi>
<mrow class="MJX-TeXAtom-ORD">
<mi>n</mi>
</mrow>
</msub>
<mo stretchy="false">)</mo>
</mstyle>
</mrow>
<annotation encoding="application/x-tex">{\displaystyle \mathbf {z} =(z_{1},z_{2},\ldots ,z_{n})}</annotation>
</semantics>
</math></span><img alt="\mathbf{z} = (z_1,z_2,\ldots,z_n)" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/394a19c373675e608117295cd6415e84f06eaaeb" style="vertical-align: -0.838ex; width:18.878ex; height:2.843ex;"/></span> be the latent variables that determine the component from which the observation originates.<sup class="reference" id="cite_ref-hastie2001_16-1"><a href="#cite_note-hastie2001-16">[16]</a></sup>
</p>
<dl><dd><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\displaystyle X_{i}\mid (Z_{i}=1)\sim {\mathcal {N}}_{d}({\boldsymbol {\mu }}_{1},\Sigma _{1})}" xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="true" scriptlevel="0">
<msub>
<mi>X</mi>
<mrow class="MJX-TeXAtom-ORD">
<mi>i</mi>
</mrow>
</msub>
<mo>∣<!-- ∣ --></mo>
<mo stretchy="false">(</mo>
<msub>
<mi>Z</mi>
<mrow class="MJX-TeXAtom-ORD">
<mi>i</mi>
</mrow>
</msub>
<mo>=</mo>
<mn>1</mn>
<mo stretchy="false">)</mo>
<mo>∼<!-- ∼ --></mo>
<msub>
<mrow class="MJX-TeXAtom-ORD">
<mrow class="MJX-TeXAtom-ORD">
<mi class="MJX-tex-caligraphic" mathvariant="script">N</mi>
</mrow>
</mrow>
<mrow class="MJX-TeXAtom-ORD">
<mi>d</mi>
</mrow>
</msub>
<mo stretchy="false">(</mo>
<msub>
<mrow class="MJX-TeXAtom-ORD">
<mi mathvariant="bold-italic">μ<!-- μ --></mi>
</mrow>
<mrow class="MJX-TeXAtom-ORD">
<mn>1</mn>
</mrow>
</msub>
<mo>,</mo>
<msub>
<mi mathvariant="normal">Σ<!-- Σ --></mi>
<mrow class="MJX-TeXAtom-ORD">
<mn>1</mn>
</mrow>
</msub>
<mo stretchy="false">)</mo>
</mstyle>
</mrow>
<annotation encoding="application/x-tex">{\displaystyle X_{i}\mid (Z_{i}=1)\sim {\mathcal {N}}_{d}({\boldsymbol {\mu }}_{1},\Sigma _{1})}</annotation>
</semantics>
</math></span><img alt="{\displaystyle X_{i}\mid (Z_{i}=1)\sim {\mathcal {N}}_{d}({\boldsymbol {\mu }}_{1},\Sigma _{1})}" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/e88d94caf64a6cc0cd17d33538f6dbf959fa023b" style="vertical-align: -0.838ex; width:27.49ex; height:3.009ex;"/></span> and <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\displaystyle X_{i}\mid (Z_{i}=2)\sim {\mathcal {N}}_{d}({\boldsymbol {\mu }}_{2},\Sigma _{2})}" xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="true" scriptlevel="0">
<msub>
<mi>X</mi>
<mrow class="MJX-TeXAtom-ORD">
<mi>i</mi>
</mrow>
</msub>
<mo>∣<!-- ∣ --></mo>
<mo stretchy="false">(</mo>
<msub>
<mi>Z</mi>
<mrow class="MJX-TeXAtom-ORD">
<mi>i</mi>
</mrow>
</msub>
<mo>=</mo>
<mn>2</mn>
<mo stretchy="false">)</mo>
<mo>∼<!-- ∼ --></mo>
<msub>
<mrow class="MJX-TeXAtom-ORD">
<mrow class="MJX-TeXAtom-ORD">
<mi class="MJX-tex-caligraphic" mathvariant="script">N</mi>
</mrow>
</mrow>
<mrow class="MJX-TeXAtom-ORD">
<mi>d</mi>
</mrow>
</msub>
<mo stretchy="false">(</mo>
<msub>
<mrow class="MJX-TeXAtom-ORD">
<mi mathvariant="bold-italic">μ<!-- μ --></mi>
</mrow>
<mrow class="MJX-TeXAtom-ORD">
<mn>2</mn>
</mrow>
</msub>
<mo>,</mo>
<msub>
<mi mathvariant="normal">Σ<!-- Σ --></mi>
<mrow class="MJX-TeXAtom-ORD">
<mn>2</mn>
</mrow>
</msub>
<mo stretchy="false">)</mo>
</mstyle>
</mrow>
<annotation encoding="application/x-tex">{\displaystyle X_{i}\mid (Z_{i}=2)\sim {\mathcal {N}}_{d}({\boldsymbol {\mu }}_{2},\Sigma _{2})}</annotation>
</semantics>
</math></span><img alt="{\displaystyle X_{i}\mid (Z_{i}=2)\sim {\mathcal {N}}_{d}({\boldsymbol {\mu }}_{2},\Sigma _{2})}" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/1d91e601537505a092d5d8ff1adabbef3b3b069f" style="vertical-align: -0.838ex; width:27.49ex; height:3.009ex;"/></span></dd></dl>
<p>where
</p>
<dl><dd><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\displaystyle \operatorname {P} (Z_{i}=1)=\tau _{1}\,}" xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="true" scriptlevel="0">
<mi mathvariant="normal">P</mi>
<mo>⁡<!-- ⁡ --></mo>
<mo stretchy="false">(</mo>
<msub>
<mi>Z</mi>
<mrow class="MJX-TeXAtom-ORD">
<mi>i</mi>
</mrow>
</msub>
<mo>=</mo>
<mn>1</mn>
<mo stretchy="false">)</mo>
<mo>=</mo>
<msub>
<mi>τ<!-- τ --></mi>
<mrow class="MJX-TeXAtom-ORD">
<mn>1</mn>
</mrow>
</msub>
<mspace width="thinmathspace"></mspace>
</mstyle>
</mrow>
<annotation encoding="application/x-tex">{\displaystyle \operatorname {P} (Z_{i}=1)=\tau _{1}\,}</annotation>
</semantics>
</math></span><img alt="\operatorname{P} (Z_i = 1 ) = \tau_1 \, " aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/9ee708039dc8c18644060681372da6736ecec2ba" style="vertical-align: -0.838ex; width:15.596ex; height:2.843ex;"/></span> and <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\displaystyle \operatorname {P} (Z_{i}=2)=\tau _{2}=1-\tau _{1}}" xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="true" scriptlevel="0">
<mi mathvariant="normal">P</mi>
<mo>⁡<!-- ⁡ --></mo>
<mo stretchy="false">(</mo>
<msub>
<mi>Z</mi>
<mrow class="MJX-TeXAtom-ORD">
<mi>i</mi>
</mrow>
</msub>
<mo>=</mo>
<mn>2</mn>
<mo stretchy="false">)</mo>
<mo>=</mo>
<msub>
<mi>τ<!-- τ --></mi>
<mrow class="MJX-TeXAtom-ORD">
<mn>2</mn>
</mrow>
</msub>
<mo>=</mo>
<mn>1</mn>
<mo>−<!-- − --></mo>
<msub>
<mi>τ<!-- τ --></mi>
<mrow class="MJX-TeXAtom-ORD">
<mn>1</mn>
</mrow>
</msub>
</mstyle>
</mrow>
<annotation encoding="application/x-tex">{\displaystyle \operatorname {P} (Z_{i}=2)=\tau _{2}=1-\tau _{1}}</annotation>
</semantics>
</math></span><img alt="\operatorname{P} (Z_i=2) = \tau_2 = 1-\tau_1" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/cdb1a54f58a987ea4dd9ee69cea557b482335adc" style="vertical-align: -0.838ex; width:24.381ex; height:2.843ex;"/></span></dd></dl>
<p>The aim is to estimate the unknown parameters representing the <i>mixing</i> value between the Gaussians and the means and covariances of each:
</p>
<dl><dd><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\displaystyle \theta ={\big (}{\boldsymbol {\tau }},{\boldsymbol {\mu }}_{1},{\boldsymbol {\mu }}_{2},\Sigma _{1},\Sigma _{2}{\big )}}" xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="true" scriptlevel="0">
<mi>θ<!-- θ --></mi>
<mo>=</mo>
<mrow class="MJX-TeXAtom-ORD">
<mrow class="MJX-TeXAtom-ORD">
<mo maxsize="1.2em" minsize="1.2em">(</mo>
</mrow>
</mrow>
<mrow class="MJX-TeXAtom-ORD">
<mi mathvariant="bold-italic">τ<!-- τ --></mi>
</mrow>
<mo>,</mo>
<msub>
<mrow class="MJX-TeXAtom-ORD">
<mi mathvariant="bold-italic">μ<!-- μ --></mi>
</mrow>
<mrow class="MJX-TeXAtom-ORD">
<mn>1</mn>
</mrow>
</msub>
<mo>,</mo>
<msub>
<mrow class="MJX-TeXAtom-ORD">
<mi mathvariant="bold-italic">μ<!-- μ --></mi>
</mrow>
<mrow class="MJX-TeXAtom-ORD">
<mn>2</mn>
</mrow>
</msub>
<mo>,</mo>
<msub>
<mi mathvariant="normal">Σ<!-- Σ --></mi>
<mrow class="MJX-TeXAtom-ORD">
<mn>1</mn>
</mrow>
</msub>
<mo>,</mo>
<msub>
<mi mathvariant="normal">Σ<!-- Σ --></mi>
<mrow class="MJX-TeXAtom-ORD">
<mn>2</mn>
</mrow>
</msub>
<mrow class="MJX-TeXAtom-ORD">
<mrow class="MJX-TeXAtom-ORD">
<mo maxsize="1.2em" minsize="1.2em">)</mo>
</mrow>
</mrow>
</mstyle>
</mrow>
<annotation encoding="application/x-tex">{\displaystyle \theta ={\big (}{\boldsymbol {\tau }},{\boldsymbol {\mu }}_{1},{\boldsymbol {\mu }}_{2},\Sigma _{1},\Sigma _{2}{\big )}}</annotation>
</semantics>
</math></span><img alt="\theta = \big( \boldsymbol{\tau},\boldsymbol{\mu}_1,\boldsymbol{\mu}_2,\Sigma_1,\Sigma_2 \big)" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/06d98dd27999faba8b6e5bd1d113a01ab4840b28" style="vertical-align: -1.005ex; width:22.737ex; height:3.176ex;"/></span></dd></dl>
<p>where the incomplete-data likelihood function is
</p>
<dl><dd><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\displaystyle L(\theta ;\mathbf {x} )=\prod _{i=1}^{n}\sum _{j=1}^{2}\tau _{j}\ f(\mathbf {x} _{i};{\boldsymbol {\mu }}_{j},\Sigma _{j})}" xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="true" scriptlevel="0">
<mi>L</mi>
<mo stretchy="false">(</mo>
<mi>θ<!-- θ --></mi>
<mo>;</mo>
<mrow class="MJX-TeXAtom-ORD">
<mi mathvariant="bold">x</mi>
</mrow>
<mo stretchy="false">)</mo>
<mo>=</mo>
<munderover>
<mo>∏<!-- ∏ --></mo>
<mrow class="MJX-TeXAtom-ORD">
<mi>i</mi>
<mo>=</mo>
<mn>1</mn>
</mrow>
<mrow class="MJX-TeXAtom-ORD">
<mi>n</mi>
</mrow>
</munderover>
<munderover>
<mo>∑<!-- ∑ --></mo>
<mrow class="MJX-TeXAtom-ORD">
<mi>j</mi>
<mo>=</mo>
<mn>1</mn>
</mrow>
<mrow class="MJX-TeXAtom-ORD">
<mn>2</mn>
</mrow>
</munderover>
<msub>
<mi>τ<!-- τ --></mi>
<mrow class="MJX-TeXAtom-ORD">
<mi>j</mi>
</mrow>
</msub>
<mtext> </mtext>
<mi>f</mi>
<mo stretchy="false">(</mo>
<msub>
<mrow class="MJX-TeXAtom-ORD">
<mi mathvariant="bold">x</mi>
</mrow>
<mrow class="MJX-TeXAtom-ORD">
<mi>i</mi>
</mrow>
</msub>
<mo>;</mo>
<msub>
<mrow class="MJX-TeXAtom-ORD">
<mi mathvariant="bold-italic">μ<!-- μ --></mi>
</mrow>
<mrow class="MJX-TeXAtom-ORD">
<mi>j</mi>
</mrow>
</msub>
<mo>,</mo>
<msub>
<mi mathvariant="normal">Σ<!-- Σ --></mi>
<mrow class="MJX-TeXAtom-ORD">
<mi>j</mi>
</mrow>
</msub>
<mo stretchy="false">)</mo>
</mstyle>
</mrow>
<annotation encoding="application/x-tex">{\displaystyle L(\theta ;\mathbf {x} )=\prod _{i=1}^{n}\sum _{j=1}^{2}\tau _{j}\ f(\mathbf {x} _{i};{\boldsymbol {\mu }}_{j},\Sigma _{j})}</annotation>
</semantics>
</math></span><img alt="L(\theta ;{\mathbf  {x}})=\prod _{{i=1}}^{n}\sum _{{j=1}}^{2}\tau _{j}\ f({\mathbf  {x}}_{i};{\boldsymbol  {\mu }}_{j},\Sigma _{j})" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/999ee469d5b538f565bf53a2fb889502466a2401" style="vertical-align: -3.338ex; width:32.141ex; height:7.676ex;"/></span>,</dd></dl>
<p>and the complete-data likelihood function is
</p>
<dl><dd><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\displaystyle L(\theta ;\mathbf {x} ,\mathbf {z} )=p(\mathbf {x} ,\mathbf {z} \mid \theta )=\prod _{i=1}^{n}\prod _{j=1}^{2}\ [f(\mathbf {x} _{i};{\boldsymbol {\mu }}_{j},\Sigma _{j})\tau _{j}]^{\mathbb {I} (z_{i}=j)}}" xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="true" scriptlevel="0">
<mi>L</mi>
<mo stretchy="false">(</mo>
<mi>θ<!-- θ --></mi>
<mo>;</mo>
<mrow class="MJX-TeXAtom-ORD">
<mi mathvariant="bold">x</mi>
</mrow>
<mo>,</mo>
<mrow class="MJX-TeXAtom-ORD">
<mi mathvariant="bold">z</mi>
</mrow>
<mo stretchy="false">)</mo>
<mo>=</mo>
<mi>p</mi>
<mo stretchy="false">(</mo>
<mrow class="MJX-TeXAtom-ORD">
<mi mathvariant="bold">x</mi>
</mrow>
<mo>,</mo>
<mrow class="MJX-TeXAtom-ORD">
<mi mathvariant="bold">z</mi>
</mrow>
<mo>∣<!-- ∣ --></mo>
<mi>θ<!-- θ --></mi>
<mo stretchy="false">)</mo>
<mo>=</mo>
<munderover>
<mo>∏<!-- ∏ --></mo>
<mrow class="MJX-TeXAtom-ORD">
<mi>i</mi>
<mo>=</mo>
<mn>1</mn>
</mrow>
<mrow class="MJX-TeXAtom-ORD">
<mi>n</mi>
</mrow>
</munderover>
<munderover>
<mo>∏<!-- ∏ --></mo>
<mrow class="MJX-TeXAtom-ORD">
<mi>j</mi>
<mo>=</mo>
<mn>1</mn>
</mrow>
<mrow class="MJX-TeXAtom-ORD">
<mn>2</mn>
</mrow>
</munderover>
<mtext> </mtext>
<mo stretchy="false">[</mo>
<mi>f</mi>
<mo stretchy="false">(</mo>
<msub>
<mrow class="MJX-TeXAtom-ORD">
<mi mathvariant="bold">x</mi>
</mrow>
<mrow class="MJX-TeXAtom-ORD">
<mi>i</mi>
</mrow>
</msub>
<mo>;</mo>
<msub>
<mrow class="MJX-TeXAtom-ORD">
<mi mathvariant="bold-italic">μ<!-- μ --></mi>
</mrow>
<mrow class="MJX-TeXAtom-ORD">
<mi>j</mi>
</mrow>
</msub>
<mo>,</mo>
<msub>
<mi mathvariant="normal">Σ<!-- Σ --></mi>
<mrow class="MJX-TeXAtom-ORD">
<mi>j</mi>
</mrow>
</msub>
<mo stretchy="false">)</mo>
<msub>
<mi>τ<!-- τ --></mi>
<mrow class="MJX-TeXAtom-ORD">
<mi>j</mi>
</mrow>
</msub>
<msup>
<mo stretchy="false">]</mo>
<mrow class="MJX-TeXAtom-ORD">
<mrow class="MJX-TeXAtom-ORD">
<mi mathvariant="double-struck">I</mi>
</mrow>
<mo stretchy="false">(</mo>
<msub>
<mi>z</mi>
<mrow class="MJX-TeXAtom-ORD">
<mi>i</mi>
</mrow>
</msub>
<mo>=</mo>
<mi>j</mi>
<mo stretchy="false">)</mo>
</mrow>
</msup>
</mstyle>
</mrow>
<annotation encoding="application/x-tex">{\displaystyle L(\theta ;\mathbf {x} ,\mathbf {z} )=p(\mathbf {x} ,\mathbf {z} \mid \theta )=\prod _{i=1}^{n}\prod _{j=1}^{2}\ [f(\mathbf {x} _{i};{\boldsymbol {\mu }}_{j},\Sigma _{j})\tau _{j}]^{\mathbb {I} (z_{i}=j)}}</annotation>
</semantics>
</math></span><img alt="{\displaystyle L(\theta ;\mathbf {x} ,\mathbf {z} )=p(\mathbf {x} ,\mathbf {z} \mid \theta )=\prod _{i=1}^{n}\prod _{j=1}^{2}\ [f(\mathbf {x} _{i};{\boldsymbol {\mu }}_{j},\Sigma _{j})\tau _{j}]^{\mathbb {I} (z_{i}=j)}}" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/7b416f9e20a8f759624c630df6bc8ec68f081496" style="vertical-align: -3.338ex; width:53.505ex; height:7.676ex;"/></span></dd></dl>
<p>or
</p>
<dl><dd><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\displaystyle L(\theta ;\mathbf {x} ,\mathbf {z} )=\exp \left\{\sum _{i=1}^{n}\sum _{j=1}^{2}\mathbb {I} (z_{i}=j){\big [}\log \tau _{j}-{\tfrac {1}{2}}\log |\Sigma _{j}|-{\tfrac {1}{2}}(\mathbf {x} _{i}-{\boldsymbol {\mu }}_{j})^{\top }\Sigma _{j}^{-1}(\mathbf {x} _{i}-{\boldsymbol {\mu }}_{j})-{\tfrac {d}{2}}\log(2\pi ){\big ]}\right\}.}" xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="true" scriptlevel="0">
<mi>L</mi>
<mo stretchy="false">(</mo>
<mi>θ<!-- θ --></mi>
<mo>;</mo>
<mrow class="MJX-TeXAtom-ORD">
<mi mathvariant="bold">x</mi>
</mrow>
<mo>,</mo>
<mrow class="MJX-TeXAtom-ORD">
<mi mathvariant="bold">z</mi>
</mrow>
<mo stretchy="false">)</mo>
<mo>=</mo>
<mi>exp</mi>
<mo>⁡<!-- ⁡ --></mo>
<mrow>
<mo>{</mo>
<mrow>
<munderover>
<mo>∑<!-- ∑ --></mo>
<mrow class="MJX-TeXAtom-ORD">
<mi>i</mi>
<mo>=</mo>
<mn>1</mn>
</mrow>
<mrow class="MJX-TeXAtom-ORD">
<mi>n</mi>
</mrow>
</munderover>
<munderover>
<mo>∑<!-- ∑ --></mo>
<mrow class="MJX-TeXAtom-ORD">
<mi>j</mi>
<mo>=</mo>
<mn>1</mn>
</mrow>
<mrow class="MJX-TeXAtom-ORD">
<mn>2</mn>
</mrow>
</munderover>
<mrow class="MJX-TeXAtom-ORD">
<mi mathvariant="double-struck">I</mi>
</mrow>
<mo stretchy="false">(</mo>
<msub>
<mi>z</mi>
<mrow class="MJX-TeXAtom-ORD">
<mi>i</mi>
</mrow>
</msub>
<mo>=</mo>
<mi>j</mi>
<mo stretchy="false">)</mo>
<mrow class="MJX-TeXAtom-ORD">
<mrow class="MJX-TeXAtom-ORD">
<mo maxsize="1.2em" minsize="1.2em">[</mo>
</mrow>
</mrow>
<mi>log</mi>
<mo>⁡<!-- ⁡ --></mo>
<msub>
<mi>τ<!-- τ --></mi>
<mrow class="MJX-TeXAtom-ORD">
<mi>j</mi>
</mrow>
</msub>
<mo>−<!-- − --></mo>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="false" scriptlevel="0">
<mfrac>
<mn>1</mn>
<mn>2</mn>
</mfrac>
</mstyle>
</mrow>
<mi>log</mi>
<mo>⁡<!-- ⁡ --></mo>
<mrow class="MJX-TeXAtom-ORD">
<mo stretchy="false">|</mo>
</mrow>
<msub>
<mi mathvariant="normal">Σ<!-- Σ --></mi>
<mrow class="MJX-TeXAtom-ORD">
<mi>j</mi>
</mrow>
</msub>
<mrow class="MJX-TeXAtom-ORD">
<mo stretchy="false">|</mo>
</mrow>
<mo>−<!-- − --></mo>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="false" scriptlevel="0">
<mfrac>
<mn>1</mn>
<mn>2</mn>
</mfrac>
</mstyle>
</mrow>
<mo stretchy="false">(</mo>
<msub>
<mrow class="MJX-TeXAtom-ORD">
<mi mathvariant="bold">x</mi>
</mrow>
<mrow class="MJX-TeXAtom-ORD">
<mi>i</mi>
</mrow>
</msub>
<mo>−<!-- − --></mo>
<msub>
<mrow class="MJX-TeXAtom-ORD">
<mi mathvariant="bold-italic">μ<!-- μ --></mi>
</mrow>
<mrow class="MJX-TeXAtom-ORD">
<mi>j</mi>
</mrow>
</msub>
<msup>
<mo stretchy="false">)</mo>
<mrow class="MJX-TeXAtom-ORD">
<mi mathvariant="normal">⊤<!-- ⊤ --></mi>
</mrow>
</msup>
<msubsup>
<mi mathvariant="normal">Σ<!-- Σ --></mi>
<mrow class="MJX-TeXAtom-ORD">
<mi>j</mi>
</mrow>
<mrow class="MJX-TeXAtom-ORD">
<mo>−<!-- − --></mo>
<mn>1</mn>
</mrow>
</msubsup>
<mo stretchy="false">(</mo>
<msub>
<mrow class="MJX-TeXAtom-ORD">
<mi mathvariant="bold">x</mi>
</mrow>
<mrow class="MJX-TeXAtom-ORD">
<mi>i</mi>
</mrow>
</msub>
<mo>−<!-- − --></mo>
<msub>
<mrow class="MJX-TeXAtom-ORD">
<mi mathvariant="bold-italic">μ<!-- μ --></mi>
</mrow>
<mrow class="MJX-TeXAtom-ORD">
<mi>j</mi>
</mrow>
</msub>
<mo stretchy="false">)</mo>
<mo>−<!-- − --></mo>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="false" scriptlevel="0">
<mfrac>
<mi>d</mi>
<mn>2</mn>
</mfrac>
</mstyle>
</mrow>
<mi>log</mi>
<mo>⁡<!-- ⁡ --></mo>
<mo stretchy="false">(</mo>
<mn>2</mn>
<mi>π<!-- π --></mi>
<mo stretchy="false">)</mo>
<mrow class="MJX-TeXAtom-ORD">
<mrow class="MJX-TeXAtom-ORD">
<mo maxsize="1.2em" minsize="1.2em">]</mo>
</mrow>
</mrow>
</mrow>
<mo>}</mo>
</mrow>
<mo>.</mo>
</mstyle>
</mrow>
<annotation encoding="application/x-tex">{\displaystyle L(\theta ;\mathbf {x} ,\mathbf {z} )=\exp \left\{\sum _{i=1}^{n}\sum _{j=1}^{2}\mathbb {I} (z_{i}=j){\big [}\log \tau _{j}-{\tfrac {1}{2}}\log |\Sigma _{j}|-{\tfrac {1}{2}}(\mathbf {x} _{i}-{\boldsymbol {\mu }}_{j})^{\top }\Sigma _{j}^{-1}(\mathbf {x} _{i}-{\boldsymbol {\mu }}_{j})-{\tfrac {d}{2}}\log(2\pi ){\big ]}\right\}.}</annotation>
</semantics>
</math></span><img alt="L(\theta;\mathbf{x},\mathbf{z}) = \exp \left\{ \sum_{i=1}^n \sum_{j=1}^2 \mathbb{I}(z_i=j) \big[ \log \tau_j -\tfrac{1}{2} \log |\Sigma_j| -\tfrac{1}{2}(\mathbf{x}_i-\boldsymbol{\mu}_j)^\top\Sigma_j^{-1} (\mathbf{x}_i-\boldsymbol{\mu}_j) -\tfrac{d}{2} \log(2\pi) \big] \right\}. " aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/1a8e067d27d7a13e113f6ae490f0e63270b819ac" style="vertical-align: -3.338ex; width:97.116ex; height:7.676ex;"/></span></dd></dl>
<p>where <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\displaystyle \mathbb {I} }" xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="true" scriptlevel="0">
<mrow class="MJX-TeXAtom-ORD">
<mi mathvariant="double-struck">I</mi>
</mrow>
</mstyle>
</mrow>
<annotation encoding="application/x-tex">{\displaystyle \mathbb {I} }</annotation>
</semantics>
</math></span><img alt="\mathbb {I} " aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/8205f06e0d279689ed04a1ac04a3d9c249c637df" style="vertical-align: -0.338ex; width:0.905ex; height:2.176ex;"/></span> is an <a href="/wiki/Indicator_function" title="Indicator function">indicator function</a> and <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\displaystyle f}" xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="true" scriptlevel="0">
<mi>f</mi>
</mstyle>
</mrow>
<annotation encoding="application/x-tex">{\displaystyle f}</annotation>
</semantics>
</math></span><img alt="f" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/132e57acb643253e7810ee9702d9581f159a1c61" style="vertical-align: -0.671ex; width:1.279ex; height:2.509ex;"/></span> is the <a href="/wiki/Probability_density_function" title="Probability density function">probability density function</a> of a multivariate normal.
</p><p>In the last equality, for each <span class="texhtml"><i>i</i></span>, one indicator <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\displaystyle \mathbb {I} (z_{i}=j)}" xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="true" scriptlevel="0">
<mrow class="MJX-TeXAtom-ORD">
<mi mathvariant="double-struck">I</mi>
</mrow>
<mo stretchy="false">(</mo>
<msub>
<mi>z</mi>
<mrow class="MJX-TeXAtom-ORD">
<mi>i</mi>
</mrow>
</msub>
<mo>=</mo>
<mi>j</mi>
<mo stretchy="false">)</mo>
</mstyle>
</mrow>
<annotation encoding="application/x-tex">{\displaystyle \mathbb {I} (z_{i}=j)}</annotation>
</semantics>
</math></span><img alt="\mathbb{I}(z_i=j)" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/7554fde3a46aa69efabd1e64538c9e5de68c36f7" style="vertical-align: -0.838ex; width:8.651ex; height:2.843ex;"/></span> is equal to zero, and one indicator is equal to one. The inner sum thus reduces to one term.
</p>
<h4><span class="mw-headline" id="E_step">E step</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Expectation%E2%80%93maximization_algorithm&amp;action=edit&amp;section=15" title="Edit section: E step">edit</a><span class="mw-editsection-bracket">]</span></span></h4>
<p>Given our current estimate of the parameters <i>θ</i><sup>(<i>t</i>)</sup>, the conditional distribution of the <i>Z</i><sub><i>i</i></sub> is determined by <a class="mw-redirect" href="/wiki/Bayes_theorem" title="Bayes theorem">Bayes theorem</a> to be the proportional height of the normal <a href="/wiki/Probability_density_function" title="Probability density function">density</a> weighted by <i>τ</i>:
</p>
<dl><dd><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\displaystyle T_{j,i}^{(t)}:=\operatorname {P} (Z_{i}=j\mid X_{i}=\mathbf {x} _{i};\theta ^{(t)})={\frac {\tau _{j}^{(t)}\ f(\mathbf {x} _{i};{\boldsymbol {\mu }}_{j}^{(t)},\Sigma _{j}^{(t)})}{\tau _{1}^{(t)}\ f(\mathbf {x} _{i};{\boldsymbol {\mu }}_{1}^{(t)},\Sigma _{1}^{(t)})+\tau _{2}^{(t)}\ f(\mathbf {x} _{i};{\boldsymbol {\mu }}_{2}^{(t)},\Sigma _{2}^{(t)})}}}" xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="true" scriptlevel="0">
<msubsup>
<mi>T</mi>
<mrow class="MJX-TeXAtom-ORD">
<mi>j</mi>
<mo>,</mo>
<mi>i</mi>
</mrow>
<mrow class="MJX-TeXAtom-ORD">
<mo stretchy="false">(</mo>
<mi>t</mi>
<mo stretchy="false">)</mo>
</mrow>
</msubsup>
<mo>:=</mo>
<mi mathvariant="normal">P</mi>
<mo>⁡<!-- ⁡ --></mo>
<mo stretchy="false">(</mo>
<msub>
<mi>Z</mi>
<mrow class="MJX-TeXAtom-ORD">
<mi>i</mi>
</mrow>
</msub>
<mo>=</mo>
<mi>j</mi>
<mo>∣<!-- ∣ --></mo>
<msub>
<mi>X</mi>
<mrow class="MJX-TeXAtom-ORD">
<mi>i</mi>
</mrow>
</msub>
<mo>=</mo>
<msub>
<mrow class="MJX-TeXAtom-ORD">
<mi mathvariant="bold">x</mi>
</mrow>
<mrow class="MJX-TeXAtom-ORD">
<mi>i</mi>
</mrow>
</msub>
<mo>;</mo>
<msup>
<mi>θ<!-- θ --></mi>
<mrow class="MJX-TeXAtom-ORD">
<mo stretchy="false">(</mo>
<mi>t</mi>
<mo stretchy="false">)</mo>
</mrow>
</msup>
<mo stretchy="false">)</mo>
<mo>=</mo>
<mrow class="MJX-TeXAtom-ORD">
<mfrac>
<mrow>
<msubsup>
<mi>τ<!-- τ --></mi>
<mrow class="MJX-TeXAtom-ORD">
<mi>j</mi>
</mrow>
<mrow class="MJX-TeXAtom-ORD">
<mo stretchy="false">(</mo>
<mi>t</mi>
<mo stretchy="false">)</mo>
</mrow>
</msubsup>
<mtext> </mtext>
<mi>f</mi>
<mo stretchy="false">(</mo>
<msub>
<mrow class="MJX-TeXAtom-ORD">
<mi mathvariant="bold">x</mi>
</mrow>
<mrow class="MJX-TeXAtom-ORD">
<mi>i</mi>
</mrow>
</msub>
<mo>;</mo>
<msubsup>
<mrow class="MJX-TeXAtom-ORD">
<mi mathvariant="bold-italic">μ<!-- μ --></mi>
</mrow>
<mrow class="MJX-TeXAtom-ORD">
<mi>j</mi>
</mrow>
<mrow class="MJX-TeXAtom-ORD">
<mo stretchy="false">(</mo>
<mi>t</mi>
<mo stretchy="false">)</mo>
</mrow>
</msubsup>
<mo>,</mo>
<msubsup>
<mi mathvariant="normal">Σ<!-- Σ --></mi>
<mrow class="MJX-TeXAtom-ORD">
<mi>j</mi>
</mrow>
<mrow class="MJX-TeXAtom-ORD">
<mo stretchy="false">(</mo>
<mi>t</mi>
<mo stretchy="false">)</mo>
</mrow>
</msubsup>
<mo stretchy="false">)</mo>
</mrow>
<mrow>
<msubsup>
<mi>τ<!-- τ --></mi>
<mrow class="MJX-TeXAtom-ORD">
<mn>1</mn>
</mrow>
<mrow class="MJX-TeXAtom-ORD">
<mo stretchy="false">(</mo>
<mi>t</mi>
<mo stretchy="false">)</mo>
</mrow>
</msubsup>
<mtext> </mtext>
<mi>f</mi>
<mo stretchy="false">(</mo>
<msub>
<mrow class="MJX-TeXAtom-ORD">
<mi mathvariant="bold">x</mi>
</mrow>
<mrow class="MJX-TeXAtom-ORD">
<mi>i</mi>
</mrow>
</msub>
<mo>;</mo>
<msubsup>
<mrow class="MJX-TeXAtom-ORD">
<mi mathvariant="bold-italic">μ<!-- μ --></mi>
</mrow>
<mrow class="MJX-TeXAtom-ORD">
<mn>1</mn>
</mrow>
<mrow class="MJX-TeXAtom-ORD">
<mo stretchy="false">(</mo>
<mi>t</mi>
<mo stretchy="false">)</mo>
</mrow>
</msubsup>
<mo>,</mo>
<msubsup>
<mi mathvariant="normal">Σ<!-- Σ --></mi>
<mrow class="MJX-TeXAtom-ORD">
<mn>1</mn>
</mrow>
<mrow class="MJX-TeXAtom-ORD">
<mo stretchy="false">(</mo>
<mi>t</mi>
<mo stretchy="false">)</mo>
</mrow>
</msubsup>
<mo stretchy="false">)</mo>
<mo>+</mo>
<msubsup>
<mi>τ<!-- τ --></mi>
<mrow class="MJX-TeXAtom-ORD">
<mn>2</mn>
</mrow>
<mrow class="MJX-TeXAtom-ORD">
<mo stretchy="false">(</mo>
<mi>t</mi>
<mo stretchy="false">)</mo>
</mrow>
</msubsup>
<mtext> </mtext>
<mi>f</mi>
<mo stretchy="false">(</mo>
<msub>
<mrow class="MJX-TeXAtom-ORD">
<mi mathvariant="bold">x</mi>
</mrow>
<mrow class="MJX-TeXAtom-ORD">
<mi>i</mi>
</mrow>
</msub>
<mo>;</mo>
<msubsup>
<mrow class="MJX-TeXAtom-ORD">
<mi mathvariant="bold-italic">μ<!-- μ --></mi>
</mrow>
<mrow class="MJX-TeXAtom-ORD">
<mn>2</mn>
</mrow>
<mrow class="MJX-TeXAtom-ORD">
<mo stretchy="false">(</mo>
<mi>t</mi>
<mo stretchy="false">)</mo>
</mrow>
</msubsup>
<mo>,</mo>
<msubsup>
<mi mathvariant="normal">Σ<!-- Σ --></mi>
<mrow class="MJX-TeXAtom-ORD">
<mn>2</mn>
</mrow>
<mrow class="MJX-TeXAtom-ORD">
<mo stretchy="false">(</mo>
<mi>t</mi>
<mo stretchy="false">)</mo>
</mrow>
</msubsup>
<mo stretchy="false">)</mo>
</mrow>
</mfrac>
</mrow>
</mstyle>
</mrow>
<annotation encoding="application/x-tex">{\displaystyle T_{j,i}^{(t)}:=\operatorname {P} (Z_{i}=j\mid X_{i}=\mathbf {x} _{i};\theta ^{(t)})={\frac {\tau _{j}^{(t)}\ f(\mathbf {x} _{i};{\boldsymbol {\mu }}_{j}^{(t)},\Sigma _{j}^{(t)})}{\tau _{1}^{(t)}\ f(\mathbf {x} _{i};{\boldsymbol {\mu }}_{1}^{(t)},\Sigma _{1}^{(t)})+\tau _{2}^{(t)}\ f(\mathbf {x} _{i};{\boldsymbol {\mu }}_{2}^{(t)},\Sigma _{2}^{(t)})}}}</annotation>
</semantics>
</math></span><img alt="{\displaystyle T_{j,i}^{(t)}:=\operatorname {P} (Z_{i}=j\mid X_{i}=\mathbf {x} _{i};\theta ^{(t)})={\frac {\tau _{j}^{(t)}\ f(\mathbf {x} _{i};{\boldsymbol {\mu }}_{j}^{(t)},\Sigma _{j}^{(t)})}{\tau _{1}^{(t)}\ f(\mathbf {x} _{i};{\boldsymbol {\mu }}_{1}^{(t)},\Sigma _{1}^{(t)})+\tau _{2}^{(t)}\ f(\mathbf {x} _{i};{\boldsymbol {\mu }}_{2}^{(t)},\Sigma _{2}^{(t)})}}}" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/7c74963776ea84620178c808eca72c233ca2c939" style="vertical-align: -3.505ex; width:76.07ex; height:8.509ex;"/></span>.</dd></dl>
<p>These are called the "membership probabilities" which are normally considered the output of the E step (although this is not the Q function of below).
</p><p>This E step corresponds with setting up this function for Q:
</p>
<dl><dd><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\displaystyle {\begin{aligned}Q(\theta \mid \theta ^{(t)})&amp;=\operatorname {E} _{\mathbf {Z} \mid \mathbf {X} ,\mathbf {\theta } ^{(t)}}[\log L(\theta ;\mathbf {x} ,\mathbf {Z} )]\\&amp;=\operatorname {E} _{\mathbf {Z} \mid \mathbf {X} ,\mathbf {\theta } ^{(t)}}[\log \prod _{i=1}^{n}L(\theta ;\mathbf {x} _{i},Z_{i})]\\&amp;=\operatorname {E} _{\mathbf {Z} \mid \mathbf {X} ,\mathbf {\theta } ^{(t)}}[\sum _{i=1}^{n}\log L(\theta ;\mathbf {x} _{i},Z_{i})]\\&amp;=\sum _{i=1}^{n}\operatorname {E} _{Z_{i}\mid \mathbf {X} ;\mathbf {\theta } ^{(t)}}[\log L(\theta ;\mathbf {x} _{i},Z_{i})]\\&amp;=\sum _{i=1}^{n}\sum _{j=1}^{2}P(Z_{i}=j\mid X_{i}=\mathbf {x} _{i};\theta ^{(t)})\log L(\theta _{j};\mathbf {x} _{i},j)\\&amp;=\sum _{i=1}^{n}\sum _{j=1}^{2}T_{j,i}^{(t)}{\big [}\log \tau _{j}-{\tfrac {1}{2}}\log |\Sigma _{j}|-{\tfrac {1}{2}}(\mathbf {x} _{i}-{\boldsymbol {\mu }}_{j})^{\top }\Sigma _{j}^{-1}(\mathbf {x} _{i}-{\boldsymbol {\mu }}_{j})-{\tfrac {d}{2}}\log(2\pi ){\big ]}\end{aligned}}}" xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="true" scriptlevel="0">
<mrow class="MJX-TeXAtom-ORD">
<mtable columnalign="right left right left right left right left right left right left" columnspacing="0em 2em 0em 2em 0em 2em 0em 2em 0em 2em 0em" displaystyle="true" rowspacing="3pt">
<mtr>
<mtd>
<mi>Q</mi>
<mo stretchy="false">(</mo>
<mi>θ<!-- θ --></mi>
<mo>∣<!-- ∣ --></mo>
<msup>
<mi>θ<!-- θ --></mi>
<mrow class="MJX-TeXAtom-ORD">
<mo stretchy="false">(</mo>
<mi>t</mi>
<mo stretchy="false">)</mo>
</mrow>
</msup>
<mo stretchy="false">)</mo>
</mtd>
<mtd>
<mi></mi>
<mo>=</mo>
<msub>
<mi mathvariant="normal">E</mi>
<mrow class="MJX-TeXAtom-ORD">
<mrow class="MJX-TeXAtom-ORD">
<mi mathvariant="bold">Z</mi>
</mrow>
<mo>∣<!-- ∣ --></mo>
<mrow class="MJX-TeXAtom-ORD">
<mi mathvariant="bold">X</mi>
</mrow>
<mo>,</mo>
<msup>
<mrow class="MJX-TeXAtom-ORD">
<mi>θ<!-- θ --></mi>
</mrow>
<mrow class="MJX-TeXAtom-ORD">
<mo stretchy="false">(</mo>
<mi>t</mi>
<mo stretchy="false">)</mo>
</mrow>
</msup>
</mrow>
</msub>
<mo>⁡<!-- ⁡ --></mo>
<mo stretchy="false">[</mo>
<mi>log</mi>
<mo>⁡<!-- ⁡ --></mo>
<mi>L</mi>
<mo stretchy="false">(</mo>
<mi>θ<!-- θ --></mi>
<mo>;</mo>
<mrow class="MJX-TeXAtom-ORD">
<mi mathvariant="bold">x</mi>
</mrow>
<mo>,</mo>
<mrow class="MJX-TeXAtom-ORD">
<mi mathvariant="bold">Z</mi>
</mrow>
<mo stretchy="false">)</mo>
<mo stretchy="false">]</mo>
</mtd>
</mtr>
<mtr>
<mtd></mtd>
<mtd>
<mi></mi>
<mo>=</mo>
<msub>
<mi mathvariant="normal">E</mi>
<mrow class="MJX-TeXAtom-ORD">
<mrow class="MJX-TeXAtom-ORD">
<mi mathvariant="bold">Z</mi>
</mrow>
<mo>∣<!-- ∣ --></mo>
<mrow class="MJX-TeXAtom-ORD">
<mi mathvariant="bold">X</mi>
</mrow>
<mo>,</mo>
<msup>
<mrow class="MJX-TeXAtom-ORD">
<mi>θ<!-- θ --></mi>
</mrow>
<mrow class="MJX-TeXAtom-ORD">
<mo stretchy="false">(</mo>
<mi>t</mi>
<mo stretchy="false">)</mo>
</mrow>
</msup>
</mrow>
</msub>
<mo>⁡<!-- ⁡ --></mo>
<mo stretchy="false">[</mo>
<mi>log</mi>
<mo>⁡<!-- ⁡ --></mo>
<munderover>
<mo>∏<!-- ∏ --></mo>
<mrow class="MJX-TeXAtom-ORD">
<mi>i</mi>
<mo>=</mo>
<mn>1</mn>
</mrow>
<mrow class="MJX-TeXAtom-ORD">
<mi>n</mi>
</mrow>
</munderover>
<mi>L</mi>
<mo stretchy="false">(</mo>
<mi>θ<!-- θ --></mi>
<mo>;</mo>
<msub>
<mrow class="MJX-TeXAtom-ORD">
<mi mathvariant="bold">x</mi>
</mrow>
<mrow class="MJX-TeXAtom-ORD">
<mi>i</mi>
</mrow>
</msub>
<mo>,</mo>
<msub>
<mi>Z</mi>
<mrow class="MJX-TeXAtom-ORD">
<mi>i</mi>
</mrow>
</msub>
<mo stretchy="false">)</mo>
<mo stretchy="false">]</mo>
</mtd>
</mtr>
<mtr>
<mtd></mtd>
<mtd>
<mi></mi>
<mo>=</mo>
<msub>
<mi mathvariant="normal">E</mi>
<mrow class="MJX-TeXAtom-ORD">
<mrow class="MJX-TeXAtom-ORD">
<mi mathvariant="bold">Z</mi>
</mrow>
<mo>∣<!-- ∣ --></mo>
<mrow class="MJX-TeXAtom-ORD">
<mi mathvariant="bold">X</mi>
</mrow>
<mo>,</mo>
<msup>
<mrow class="MJX-TeXAtom-ORD">
<mi>θ<!-- θ --></mi>
</mrow>
<mrow class="MJX-TeXAtom-ORD">
<mo stretchy="false">(</mo>
<mi>t</mi>
<mo stretchy="false">)</mo>
</mrow>
</msup>
</mrow>
</msub>
<mo>⁡<!-- ⁡ --></mo>
<mo stretchy="false">[</mo>
<munderover>
<mo>∑<!-- ∑ --></mo>
<mrow class="MJX-TeXAtom-ORD">
<mi>i</mi>
<mo>=</mo>
<mn>1</mn>
</mrow>
<mrow class="MJX-TeXAtom-ORD">
<mi>n</mi>
</mrow>
</munderover>
<mi>log</mi>
<mo>⁡<!-- ⁡ --></mo>
<mi>L</mi>
<mo stretchy="false">(</mo>
<mi>θ<!-- θ --></mi>
<mo>;</mo>
<msub>
<mrow class="MJX-TeXAtom-ORD">
<mi mathvariant="bold">x</mi>
</mrow>
<mrow class="MJX-TeXAtom-ORD">
<mi>i</mi>
</mrow>
</msub>
<mo>,</mo>
<msub>
<mi>Z</mi>
<mrow class="MJX-TeXAtom-ORD">
<mi>i</mi>
</mrow>
</msub>
<mo stretchy="false">)</mo>
<mo stretchy="false">]</mo>
</mtd>
</mtr>
<mtr>
<mtd></mtd>
<mtd>
<mi></mi>
<mo>=</mo>
<munderover>
<mo>∑<!-- ∑ --></mo>
<mrow class="MJX-TeXAtom-ORD">
<mi>i</mi>
<mo>=</mo>
<mn>1</mn>
</mrow>
<mrow class="MJX-TeXAtom-ORD">
<mi>n</mi>
</mrow>
</munderover>
<msub>
<mi mathvariant="normal">E</mi>
<mrow class="MJX-TeXAtom-ORD">
<msub>
<mi>Z</mi>
<mrow class="MJX-TeXAtom-ORD">
<mi>i</mi>
</mrow>
</msub>
<mo>∣<!-- ∣ --></mo>
<mrow class="MJX-TeXAtom-ORD">
<mi mathvariant="bold">X</mi>
</mrow>
<mo>;</mo>
<msup>
<mrow class="MJX-TeXAtom-ORD">
<mi>θ<!-- θ --></mi>
</mrow>
<mrow class="MJX-TeXAtom-ORD">
<mo stretchy="false">(</mo>
<mi>t</mi>
<mo stretchy="false">)</mo>
</mrow>
</msup>
</mrow>
</msub>
<mo>⁡<!-- ⁡ --></mo>
<mo stretchy="false">[</mo>
<mi>log</mi>
<mo>⁡<!-- ⁡ --></mo>
<mi>L</mi>
<mo stretchy="false">(</mo>
<mi>θ<!-- θ --></mi>
<mo>;</mo>
<msub>
<mrow class="MJX-TeXAtom-ORD">
<mi mathvariant="bold">x</mi>
</mrow>
<mrow class="MJX-TeXAtom-ORD">
<mi>i</mi>
</mrow>
</msub>
<mo>,</mo>
<msub>
<mi>Z</mi>
<mrow class="MJX-TeXAtom-ORD">
<mi>i</mi>
</mrow>
</msub>
<mo stretchy="false">)</mo>
<mo stretchy="false">]</mo>
</mtd>
</mtr>
<mtr>
<mtd></mtd>
<mtd>
<mi></mi>
<mo>=</mo>
<munderover>
<mo>∑<!-- ∑ --></mo>
<mrow class="MJX-TeXAtom-ORD">
<mi>i</mi>
<mo>=</mo>
<mn>1</mn>
</mrow>
<mrow class="MJX-TeXAtom-ORD">
<mi>n</mi>
</mrow>
</munderover>
<munderover>
<mo>∑<!-- ∑ --></mo>
<mrow class="MJX-TeXAtom-ORD">
<mi>j</mi>
<mo>=</mo>
<mn>1</mn>
</mrow>
<mrow class="MJX-TeXAtom-ORD">
<mn>2</mn>
</mrow>
</munderover>
<mi>P</mi>
<mo stretchy="false">(</mo>
<msub>
<mi>Z</mi>
<mrow class="MJX-TeXAtom-ORD">
<mi>i</mi>
</mrow>
</msub>
<mo>=</mo>
<mi>j</mi>
<mo>∣<!-- ∣ --></mo>
<msub>
<mi>X</mi>
<mrow class="MJX-TeXAtom-ORD">
<mi>i</mi>
</mrow>
</msub>
<mo>=</mo>
<msub>
<mrow class="MJX-TeXAtom-ORD">
<mi mathvariant="bold">x</mi>
</mrow>
<mrow class="MJX-TeXAtom-ORD">
<mi>i</mi>
</mrow>
</msub>
<mo>;</mo>
<msup>
<mi>θ<!-- θ --></mi>
<mrow class="MJX-TeXAtom-ORD">
<mo stretchy="false">(</mo>
<mi>t</mi>
<mo stretchy="false">)</mo>
</mrow>
</msup>
<mo stretchy="false">)</mo>
<mi>log</mi>
<mo>⁡<!-- ⁡ --></mo>
<mi>L</mi>
<mo stretchy="false">(</mo>
<msub>
<mi>θ<!-- θ --></mi>
<mrow class="MJX-TeXAtom-ORD">
<mi>j</mi>
</mrow>
</msub>
<mo>;</mo>
<msub>
<mrow class="MJX-TeXAtom-ORD">
<mi mathvariant="bold">x</mi>
</mrow>
<mrow class="MJX-TeXAtom-ORD">
<mi>i</mi>
</mrow>
</msub>
<mo>,</mo>
<mi>j</mi>
<mo stretchy="false">)</mo>
</mtd>
</mtr>
<mtr>
<mtd></mtd>
<mtd>
<mi></mi>
<mo>=</mo>
<munderover>
<mo>∑<!-- ∑ --></mo>
<mrow class="MJX-TeXAtom-ORD">
<mi>i</mi>
<mo>=</mo>
<mn>1</mn>
</mrow>
<mrow class="MJX-TeXAtom-ORD">
<mi>n</mi>
</mrow>
</munderover>
<munderover>
<mo>∑<!-- ∑ --></mo>
<mrow class="MJX-TeXAtom-ORD">
<mi>j</mi>
<mo>=</mo>
<mn>1</mn>
</mrow>
<mrow class="MJX-TeXAtom-ORD">
<mn>2</mn>
</mrow>
</munderover>
<msubsup>
<mi>T</mi>
<mrow class="MJX-TeXAtom-ORD">
<mi>j</mi>
<mo>,</mo>
<mi>i</mi>
</mrow>
<mrow class="MJX-TeXAtom-ORD">
<mo stretchy="false">(</mo>
<mi>t</mi>
<mo stretchy="false">)</mo>
</mrow>
</msubsup>
<mrow class="MJX-TeXAtom-ORD">
<mrow class="MJX-TeXAtom-ORD">
<mo maxsize="1.2em" minsize="1.2em">[</mo>
</mrow>
</mrow>
<mi>log</mi>
<mo>⁡<!-- ⁡ --></mo>
<msub>
<mi>τ<!-- τ --></mi>
<mrow class="MJX-TeXAtom-ORD">
<mi>j</mi>
</mrow>
</msub>
<mo>−<!-- − --></mo>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="false" scriptlevel="0">
<mfrac>
<mn>1</mn>
<mn>2</mn>
</mfrac>
</mstyle>
</mrow>
<mi>log</mi>
<mo>⁡<!-- ⁡ --></mo>
<mrow class="MJX-TeXAtom-ORD">
<mo stretchy="false">|</mo>
</mrow>
<msub>
<mi mathvariant="normal">Σ<!-- Σ --></mi>
<mrow class="MJX-TeXAtom-ORD">
<mi>j</mi>
</mrow>
</msub>
<mrow class="MJX-TeXAtom-ORD">
<mo stretchy="false">|</mo>
</mrow>
<mo>−<!-- − --></mo>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="false" scriptlevel="0">
<mfrac>
<mn>1</mn>
<mn>2</mn>
</mfrac>
</mstyle>
</mrow>
<mo stretchy="false">(</mo>
<msub>
<mrow class="MJX-TeXAtom-ORD">
<mi mathvariant="bold">x</mi>
</mrow>
<mrow class="MJX-TeXAtom-ORD">
<mi>i</mi>
</mrow>
</msub>
<mo>−<!-- − --></mo>
<msub>
<mrow class="MJX-TeXAtom-ORD">
<mi mathvariant="bold-italic">μ<!-- μ --></mi>
</mrow>
<mrow class="MJX-TeXAtom-ORD">
<mi>j</mi>
</mrow>
</msub>
<msup>
<mo stretchy="false">)</mo>
<mrow class="MJX-TeXAtom-ORD">
<mi mathvariant="normal">⊤<!-- ⊤ --></mi>
</mrow>
</msup>
<msubsup>
<mi mathvariant="normal">Σ<!-- Σ --></mi>
<mrow class="MJX-TeXAtom-ORD">
<mi>j</mi>
</mrow>
<mrow class="MJX-TeXAtom-ORD">
<mo>−<!-- − --></mo>
<mn>1</mn>
</mrow>
</msubsup>
<mo stretchy="false">(</mo>
<msub>
<mrow class="MJX-TeXAtom-ORD">
<mi mathvariant="bold">x</mi>
</mrow>
<mrow class="MJX-TeXAtom-ORD">
<mi>i</mi>
</mrow>
</msub>
<mo>−<!-- − --></mo>
<msub>
<mrow class="MJX-TeXAtom-ORD">
<mi mathvariant="bold-italic">μ<!-- μ --></mi>
</mrow>
<mrow class="MJX-TeXAtom-ORD">
<mi>j</mi>
</mrow>
</msub>
<mo stretchy="false">)</mo>
<mo>−<!-- − --></mo>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="false" scriptlevel="0">
<mfrac>
<mi>d</mi>
<mn>2</mn>
</mfrac>
</mstyle>
</mrow>
<mi>log</mi>
<mo>⁡<!-- ⁡ --></mo>
<mo stretchy="false">(</mo>
<mn>2</mn>
<mi>π<!-- π --></mi>
<mo stretchy="false">)</mo>
<mrow class="MJX-TeXAtom-ORD">
<mrow class="MJX-TeXAtom-ORD">
<mo maxsize="1.2em" minsize="1.2em">]</mo>
</mrow>
</mrow>
</mtd>
</mtr>
</mtable>
</mrow>
</mstyle>
</mrow>
<annotation encoding="application/x-tex">{\displaystyle {\begin{aligned}Q(\theta \mid \theta ^{(t)})&amp;=\operatorname {E} _{\mathbf {Z} \mid \mathbf {X} ,\mathbf {\theta } ^{(t)}}[\log L(\theta ;\mathbf {x} ,\mathbf {Z} )]\\&amp;=\operatorname {E} _{\mathbf {Z} \mid \mathbf {X} ,\mathbf {\theta } ^{(t)}}[\log \prod _{i=1}^{n}L(\theta ;\mathbf {x} _{i},Z_{i})]\\&amp;=\operatorname {E} _{\mathbf {Z} \mid \mathbf {X} ,\mathbf {\theta } ^{(t)}}[\sum _{i=1}^{n}\log L(\theta ;\mathbf {x} _{i},Z_{i})]\\&amp;=\sum _{i=1}^{n}\operatorname {E} _{Z_{i}\mid \mathbf {X} ;\mathbf {\theta } ^{(t)}}[\log L(\theta ;\mathbf {x} _{i},Z_{i})]\\&amp;=\sum _{i=1}^{n}\sum _{j=1}^{2}P(Z_{i}=j\mid X_{i}=\mathbf {x} _{i};\theta ^{(t)})\log L(\theta _{j};\mathbf {x} _{i},j)\\&amp;=\sum _{i=1}^{n}\sum _{j=1}^{2}T_{j,i}^{(t)}{\big [}\log \tau _{j}-{\tfrac {1}{2}}\log |\Sigma _{j}|-{\tfrac {1}{2}}(\mathbf {x} _{i}-{\boldsymbol {\mu }}_{j})^{\top }\Sigma _{j}^{-1}(\mathbf {x} _{i}-{\boldsymbol {\mu }}_{j})-{\tfrac {d}{2}}\log(2\pi ){\big ]}\end{aligned}}}</annotation>
</semantics>
</math></span><img alt="{\displaystyle {\begin{aligned}Q(\theta \mid \theta ^{(t)})&amp;=\operatorname {E} _{\mathbf {Z} \mid \mathbf {X} ,\mathbf {\theta } ^{(t)}}[\log L(\theta ;\mathbf {x} ,\mathbf {Z} )]\\&amp;=\operatorname {E} _{\mathbf {Z} \mid \mathbf {X} ,\mathbf {\theta } ^{(t)}}[\log \prod _{i=1}^{n}L(\theta ;\mathbf {x} _{i},Z_{i})]\\&amp;=\operatorname {E} _{\mathbf {Z} \mid \mathbf {X} ,\mathbf {\theta } ^{(t)}}[\sum _{i=1}^{n}\log L(\theta ;\mathbf {x} _{i},Z_{i})]\\&amp;=\sum _{i=1}^{n}\operatorname {E} _{Z_{i}\mid \mathbf {X} ;\mathbf {\theta } ^{(t)}}[\log L(\theta ;\mathbf {x} _{i},Z_{i})]\\&amp;=\sum _{i=1}^{n}\sum _{j=1}^{2}P(Z_{i}=j\mid X_{i}=\mathbf {x} _{i};\theta ^{(t)})\log L(\theta _{j};\mathbf {x} _{i},j)\\&amp;=\sum _{i=1}^{n}\sum _{j=1}^{2}T_{j,i}^{(t)}{\big [}\log \tau _{j}-{\tfrac {1}{2}}\log |\Sigma _{j}|-{\tfrac {1}{2}}(\mathbf {x} _{i}-{\boldsymbol {\mu }}_{j})^{\top }\Sigma _{j}^{-1}(\mathbf {x} _{i}-{\boldsymbol {\mu }}_{j})-{\tfrac {d}{2}}\log(2\pi ){\big ]}\end{aligned}}}" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/f1fbd1e927af9e9cbf59d19e0636ec64634977e8" style="vertical-align: -19.838ex; width:85.818ex; height:40.843ex;"/></span></dd></dl>
<p>The expectation of <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\displaystyle \log L(\theta ;\mathbf {x} _{i},Z_{i})}" xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="true" scriptlevel="0">
<mi>log</mi>
<mo>⁡<!-- ⁡ --></mo>
<mi>L</mi>
<mo stretchy="false">(</mo>
<mi>θ<!-- θ --></mi>
<mo>;</mo>
<msub>
<mrow class="MJX-TeXAtom-ORD">
<mi mathvariant="bold">x</mi>
</mrow>
<mrow class="MJX-TeXAtom-ORD">
<mi>i</mi>
</mrow>
</msub>
<mo>,</mo>
<msub>
<mi>Z</mi>
<mrow class="MJX-TeXAtom-ORD">
<mi>i</mi>
</mrow>
</msub>
<mo stretchy="false">)</mo>
</mstyle>
</mrow>
<annotation encoding="application/x-tex">{\displaystyle \log L(\theta ;\mathbf {x} _{i},Z_{i})}</annotation>
</semantics>
</math></span><img alt="{\displaystyle \log L(\theta ;\mathbf {x} _{i},Z_{i})}" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/c9d7c15b71808c0aa9700ac4abbea1ac788071e6" style="vertical-align: -0.838ex; width:14.507ex; height:2.843ex;"/></span> inside the sum is taken with respect to the probability density function <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\displaystyle P(Z_{i}\mid X_{i}=\mathbf {x} _{i};\theta ^{(t)})}" xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="true" scriptlevel="0">
<mi>P</mi>
<mo stretchy="false">(</mo>
<msub>
<mi>Z</mi>
<mrow class="MJX-TeXAtom-ORD">
<mi>i</mi>
</mrow>
</msub>
<mo>∣<!-- ∣ --></mo>
<msub>
<mi>X</mi>
<mrow class="MJX-TeXAtom-ORD">
<mi>i</mi>
</mrow>
</msub>
<mo>=</mo>
<msub>
<mrow class="MJX-TeXAtom-ORD">
<mi mathvariant="bold">x</mi>
</mrow>
<mrow class="MJX-TeXAtom-ORD">
<mi>i</mi>
</mrow>
</msub>
<mo>;</mo>
<msup>
<mi>θ<!-- θ --></mi>
<mrow class="MJX-TeXAtom-ORD">
<mo stretchy="false">(</mo>
<mi>t</mi>
<mo stretchy="false">)</mo>
</mrow>
</msup>
<mo stretchy="false">)</mo>
</mstyle>
</mrow>
<annotation encoding="application/x-tex">{\displaystyle P(Z_{i}\mid X_{i}=\mathbf {x} _{i};\theta ^{(t)})}</annotation>
</semantics>
</math></span><img alt="{\displaystyle P(Z_{i}\mid X_{i}=\mathbf {x} _{i};\theta ^{(t)})}" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/a6cb63d21c4798790355502371133afb825970d3" style="vertical-align: -0.838ex; width:20.142ex; height:3.343ex;"/></span>, which might be different for each  <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\displaystyle \mathbf {x} _{i}}" xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="true" scriptlevel="0">
<msub>
<mrow class="MJX-TeXAtom-ORD">
<mi mathvariant="bold">x</mi>
</mrow>
<mrow class="MJX-TeXAtom-ORD">
<mi>i</mi>
</mrow>
</msub>
</mstyle>
</mrow>
<annotation encoding="application/x-tex">{\displaystyle \mathbf {x} _{i}}</annotation>
</semantics>
</math></span><img alt="\mathbf {x} _{i}" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/57d2ef3df60acdb53bdf90535264041fea7231cd" style="vertical-align: -0.671ex; width:2.211ex; height:2.009ex;"/></span> of the training set. Everything in the E step is known before the step is taken except <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\displaystyle T_{j,i}}" xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="true" scriptlevel="0">
<msub>
<mi>T</mi>
<mrow class="MJX-TeXAtom-ORD">
<mi>j</mi>
<mo>,</mo>
<mi>i</mi>
</mrow>
</msub>
</mstyle>
</mrow>
<annotation encoding="application/x-tex">{\displaystyle T_{j,i}}</annotation>
</semantics>
</math></span><img alt="{\displaystyle T_{j,i}}" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/896bd3433b93d00916b90aa6493c84434596c232" style="vertical-align: -1.005ex; width:3.292ex; height:2.843ex;"/></span>, which is computed according to the equation at the beginning of the E step section.
</p><p>This full conditional expectation does not need to be calculated in one step, because <i>τ</i> and <b>μ</b>/<b>Σ</b> appear in separate linear terms and can thus be maximized independently.
</p>
<h4><span class="mw-headline" id="M_step">M step</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Expectation%E2%80%93maximization_algorithm&amp;action=edit&amp;section=16" title="Edit section: M step">edit</a><span class="mw-editsection-bracket">]</span></span></h4>
<p><i>Q</i>(<i>θ</i> | <i>θ</i><sup>(<i>t</i>)</sup>) being quadratic in form means that determining the maximizing values of <i>θ</i> is relatively straightforward. Also, <i>τ</i>, (<b>μ</b><sub>1</sub>,<i>Σ</i><sub>1</sub>) and (<b>μ</b><sub>2</sub>,<i>Σ</i><sub>2</sub>) may all be maximized independently since they all appear in separate linear terms.
</p><p>To begin, consider <i>τ</i>, which has the constraint <i>τ</i><sub>1</sub> + <i>τ</i><sub>2</sub>=1:
</p>
<dl><dd><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\displaystyle {\begin{aligned}{\boldsymbol {\tau }}^{(t+1)}&amp;={\underset {\boldsymbol {\tau }}{\operatorname {arg\,max} }}\ Q(\theta \mid \theta ^{(t)})\\&amp;={\underset {\boldsymbol {\tau }}{\operatorname {arg\,max} }}\ \left\{\left[\sum _{i=1}^{n}T_{1,i}^{(t)}\right]\log \tau _{1}+\left[\sum _{i=1}^{n}T_{2,i}^{(t)}\right]\log \tau _{2}\right\}\end{aligned}}}" xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="true" scriptlevel="0">
<mrow class="MJX-TeXAtom-ORD">
<mtable columnalign="right left right left right left right left right left right left" columnspacing="0em 2em 0em 2em 0em 2em 0em 2em 0em 2em 0em" displaystyle="true" rowspacing="3pt">
<mtr>
<mtd>
<msup>
<mrow class="MJX-TeXAtom-ORD">
<mi mathvariant="bold-italic">τ<!-- τ --></mi>
</mrow>
<mrow class="MJX-TeXAtom-ORD">
<mo stretchy="false">(</mo>
<mi>t</mi>
<mo>+</mo>
<mn>1</mn>
<mo stretchy="false">)</mo>
</mrow>
</msup>
</mtd>
<mtd>
<mi></mi>
<mo>=</mo>
<mrow class="MJX-TeXAtom-ORD">
<munder>
<mrow class="MJX-TeXAtom-OP MJX-fixedlimits">
<mi mathvariant="normal">a</mi>
<mi mathvariant="normal">r</mi>
<mi mathvariant="normal">g</mi>
<mspace width="thinmathspace"></mspace>
<mi mathvariant="normal">m</mi>
<mi mathvariant="normal">a</mi>
<mi mathvariant="normal">x</mi>
</mrow>
<mi mathvariant="bold-italic">τ<!-- τ --></mi>
</munder>
</mrow>
<mtext> </mtext>
<mi>Q</mi>
<mo stretchy="false">(</mo>
<mi>θ<!-- θ --></mi>
<mo>∣<!-- ∣ --></mo>
<msup>
<mi>θ<!-- θ --></mi>
<mrow class="MJX-TeXAtom-ORD">
<mo stretchy="false">(</mo>
<mi>t</mi>
<mo stretchy="false">)</mo>
</mrow>
</msup>
<mo stretchy="false">)</mo>
</mtd>
</mtr>
<mtr>
<mtd></mtd>
<mtd>
<mi></mi>
<mo>=</mo>
<mrow class="MJX-TeXAtom-ORD">
<munder>
<mrow class="MJX-TeXAtom-OP MJX-fixedlimits">
<mi mathvariant="normal">a</mi>
<mi mathvariant="normal">r</mi>
<mi mathvariant="normal">g</mi>
<mspace width="thinmathspace"></mspace>
<mi mathvariant="normal">m</mi>
<mi mathvariant="normal">a</mi>
<mi mathvariant="normal">x</mi>
</mrow>
<mi mathvariant="bold-italic">τ<!-- τ --></mi>
</munder>
</mrow>
<mtext> </mtext>
<mrow>
<mo>{</mo>
<mrow>
<mrow>
<mo>[</mo>
<mrow>
<munderover>
<mo>∑<!-- ∑ --></mo>
<mrow class="MJX-TeXAtom-ORD">
<mi>i</mi>
<mo>=</mo>
<mn>1</mn>
</mrow>
<mrow class="MJX-TeXAtom-ORD">
<mi>n</mi>
</mrow>
</munderover>
<msubsup>
<mi>T</mi>
<mrow class="MJX-TeXAtom-ORD">
<mn>1</mn>
<mo>,</mo>
<mi>i</mi>
</mrow>
<mrow class="MJX-TeXAtom-ORD">
<mo stretchy="false">(</mo>
<mi>t</mi>
<mo stretchy="false">)</mo>
</mrow>
</msubsup>
</mrow>
<mo>]</mo>
</mrow>
<mi>log</mi>
<mo>⁡<!-- ⁡ --></mo>
<msub>
<mi>τ<!-- τ --></mi>
<mrow class="MJX-TeXAtom-ORD">
<mn>1</mn>
</mrow>
</msub>
<mo>+</mo>
<mrow>
<mo>[</mo>
<mrow>
<munderover>
<mo>∑<!-- ∑ --></mo>
<mrow class="MJX-TeXAtom-ORD">
<mi>i</mi>
<mo>=</mo>
<mn>1</mn>
</mrow>
<mrow class="MJX-TeXAtom-ORD">
<mi>n</mi>
</mrow>
</munderover>
<msubsup>
<mi>T</mi>
<mrow class="MJX-TeXAtom-ORD">
<mn>2</mn>
<mo>,</mo>
<mi>i</mi>
</mrow>
<mrow class="MJX-TeXAtom-ORD">
<mo stretchy="false">(</mo>
<mi>t</mi>
<mo stretchy="false">)</mo>
</mrow>
</msubsup>
</mrow>
<mo>]</mo>
</mrow>
<mi>log</mi>
<mo>⁡<!-- ⁡ --></mo>
<msub>
<mi>τ<!-- τ --></mi>
<mrow class="MJX-TeXAtom-ORD">
<mn>2</mn>
</mrow>
</msub>
</mrow>
<mo>}</mo>
</mrow>
</mtd>
</mtr>
</mtable>
</mrow>
</mstyle>
</mrow>
<annotation encoding="application/x-tex">{\displaystyle {\begin{aligned}{\boldsymbol {\tau }}^{(t+1)}&amp;={\underset {\boldsymbol {\tau }}{\operatorname {arg\,max} }}\ Q(\theta \mid \theta ^{(t)})\\&amp;={\underset {\boldsymbol {\tau }}{\operatorname {arg\,max} }}\ \left\{\left[\sum _{i=1}^{n}T_{1,i}^{(t)}\right]\log \tau _{1}+\left[\sum _{i=1}^{n}T_{2,i}^{(t)}\right]\log \tau _{2}\right\}\end{aligned}}}</annotation>
</semantics>
</math></span><img alt="{\displaystyle {\begin{aligned}{\boldsymbol {\tau }}^{(t+1)}&amp;={\underset {\boldsymbol {\tau }}{\operatorname {arg\,max} }}\ Q(\theta \mid \theta ^{(t)})\\&amp;={\underset {\boldsymbol {\tau }}{\operatorname {arg\,max} }}\ \left\{\left[\sum _{i=1}^{n}T_{1,i}^{(t)}\right]\log \tau _{1}+\left[\sum _{i=1}^{n}T_{2,i}^{(t)}\right]\log \tau _{2}\right\}\end{aligned}}}" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/913533315c1aeb55c2d0172b5bffb0bc17a7e5fc" style="vertical-align: -5.671ex; width:57.228ex; height:12.509ex;"/></span></dd></dl>
<p>This has the same form as the MLE for the <a href="/wiki/Binomial_distribution" title="Binomial distribution">binomial distribution</a>, so
</p>
<dl><dd><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\displaystyle \tau _{j}^{(t+1)}={\frac {\sum _{i=1}^{n}T_{j,i}^{(t)}}{\sum _{i=1}^{n}(T_{1,i}^{(t)}+T_{2,i}^{(t)})}}={\frac {1}{n}}\sum _{i=1}^{n}T_{j,i}^{(t)}}" xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="true" scriptlevel="0">
<msubsup>
<mi>τ<!-- τ --></mi>
<mrow class="MJX-TeXAtom-ORD">
<mi>j</mi>
</mrow>
<mrow class="MJX-TeXAtom-ORD">
<mo stretchy="false">(</mo>
<mi>t</mi>
<mo>+</mo>
<mn>1</mn>
<mo stretchy="false">)</mo>
</mrow>
</msubsup>
<mo>=</mo>
<mrow class="MJX-TeXAtom-ORD">
<mfrac>
<mrow>
<munderover>
<mo>∑<!-- ∑ --></mo>
<mrow class="MJX-TeXAtom-ORD">
<mi>i</mi>
<mo>=</mo>
<mn>1</mn>
</mrow>
<mrow class="MJX-TeXAtom-ORD">
<mi>n</mi>
</mrow>
</munderover>
<msubsup>
<mi>T</mi>
<mrow class="MJX-TeXAtom-ORD">
<mi>j</mi>
<mo>,</mo>
<mi>i</mi>
</mrow>
<mrow class="MJX-TeXAtom-ORD">
<mo stretchy="false">(</mo>
<mi>t</mi>
<mo stretchy="false">)</mo>
</mrow>
</msubsup>
</mrow>
<mrow>
<munderover>
<mo>∑<!-- ∑ --></mo>
<mrow class="MJX-TeXAtom-ORD">
<mi>i</mi>
<mo>=</mo>
<mn>1</mn>
</mrow>
<mrow class="MJX-TeXAtom-ORD">
<mi>n</mi>
</mrow>
</munderover>
<mo stretchy="false">(</mo>
<msubsup>
<mi>T</mi>
<mrow class="MJX-TeXAtom-ORD">
<mn>1</mn>
<mo>,</mo>
<mi>i</mi>
</mrow>
<mrow class="MJX-TeXAtom-ORD">
<mo stretchy="false">(</mo>
<mi>t</mi>
<mo stretchy="false">)</mo>
</mrow>
</msubsup>
<mo>+</mo>
<msubsup>
<mi>T</mi>
<mrow class="MJX-TeXAtom-ORD">
<mn>2</mn>
<mo>,</mo>
<mi>i</mi>
</mrow>
<mrow class="MJX-TeXAtom-ORD">
<mo stretchy="false">(</mo>
<mi>t</mi>
<mo stretchy="false">)</mo>
</mrow>
</msubsup>
<mo stretchy="false">)</mo>
</mrow>
</mfrac>
</mrow>
<mo>=</mo>
<mrow class="MJX-TeXAtom-ORD">
<mfrac>
<mn>1</mn>
<mi>n</mi>
</mfrac>
</mrow>
<munderover>
<mo>∑<!-- ∑ --></mo>
<mrow class="MJX-TeXAtom-ORD">
<mi>i</mi>
<mo>=</mo>
<mn>1</mn>
</mrow>
<mrow class="MJX-TeXAtom-ORD">
<mi>n</mi>
</mrow>
</munderover>
<msubsup>
<mi>T</mi>
<mrow class="MJX-TeXAtom-ORD">
<mi>j</mi>
<mo>,</mo>
<mi>i</mi>
</mrow>
<mrow class="MJX-TeXAtom-ORD">
<mo stretchy="false">(</mo>
<mi>t</mi>
<mo stretchy="false">)</mo>
</mrow>
</msubsup>
</mstyle>
</mrow>
<annotation encoding="application/x-tex">{\displaystyle \tau _{j}^{(t+1)}={\frac {\sum _{i=1}^{n}T_{j,i}^{(t)}}{\sum _{i=1}^{n}(T_{1,i}^{(t)}+T_{2,i}^{(t)})}}={\frac {1}{n}}\sum _{i=1}^{n}T_{j,i}^{(t)}}</annotation>
</semantics>
</math></span><img alt="\tau^{(t+1)}_j = \frac{\sum_{i=1}^n T_{j,i}^{(t)}}{\sum_{i=1}^n (T_{1,i}^{(t)} + T_{2,i}^{(t)} ) } = \frac{1}{n} \sum_{i=1}^n T_{j,i}^{(t)}" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/0e0327c8676ae66ec651b422a19f5ea532913c7a" style="vertical-align: -3.838ex; width:40.336ex; height:8.843ex;"/></span>.</dd></dl>
<p>For the next estimates of (<b>μ</b><sub>1</sub>,Σ<sub>1</sub>):
</p>
<dl><dd><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\displaystyle {\begin{aligned}({\boldsymbol {\mu }}_{1}^{(t+1)},\Sigma _{1}^{(t+1)})&amp;={\underset {{\boldsymbol {\mu }}_{1},\Sigma _{1}}{\operatorname {arg\,max} }}Q(\theta \mid \theta ^{(t)})\\&amp;={\underset {{\boldsymbol {\mu }}_{1},\Sigma _{1}}{\operatorname {arg\,max} }}\sum _{i=1}^{n}T_{1,i}^{(t)}\left\{-{\tfrac {1}{2}}\log |\Sigma _{1}|-{\tfrac {1}{2}}(\mathbf {x} _{i}-{\boldsymbol {\mu }}_{1})^{\top }\Sigma _{1}^{-1}(\mathbf {x} _{i}-{\boldsymbol {\mu }}_{1})\right\}\end{aligned}}}" xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="true" scriptlevel="0">
<mrow class="MJX-TeXAtom-ORD">
<mtable columnalign="right left right left right left right left right left right left" columnspacing="0em 2em 0em 2em 0em 2em 0em 2em 0em 2em 0em" displaystyle="true" rowspacing="3pt">
<mtr>
<mtd>
<mo stretchy="false">(</mo>
<msubsup>
<mrow class="MJX-TeXAtom-ORD">
<mi mathvariant="bold-italic">μ<!-- μ --></mi>
</mrow>
<mrow class="MJX-TeXAtom-ORD">
<mn>1</mn>
</mrow>
<mrow class="MJX-TeXAtom-ORD">
<mo stretchy="false">(</mo>
<mi>t</mi>
<mo>+</mo>
<mn>1</mn>
<mo stretchy="false">)</mo>
</mrow>
</msubsup>
<mo>,</mo>
<msubsup>
<mi mathvariant="normal">Σ<!-- Σ --></mi>
<mrow class="MJX-TeXAtom-ORD">
<mn>1</mn>
</mrow>
<mrow class="MJX-TeXAtom-ORD">
<mo stretchy="false">(</mo>
<mi>t</mi>
<mo>+</mo>
<mn>1</mn>
<mo stretchy="false">)</mo>
</mrow>
</msubsup>
<mo stretchy="false">)</mo>
</mtd>
<mtd>
<mi></mi>
<mo>=</mo>
<mrow class="MJX-TeXAtom-ORD">
<munder>
<mrow class="MJX-TeXAtom-OP MJX-fixedlimits">
<mi mathvariant="normal">a</mi>
<mi mathvariant="normal">r</mi>
<mi mathvariant="normal">g</mi>
<mspace width="thinmathspace"></mspace>
<mi mathvariant="normal">m</mi>
<mi mathvariant="normal">a</mi>
<mi mathvariant="normal">x</mi>
</mrow>
<mrow>
<msub>
<mrow class="MJX-TeXAtom-ORD">
<mi mathvariant="bold-italic">μ<!-- μ --></mi>
</mrow>
<mrow class="MJX-TeXAtom-ORD">
<mn>1</mn>
</mrow>
</msub>
<mo>,</mo>
<msub>
<mi mathvariant="normal">Σ<!-- Σ --></mi>
<mrow class="MJX-TeXAtom-ORD">
<mn>1</mn>
</mrow>
</msub>
</mrow>
</munder>
</mrow>
<mi>Q</mi>
<mo stretchy="false">(</mo>
<mi>θ<!-- θ --></mi>
<mo>∣<!-- ∣ --></mo>
<msup>
<mi>θ<!-- θ --></mi>
<mrow class="MJX-TeXAtom-ORD">
<mo stretchy="false">(</mo>
<mi>t</mi>
<mo stretchy="false">)</mo>
</mrow>
</msup>
<mo stretchy="false">)</mo>
</mtd>
</mtr>
<mtr>
<mtd></mtd>
<mtd>
<mi></mi>
<mo>=</mo>
<mrow class="MJX-TeXAtom-ORD">
<munder>
<mrow class="MJX-TeXAtom-OP MJX-fixedlimits">
<mi mathvariant="normal">a</mi>
<mi mathvariant="normal">r</mi>
<mi mathvariant="normal">g</mi>
<mspace width="thinmathspace"></mspace>
<mi mathvariant="normal">m</mi>
<mi mathvariant="normal">a</mi>
<mi mathvariant="normal">x</mi>
</mrow>
<mrow>
<msub>
<mrow class="MJX-TeXAtom-ORD">
<mi mathvariant="bold-italic">μ<!-- μ --></mi>
</mrow>
<mrow class="MJX-TeXAtom-ORD">
<mn>1</mn>
</mrow>
</msub>
<mo>,</mo>
<msub>
<mi mathvariant="normal">Σ<!-- Σ --></mi>
<mrow class="MJX-TeXAtom-ORD">
<mn>1</mn>
</mrow>
</msub>
</mrow>
</munder>
</mrow>
<munderover>
<mo>∑<!-- ∑ --></mo>
<mrow class="MJX-TeXAtom-ORD">
<mi>i</mi>
<mo>=</mo>
<mn>1</mn>
</mrow>
<mrow class="MJX-TeXAtom-ORD">
<mi>n</mi>
</mrow>
</munderover>
<msubsup>
<mi>T</mi>
<mrow class="MJX-TeXAtom-ORD">
<mn>1</mn>
<mo>,</mo>
<mi>i</mi>
</mrow>
<mrow class="MJX-TeXAtom-ORD">
<mo stretchy="false">(</mo>
<mi>t</mi>
<mo stretchy="false">)</mo>
</mrow>
</msubsup>
<mrow>
<mo>{</mo>
<mrow>
<mo>−<!-- − --></mo>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="false" scriptlevel="0">
<mfrac>
<mn>1</mn>
<mn>2</mn>
</mfrac>
</mstyle>
</mrow>
<mi>log</mi>
<mo>⁡<!-- ⁡ --></mo>
<mrow class="MJX-TeXAtom-ORD">
<mo stretchy="false">|</mo>
</mrow>
<msub>
<mi mathvariant="normal">Σ<!-- Σ --></mi>
<mrow class="MJX-TeXAtom-ORD">
<mn>1</mn>
</mrow>
</msub>
<mrow class="MJX-TeXAtom-ORD">
<mo stretchy="false">|</mo>
</mrow>
<mo>−<!-- − --></mo>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="false" scriptlevel="0">
<mfrac>
<mn>1</mn>
<mn>2</mn>
</mfrac>
</mstyle>
</mrow>
<mo stretchy="false">(</mo>
<msub>
<mrow class="MJX-TeXAtom-ORD">
<mi mathvariant="bold">x</mi>
</mrow>
<mrow class="MJX-TeXAtom-ORD">
<mi>i</mi>
</mrow>
</msub>
<mo>−<!-- − --></mo>
<msub>
<mrow class="MJX-TeXAtom-ORD">
<mi mathvariant="bold-italic">μ<!-- μ --></mi>
</mrow>
<mrow class="MJX-TeXAtom-ORD">
<mn>1</mn>
</mrow>
</msub>
<msup>
<mo stretchy="false">)</mo>
<mrow class="MJX-TeXAtom-ORD">
<mi mathvariant="normal">⊤<!-- ⊤ --></mi>
</mrow>
</msup>
<msubsup>
<mi mathvariant="normal">Σ<!-- Σ --></mi>
<mrow class="MJX-TeXAtom-ORD">
<mn>1</mn>
</mrow>
<mrow class="MJX-TeXAtom-ORD">
<mo>−<!-- − --></mo>
<mn>1</mn>
</mrow>
</msubsup>
<mo stretchy="false">(</mo>
<msub>
<mrow class="MJX-TeXAtom-ORD">
<mi mathvariant="bold">x</mi>
</mrow>
<mrow class="MJX-TeXAtom-ORD">
<mi>i</mi>
</mrow>
</msub>
<mo>−<!-- − --></mo>
<msub>
<mrow class="MJX-TeXAtom-ORD">
<mi mathvariant="bold-italic">μ<!-- μ --></mi>
</mrow>
<mrow class="MJX-TeXAtom-ORD">
<mn>1</mn>
</mrow>
</msub>
<mo stretchy="false">)</mo>
</mrow>
<mo>}</mo>
</mrow>
</mtd>
</mtr>
</mtable>
</mrow>
</mstyle>
</mrow>
<annotation encoding="application/x-tex">{\displaystyle {\begin{aligned}({\boldsymbol {\mu }}_{1}^{(t+1)},\Sigma _{1}^{(t+1)})&amp;={\underset {{\boldsymbol {\mu }}_{1},\Sigma _{1}}{\operatorname {arg\,max} }}Q(\theta \mid \theta ^{(t)})\\&amp;={\underset {{\boldsymbol {\mu }}_{1},\Sigma _{1}}{\operatorname {arg\,max} }}\sum _{i=1}^{n}T_{1,i}^{(t)}\left\{-{\tfrac {1}{2}}\log |\Sigma _{1}|-{\tfrac {1}{2}}(\mathbf {x} _{i}-{\boldsymbol {\mu }}_{1})^{\top }\Sigma _{1}^{-1}(\mathbf {x} _{i}-{\boldsymbol {\mu }}_{1})\right\}\end{aligned}}}</annotation>
</semantics>
</math></span><img alt="{\displaystyle {\begin{aligned}({\boldsymbol {\mu }}_{1}^{(t+1)},\Sigma _{1}^{(t+1)})&amp;={\underset {{\boldsymbol {\mu }}_{1},\Sigma _{1}}{\operatorname {arg\,max} }}Q(\theta \mid \theta ^{(t)})\\&amp;={\underset {{\boldsymbol {\mu }}_{1},\Sigma _{1}}{\operatorname {arg\,max} }}\sum _{i=1}^{n}T_{1,i}^{(t)}\left\{-{\tfrac {1}{2}}\log |\Sigma _{1}|-{\tfrac {1}{2}}(\mathbf {x} _{i}-{\boldsymbol {\mu }}_{1})^{\top }\Sigma _{1}^{-1}(\mathbf {x} _{i}-{\boldsymbol {\mu }}_{1})\right\}\end{aligned}}}" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/cbe750eef20b5c7fd235d28e3f1796c31abb70c0" style="vertical-align: -5.838ex; width:77.809ex; height:12.843ex;"/></span>.</dd></dl>
<p>This has the same form as a weighted MLE for a normal distribution, so
</p>
<dl><dd><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\displaystyle {\boldsymbol {\mu }}_{1}^{(t+1)}={\frac {\sum _{i=1}^{n}T_{1,i}^{(t)}\mathbf {x} _{i}}{\sum _{i=1}^{n}T_{1,i}^{(t)}}}}" xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="true" scriptlevel="0">
<msubsup>
<mrow class="MJX-TeXAtom-ORD">
<mi mathvariant="bold-italic">μ<!-- μ --></mi>
</mrow>
<mrow class="MJX-TeXAtom-ORD">
<mn>1</mn>
</mrow>
<mrow class="MJX-TeXAtom-ORD">
<mo stretchy="false">(</mo>
<mi>t</mi>
<mo>+</mo>
<mn>1</mn>
<mo stretchy="false">)</mo>
</mrow>
</msubsup>
<mo>=</mo>
<mrow class="MJX-TeXAtom-ORD">
<mfrac>
<mrow>
<munderover>
<mo>∑<!-- ∑ --></mo>
<mrow class="MJX-TeXAtom-ORD">
<mi>i</mi>
<mo>=</mo>
<mn>1</mn>
</mrow>
<mrow class="MJX-TeXAtom-ORD">
<mi>n</mi>
</mrow>
</munderover>
<msubsup>
<mi>T</mi>
<mrow class="MJX-TeXAtom-ORD">
<mn>1</mn>
<mo>,</mo>
<mi>i</mi>
</mrow>
<mrow class="MJX-TeXAtom-ORD">
<mo stretchy="false">(</mo>
<mi>t</mi>
<mo stretchy="false">)</mo>
</mrow>
</msubsup>
<msub>
<mrow class="MJX-TeXAtom-ORD">
<mi mathvariant="bold">x</mi>
</mrow>
<mrow class="MJX-TeXAtom-ORD">
<mi>i</mi>
</mrow>
</msub>
</mrow>
<mrow>
<munderover>
<mo>∑<!-- ∑ --></mo>
<mrow class="MJX-TeXAtom-ORD">
<mi>i</mi>
<mo>=</mo>
<mn>1</mn>
</mrow>
<mrow class="MJX-TeXAtom-ORD">
<mi>n</mi>
</mrow>
</munderover>
<msubsup>
<mi>T</mi>
<mrow class="MJX-TeXAtom-ORD">
<mn>1</mn>
<mo>,</mo>
<mi>i</mi>
</mrow>
<mrow class="MJX-TeXAtom-ORD">
<mo stretchy="false">(</mo>
<mi>t</mi>
<mo stretchy="false">)</mo>
</mrow>
</msubsup>
</mrow>
</mfrac>
</mrow>
</mstyle>
</mrow>
<annotation encoding="application/x-tex">{\displaystyle {\boldsymbol {\mu }}_{1}^{(t+1)}={\frac {\sum _{i=1}^{n}T_{1,i}^{(t)}\mathbf {x} _{i}}{\sum _{i=1}^{n}T_{1,i}^{(t)}}}}</annotation>
</semantics>
</math></span><img alt="\boldsymbol{\mu}_1^{(t+1)} = \frac{\sum_{i=1}^n T_{1,i}^{(t)} \mathbf{x}_i}{\sum_{i=1}^n T_{1,i}^{(t)}} " aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/45f3e73f50d396aadc98182709eee0c0d513aa6b" style="vertical-align: -3.838ex; width:21.563ex; height:8.843ex;"/></span> and <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\displaystyle \Sigma _{1}^{(t+1)}={\frac {\sum _{i=1}^{n}T_{1,i}^{(t)}(\mathbf {x} _{i}-{\boldsymbol {\mu }}_{1}^{(t+1)})(\mathbf {x} _{i}-{\boldsymbol {\mu }}_{1}^{(t+1)})^{\top }}{\sum _{i=1}^{n}T_{1,i}^{(t)}}}}" xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="true" scriptlevel="0">
<msubsup>
<mi mathvariant="normal">Σ<!-- Σ --></mi>
<mrow class="MJX-TeXAtom-ORD">
<mn>1</mn>
</mrow>
<mrow class="MJX-TeXAtom-ORD">
<mo stretchy="false">(</mo>
<mi>t</mi>
<mo>+</mo>
<mn>1</mn>
<mo stretchy="false">)</mo>
</mrow>
</msubsup>
<mo>=</mo>
<mrow class="MJX-TeXAtom-ORD">
<mfrac>
<mrow>
<munderover>
<mo>∑<!-- ∑ --></mo>
<mrow class="MJX-TeXAtom-ORD">
<mi>i</mi>
<mo>=</mo>
<mn>1</mn>
</mrow>
<mrow class="MJX-TeXAtom-ORD">
<mi>n</mi>
</mrow>
</munderover>
<msubsup>
<mi>T</mi>
<mrow class="MJX-TeXAtom-ORD">
<mn>1</mn>
<mo>,</mo>
<mi>i</mi>
</mrow>
<mrow class="MJX-TeXAtom-ORD">
<mo stretchy="false">(</mo>
<mi>t</mi>
<mo stretchy="false">)</mo>
</mrow>
</msubsup>
<mo stretchy="false">(</mo>
<msub>
<mrow class="MJX-TeXAtom-ORD">
<mi mathvariant="bold">x</mi>
</mrow>
<mrow class="MJX-TeXAtom-ORD">
<mi>i</mi>
</mrow>
</msub>
<mo>−<!-- − --></mo>
<msubsup>
<mrow class="MJX-TeXAtom-ORD">
<mi mathvariant="bold-italic">μ<!-- μ --></mi>
</mrow>
<mrow class="MJX-TeXAtom-ORD">
<mn>1</mn>
</mrow>
<mrow class="MJX-TeXAtom-ORD">
<mo stretchy="false">(</mo>
<mi>t</mi>
<mo>+</mo>
<mn>1</mn>
<mo stretchy="false">)</mo>
</mrow>
</msubsup>
<mo stretchy="false">)</mo>
<mo stretchy="false">(</mo>
<msub>
<mrow class="MJX-TeXAtom-ORD">
<mi mathvariant="bold">x</mi>
</mrow>
<mrow class="MJX-TeXAtom-ORD">
<mi>i</mi>
</mrow>
</msub>
<mo>−<!-- − --></mo>
<msubsup>
<mrow class="MJX-TeXAtom-ORD">
<mi mathvariant="bold-italic">μ<!-- μ --></mi>
</mrow>
<mrow class="MJX-TeXAtom-ORD">
<mn>1</mn>
</mrow>
<mrow class="MJX-TeXAtom-ORD">
<mo stretchy="false">(</mo>
<mi>t</mi>
<mo>+</mo>
<mn>1</mn>
<mo stretchy="false">)</mo>
</mrow>
</msubsup>
<msup>
<mo stretchy="false">)</mo>
<mrow class="MJX-TeXAtom-ORD">
<mi mathvariant="normal">⊤<!-- ⊤ --></mi>
</mrow>
</msup>
</mrow>
<mrow>
<munderover>
<mo>∑<!-- ∑ --></mo>
<mrow class="MJX-TeXAtom-ORD">
<mi>i</mi>
<mo>=</mo>
<mn>1</mn>
</mrow>
<mrow class="MJX-TeXAtom-ORD">
<mi>n</mi>
</mrow>
</munderover>
<msubsup>
<mi>T</mi>
<mrow class="MJX-TeXAtom-ORD">
<mn>1</mn>
<mo>,</mo>
<mi>i</mi>
</mrow>
<mrow class="MJX-TeXAtom-ORD">
<mo stretchy="false">(</mo>
<mi>t</mi>
<mo stretchy="false">)</mo>
</mrow>
</msubsup>
</mrow>
</mfrac>
</mrow>
</mstyle>
</mrow>
<annotation encoding="application/x-tex">{\displaystyle \Sigma _{1}^{(t+1)}={\frac {\sum _{i=1}^{n}T_{1,i}^{(t)}(\mathbf {x} _{i}-{\boldsymbol {\mu }}_{1}^{(t+1)})(\mathbf {x} _{i}-{\boldsymbol {\mu }}_{1}^{(t+1)})^{\top }}{\sum _{i=1}^{n}T_{1,i}^{(t)}}}}</annotation>
</semantics>
</math></span><img alt="\Sigma_1^{(t+1)} = \frac{\sum_{i=1}^n T_{1,i}^{(t)} (\mathbf{x}_i - \boldsymbol{\mu}_1^{(t+1)}) (\mathbf{x}_i - \boldsymbol{\mu}_1^{(t+1)})^\top }{\sum_{i=1}^n T_{1,i}^{(t)}} " aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/a92651be432155520db19dc0b4da807039d96eb0" style="vertical-align: -3.838ex; width:46.319ex; height:8.843ex;"/></span></dd></dl>
<p>and, by symmetry
</p>
<dl><dd><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\displaystyle {\boldsymbol {\mu }}_{2}^{(t+1)}={\frac {\sum _{i=1}^{n}T_{2,i}^{(t)}\mathbf {x} _{i}}{\sum _{i=1}^{n}T_{2,i}^{(t)}}}}" xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="true" scriptlevel="0">
<msubsup>
<mrow class="MJX-TeXAtom-ORD">
<mi mathvariant="bold-italic">μ<!-- μ --></mi>
</mrow>
<mrow class="MJX-TeXAtom-ORD">
<mn>2</mn>
</mrow>
<mrow class="MJX-TeXAtom-ORD">
<mo stretchy="false">(</mo>
<mi>t</mi>
<mo>+</mo>
<mn>1</mn>
<mo stretchy="false">)</mo>
</mrow>
</msubsup>
<mo>=</mo>
<mrow class="MJX-TeXAtom-ORD">
<mfrac>
<mrow>
<munderover>
<mo>∑<!-- ∑ --></mo>
<mrow class="MJX-TeXAtom-ORD">
<mi>i</mi>
<mo>=</mo>
<mn>1</mn>
</mrow>
<mrow class="MJX-TeXAtom-ORD">
<mi>n</mi>
</mrow>
</munderover>
<msubsup>
<mi>T</mi>
<mrow class="MJX-TeXAtom-ORD">
<mn>2</mn>
<mo>,</mo>
<mi>i</mi>
</mrow>
<mrow class="MJX-TeXAtom-ORD">
<mo stretchy="false">(</mo>
<mi>t</mi>
<mo stretchy="false">)</mo>
</mrow>
</msubsup>
<msub>
<mrow class="MJX-TeXAtom-ORD">
<mi mathvariant="bold">x</mi>
</mrow>
<mrow class="MJX-TeXAtom-ORD">
<mi>i</mi>
</mrow>
</msub>
</mrow>
<mrow>
<munderover>
<mo>∑<!-- ∑ --></mo>
<mrow class="MJX-TeXAtom-ORD">
<mi>i</mi>
<mo>=</mo>
<mn>1</mn>
</mrow>
<mrow class="MJX-TeXAtom-ORD">
<mi>n</mi>
</mrow>
</munderover>
<msubsup>
<mi>T</mi>
<mrow class="MJX-TeXAtom-ORD">
<mn>2</mn>
<mo>,</mo>
<mi>i</mi>
</mrow>
<mrow class="MJX-TeXAtom-ORD">
<mo stretchy="false">(</mo>
<mi>t</mi>
<mo stretchy="false">)</mo>
</mrow>
</msubsup>
</mrow>
</mfrac>
</mrow>
</mstyle>
</mrow>
<annotation encoding="application/x-tex">{\displaystyle {\boldsymbol {\mu }}_{2}^{(t+1)}={\frac {\sum _{i=1}^{n}T_{2,i}^{(t)}\mathbf {x} _{i}}{\sum _{i=1}^{n}T_{2,i}^{(t)}}}}</annotation>
</semantics>
</math></span><img alt="\boldsymbol{\mu}_2^{(t+1)} = \frac{\sum_{i=1}^n T_{2,i}^{(t)} \mathbf{x}_i}{\sum_{i=1}^n T_{2,i}^{(t)}} " aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/939349990d3a58d89689a8872f23fbd27c828a43" style="vertical-align: -3.838ex; width:21.563ex; height:8.843ex;"/></span> and <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\displaystyle \Sigma _{2}^{(t+1)}={\frac {\sum _{i=1}^{n}T_{2,i}^{(t)}(\mathbf {x} _{i}-{\boldsymbol {\mu }}_{2}^{(t+1)})(\mathbf {x} _{i}-{\boldsymbol {\mu }}_{2}^{(t+1)})^{\top }}{\sum _{i=1}^{n}T_{2,i}^{(t)}}}}" xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="true" scriptlevel="0">
<msubsup>
<mi mathvariant="normal">Σ<!-- Σ --></mi>
<mrow class="MJX-TeXAtom-ORD">
<mn>2</mn>
</mrow>
<mrow class="MJX-TeXAtom-ORD">
<mo stretchy="false">(</mo>
<mi>t</mi>
<mo>+</mo>
<mn>1</mn>
<mo stretchy="false">)</mo>
</mrow>
</msubsup>
<mo>=</mo>
<mrow class="MJX-TeXAtom-ORD">
<mfrac>
<mrow>
<munderover>
<mo>∑<!-- ∑ --></mo>
<mrow class="MJX-TeXAtom-ORD">
<mi>i</mi>
<mo>=</mo>
<mn>1</mn>
</mrow>
<mrow class="MJX-TeXAtom-ORD">
<mi>n</mi>
</mrow>
</munderover>
<msubsup>
<mi>T</mi>
<mrow class="MJX-TeXAtom-ORD">
<mn>2</mn>
<mo>,</mo>
<mi>i</mi>
</mrow>
<mrow class="MJX-TeXAtom-ORD">
<mo stretchy="false">(</mo>
<mi>t</mi>
<mo stretchy="false">)</mo>
</mrow>
</msubsup>
<mo stretchy="false">(</mo>
<msub>
<mrow class="MJX-TeXAtom-ORD">
<mi mathvariant="bold">x</mi>
</mrow>
<mrow class="MJX-TeXAtom-ORD">
<mi>i</mi>
</mrow>
</msub>
<mo>−<!-- − --></mo>
<msubsup>
<mrow class="MJX-TeXAtom-ORD">
<mi mathvariant="bold-italic">μ<!-- μ --></mi>
</mrow>
<mrow class="MJX-TeXAtom-ORD">
<mn>2</mn>
</mrow>
<mrow class="MJX-TeXAtom-ORD">
<mo stretchy="false">(</mo>
<mi>t</mi>
<mo>+</mo>
<mn>1</mn>
<mo stretchy="false">)</mo>
</mrow>
</msubsup>
<mo stretchy="false">)</mo>
<mo stretchy="false">(</mo>
<msub>
<mrow class="MJX-TeXAtom-ORD">
<mi mathvariant="bold">x</mi>
</mrow>
<mrow class="MJX-TeXAtom-ORD">
<mi>i</mi>
</mrow>
</msub>
<mo>−<!-- − --></mo>
<msubsup>
<mrow class="MJX-TeXAtom-ORD">
<mi mathvariant="bold-italic">μ<!-- μ --></mi>
</mrow>
<mrow class="MJX-TeXAtom-ORD">
<mn>2</mn>
</mrow>
<mrow class="MJX-TeXAtom-ORD">
<mo stretchy="false">(</mo>
<mi>t</mi>
<mo>+</mo>
<mn>1</mn>
<mo stretchy="false">)</mo>
</mrow>
</msubsup>
<msup>
<mo stretchy="false">)</mo>
<mrow class="MJX-TeXAtom-ORD">
<mi mathvariant="normal">⊤<!-- ⊤ --></mi>
</mrow>
</msup>
</mrow>
<mrow>
<munderover>
<mo>∑<!-- ∑ --></mo>
<mrow class="MJX-TeXAtom-ORD">
<mi>i</mi>
<mo>=</mo>
<mn>1</mn>
</mrow>
<mrow class="MJX-TeXAtom-ORD">
<mi>n</mi>
</mrow>
</munderover>
<msubsup>
<mi>T</mi>
<mrow class="MJX-TeXAtom-ORD">
<mn>2</mn>
<mo>,</mo>
<mi>i</mi>
</mrow>
<mrow class="MJX-TeXAtom-ORD">
<mo stretchy="false">(</mo>
<mi>t</mi>
<mo stretchy="false">)</mo>
</mrow>
</msubsup>
</mrow>
</mfrac>
</mrow>
</mstyle>
</mrow>
<annotation encoding="application/x-tex">{\displaystyle \Sigma _{2}^{(t+1)}={\frac {\sum _{i=1}^{n}T_{2,i}^{(t)}(\mathbf {x} _{i}-{\boldsymbol {\mu }}_{2}^{(t+1)})(\mathbf {x} _{i}-{\boldsymbol {\mu }}_{2}^{(t+1)})^{\top }}{\sum _{i=1}^{n}T_{2,i}^{(t)}}}}</annotation>
</semantics>
</math></span><img alt="\Sigma_2^{(t+1)} = \frac{\sum_{i=1}^n T_{2,i}^{(t)} (\mathbf{x}_i - \boldsymbol{\mu}_2^{(t+1)}) (\mathbf{x}_i - \boldsymbol{\mu}_2^{(t+1)})^\top }{\sum_{i=1}^n T_{2,i}^{(t)}} " aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/f11a366cc98f2b9774ca34b28f4506c031b92b6f" style="vertical-align: -3.838ex; width:46.319ex; height:8.843ex;"/></span>.</dd></dl>
<h4><span class="mw-headline" id="Termination">Termination</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Expectation%E2%80%93maximization_algorithm&amp;action=edit&amp;section=17" title="Edit section: Termination">edit</a><span class="mw-editsection-bracket">]</span></span></h4>
<p>Conclude the iterative process if <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\displaystyle E_{Z\mid \theta ^{(t)},\mathbf {x} }[\log L(\theta ^{(t)};\mathbf {x} ,\mathbf {Z} )]\leq E_{Z\mid \theta ^{(t-1)},\mathbf {x} }[\log L(\theta ^{(t-1)};\mathbf {x} ,\mathbf {Z} )]+\varepsilon }" xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="true" scriptlevel="0">
<msub>
<mi>E</mi>
<mrow class="MJX-TeXAtom-ORD">
<mi>Z</mi>
<mo>∣<!-- ∣ --></mo>
<msup>
<mi>θ<!-- θ --></mi>
<mrow class="MJX-TeXAtom-ORD">
<mo stretchy="false">(</mo>
<mi>t</mi>
<mo stretchy="false">)</mo>
</mrow>
</msup>
<mo>,</mo>
<mrow class="MJX-TeXAtom-ORD">
<mi mathvariant="bold">x</mi>
</mrow>
</mrow>
</msub>
<mo stretchy="false">[</mo>
<mi>log</mi>
<mo>⁡<!-- ⁡ --></mo>
<mi>L</mi>
<mo stretchy="false">(</mo>
<msup>
<mi>θ<!-- θ --></mi>
<mrow class="MJX-TeXAtom-ORD">
<mo stretchy="false">(</mo>
<mi>t</mi>
<mo stretchy="false">)</mo>
</mrow>
</msup>
<mo>;</mo>
<mrow class="MJX-TeXAtom-ORD">
<mi mathvariant="bold">x</mi>
</mrow>
<mo>,</mo>
<mrow class="MJX-TeXAtom-ORD">
<mi mathvariant="bold">Z</mi>
</mrow>
<mo stretchy="false">)</mo>
<mo stretchy="false">]</mo>
<mo>≤<!-- ≤ --></mo>
<msub>
<mi>E</mi>
<mrow class="MJX-TeXAtom-ORD">
<mi>Z</mi>
<mo>∣<!-- ∣ --></mo>
<msup>
<mi>θ<!-- θ --></mi>
<mrow class="MJX-TeXAtom-ORD">
<mo stretchy="false">(</mo>
<mi>t</mi>
<mo>−<!-- − --></mo>
<mn>1</mn>
<mo stretchy="false">)</mo>
</mrow>
</msup>
<mo>,</mo>
<mrow class="MJX-TeXAtom-ORD">
<mi mathvariant="bold">x</mi>
</mrow>
</mrow>
</msub>
<mo stretchy="false">[</mo>
<mi>log</mi>
<mo>⁡<!-- ⁡ --></mo>
<mi>L</mi>
<mo stretchy="false">(</mo>
<msup>
<mi>θ<!-- θ --></mi>
<mrow class="MJX-TeXAtom-ORD">
<mo stretchy="false">(</mo>
<mi>t</mi>
<mo>−<!-- − --></mo>
<mn>1</mn>
<mo stretchy="false">)</mo>
</mrow>
</msup>
<mo>;</mo>
<mrow class="MJX-TeXAtom-ORD">
<mi mathvariant="bold">x</mi>
</mrow>
<mo>,</mo>
<mrow class="MJX-TeXAtom-ORD">
<mi mathvariant="bold">Z</mi>
</mrow>
<mo stretchy="false">)</mo>
<mo stretchy="false">]</mo>
<mo>+</mo>
<mi>ε<!-- ε --></mi>
</mstyle>
</mrow>
<annotation encoding="application/x-tex">{\displaystyle E_{Z\mid \theta ^{(t)},\mathbf {x} }[\log L(\theta ^{(t)};\mathbf {x} ,\mathbf {Z} )]\leq E_{Z\mid \theta ^{(t-1)},\mathbf {x} }[\log L(\theta ^{(t-1)};\mathbf {x} ,\mathbf {Z} )]+\varepsilon }</annotation>
</semantics>
</math></span><img alt="{\displaystyle E_{Z\mid \theta ^{(t)},\mathbf {x} }[\log L(\theta ^{(t)};\mathbf {x} ,\mathbf {Z} )]\leq E_{Z\mid \theta ^{(t-1)},\mathbf {x} }[\log L(\theta ^{(t-1)};\mathbf {x} ,\mathbf {Z} )]+\varepsilon }" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/1936cdfb30674d85c6029aed6c4b3e571300374b" style="vertical-align: -1.505ex; width:58.543ex; height:4.009ex;"/></span> for <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\displaystyle \varepsilon }" xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="true" scriptlevel="0">
<mi>ε<!-- ε --></mi>
</mstyle>
</mrow>
<annotation encoding="application/x-tex">{\displaystyle \varepsilon }</annotation>
</semantics>
</math></span><img alt="\varepsilon " aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/a30c89172e5b88edbd45d3e2772c7f5e562e5173" style="vertical-align: -0.338ex; width:1.083ex; height:1.676ex;"/></span> below some preset threshold.
</p>
<h4><span class="mw-headline" id="Generalization">Generalization</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Expectation%E2%80%93maximization_algorithm&amp;action=edit&amp;section=18" title="Edit section: Generalization">edit</a><span class="mw-editsection-bracket">]</span></span></h4>
<p>The algorithm illustrated above can be generalized for mixtures of more than two <a href="/wiki/Multivariate_normal_distribution" title="Multivariate normal distribution">multivariate normal distributions</a>.
</p>
<h3><span class="mw-headline" id="Truncated_and_censored_regression">Truncated and censored regression</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Expectation%E2%80%93maximization_algorithm&amp;action=edit&amp;section=19" title="Edit section: Truncated and censored regression">edit</a><span class="mw-editsection-bracket">]</span></span></h3>
<p>The EM algorithm has been implemented in the case where an underlying <a href="/wiki/Linear_regression" title="Linear regression">linear regression</a> model exists explaining the variation of some quantity, but where the values actually observed are censored or truncated versions of those represented in the model.<sup class="reference" id="cite_ref-Wolynetz_33-0"><a href="#cite_note-Wolynetz-33">[33]</a></sup>  Special cases of this model include censored or truncated observations from one <a href="/wiki/Normal_distribution" title="Normal distribution">normal distribution</a>.<sup class="reference" id="cite_ref-Wolynetz_33-1"><a href="#cite_note-Wolynetz-33">[33]</a></sup>
</p>
<h2><span class="mw-headline" id="Alternatives">Alternatives</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Expectation%E2%80%93maximization_algorithm&amp;action=edit&amp;section=20" title="Edit section: Alternatives">edit</a><span class="mw-editsection-bracket">]</span></span></h2>
<p>EM typically converges to a local optimum, not necessarily the global optimum, with no bound on the convergence rate in general. It is possible that it can be arbitrarily poor in high dimensions and there can be an exponential number of local optima. Hence, a need exists for alternative methods for guaranteed learning, especially in the high-dimensional setting. Alternatives to EM exist with better guarantees for consistency, which are termed <i>moment-based approaches</i><sup class="reference" id="cite_ref-34"><a href="#cite_note-34">[34]</a></sup> or the so-called <i>spectral techniques</i><sup class="reference" id="cite_ref-35"><a href="#cite_note-35">[35]</a></sup><sup class="reference" id="cite_ref-36"><a href="#cite_note-36">[36]</a></sup><sup class="noprint Inline-Template Template-Fact" style="white-space:nowrap;">[<i><a href="/wiki/Wikipedia:Citation_needed" title="Wikipedia:Citation needed"><span title="This claim needs references to reliable sources. (April 2019)">citation needed</span></a></i>]</sup>. Moment-based approaches to learning the parameters of a probabilistic model are of increasing interest recently since they enjoy guarantees such as global convergence under certain conditions unlike EM which is often plagued by the issue of getting stuck in local optima. Algorithms with guarantees for learning can be derived for a number of important models such as mixture models, HMMs etc. For these spectral methods, no spurious local optima occur, and the true parameters can be consistently estimated under some regularity conditions<sup class="noprint Inline-Template Template-Fact" style="white-space:nowrap;">[<i><a href="/wiki/Wikipedia:Citation_needed" title="Wikipedia:Citation needed"><span title="This claim needs references to reliable sources. (April 2019)">citation needed</span></a></i>]</sup>.
</p>
<h2><span class="mw-headline" id="See_also">See also</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Expectation%E2%80%93maximization_algorithm&amp;action=edit&amp;section=21" title="Edit section: See also">edit</a><span class="mw-editsection-bracket">]</span></span></h2>
<ul><li><a href="/wiki/Mixture_distribution" title="Mixture distribution">mixture distribution</a></li>
<li><a class="mw-redirect" href="/wiki/Compound_distribution" title="Compound distribution">compound distribution</a></li>
<li><a href="/wiki/Density_estimation" title="Density estimation">density estimation</a></li>
<li><a href="/wiki/Total_absorption_spectroscopy" title="Total absorption spectroscopy">total absorption spectroscopy</a></li>
<li>The EM algorithm can be viewed as a special case of the <a href="/wiki/MM_algorithm" title="MM algorithm">majorize-minimization (MM) algorithm</a>.<sup class="reference" id="cite_ref-37"><a href="#cite_note-37">[37]</a></sup></li></ul>
<h2><span class="mw-headline" id="References">References</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Expectation%E2%80%93maximization_algorithm&amp;action=edit&amp;section=22" title="Edit section: References">edit</a><span class="mw-editsection-bracket">]</span></span></h2>
<div class="reflist" style="list-style-type: decimal;">
<div class="mw-references-wrap mw-references-columns"><ol class="references">
<li id="cite_note-Dempster1977-1"><span class="mw-cite-backlink"><b><a href="#cite_ref-Dempster1977_1-0">^</a></b></span> <span class="reference-text">
<cite class="citation journal"><a href="/wiki/Arthur_P._Dempster" title="Arthur P. Dempster">Dempster, A.P.</a>; <a href="/wiki/Nan_Laird" title="Nan Laird">Laird, N.M.</a>; <a href="/wiki/Donald_Rubin" title="Donald Rubin">Rubin, D.B.</a> (1977). "Maximum Likelihood from Incomplete Data via the EM Algorithm". <i><a class="mw-redirect" href="/wiki/Journal_of_the_Royal_Statistical_Society,_Series_B" title="Journal of the Royal Statistical Society, Series B">Journal of the Royal Statistical Society, Series B</a></i>. <b>39</b> (1): 1–38. <a href="/wiki/JSTOR" title="JSTOR">JSTOR</a> <a class="external text" href="//www.jstor.org/stable/2984875" rel="nofollow">2984875</a>. <a href="/wiki/Mathematical_Reviews" title="Mathematical Reviews">MR</a> <a class="external text" href="//www.ams.org/mathscinet-getitem?mr=0501537" rel="nofollow">0501537</a>.</cite><span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Journal+of+the+Royal+Statistical+Society%2C+Series+B&amp;rft.atitle=Maximum+Likelihood+from+Incomplete+Data+via+the+EM+Algorithm&amp;rft.volume=39&amp;rft.issue=1&amp;rft.pages=1-38&amp;rft.date=1977&amp;rft_id=%2F%2Fwww.jstor.org%2Fstable%2F2984875&amp;rft_id=%2F%2Fwww.ams.org%2Fmathscinet-getitem%3Fmr%3D0501537&amp;rft.aulast=Dempster&amp;rft.aufirst=A.P.&amp;rft.au=Laird%2C+N.M.&amp;rft.au=Rubin%2C+D.B.&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AExpectation%E2%80%93maximization+algorithm"></span><style data-mw-deduplicate="TemplateStyles:r935243608">.mw-parser-output cite.citation{font-style:inherit}.mw-parser-output .citation q{quotes:"\"""\"""'""'"}.mw-parser-output .id-lock-free a,.mw-parser-output .citation .cs1-lock-free a{background:url("//upload.wikimedia.org/wikipedia/commons/thumb/6/65/Lock-green.svg/9px-Lock-green.svg.png")no-repeat;background-position:right .1em center}.mw-parser-output .id-lock-limited a,.mw-parser-output .id-lock-registration a,.mw-parser-output .citation .cs1-lock-limited a,.mw-parser-output .citation .cs1-lock-registration a{background:url("//upload.wikimedia.org/wikipedia/commons/thumb/d/d6/Lock-gray-alt-2.svg/9px-Lock-gray-alt-2.svg.png")no-repeat;background-position:right .1em center}.mw-parser-output .id-lock-subscription a,.mw-parser-output .citation .cs1-lock-subscription a{background:url("//upload.wikimedia.org/wikipedia/commons/thumb/a/aa/Lock-red-alt-2.svg/9px-Lock-red-alt-2.svg.png")no-repeat;background-position:right .1em center}.mw-parser-output .cs1-subscription,.mw-parser-output .cs1-registration{color:#555}.mw-parser-output .cs1-subscription span,.mw-parser-output .cs1-registration span{border-bottom:1px dotted;cursor:help}.mw-parser-output .cs1-ws-icon a{background:url("//upload.wikimedia.org/wikipedia/commons/thumb/4/4c/Wikisource-logo.svg/12px-Wikisource-logo.svg.png")no-repeat;background-position:right .1em center}.mw-parser-output code.cs1-code{color:inherit;background:inherit;border:inherit;padding:inherit}.mw-parser-output .cs1-hidden-error{display:none;font-size:100%}.mw-parser-output .cs1-visible-error{font-size:100%}.mw-parser-output .cs1-maint{display:none;color:#33aa33;margin-left:0.3em}.mw-parser-output .cs1-subscription,.mw-parser-output .cs1-registration,.mw-parser-output .cs1-format{font-size:95%}.mw-parser-output .cs1-kern-left,.mw-parser-output .cs1-kern-wl-left{padding-left:0.2em}.mw-parser-output .cs1-kern-right,.mw-parser-output .cs1-kern-wl-right{padding-right:0.2em}</style></span>
</li>
<li id="cite_note-2"><span class="mw-cite-backlink"><b><a href="#cite_ref-2">^</a></b></span> <span class="reference-text"><cite class="citation journal">Ceppelini, R.M. (1955). "The estimation of gene frequencies in a random-mating population". <i>Ann. Hum. Genet</i>. <b>20</b> (2): 97–115. <a href="/wiki/Digital_object_identifier" title="Digital object identifier">doi</a>:<a class="external text" href="https://doi.org/10.1111%2Fj.1469-1809.1955.tb01360.x" rel="nofollow">10.1111/j.1469-1809.1955.tb01360.x</a>. <a class="mw-redirect" href="/wiki/PubMed_Identifier" title="PubMed Identifier">PMID</a> <a class="external text" href="//pubmed.ncbi.nlm.nih.gov/13268982" rel="nofollow">13268982</a>.</cite><span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Ann.+Hum.+Genet.&amp;rft.atitle=The+estimation+of+gene+frequencies+in+a+random-mating+population&amp;rft.volume=20&amp;rft.issue=2&amp;rft.pages=97-115&amp;rft.date=1955&amp;rft_id=info%3Adoi%2F10.1111%2Fj.1469-1809.1955.tb01360.x&amp;rft_id=info%3Apmid%2F13268982&amp;rft.aulast=Ceppelini&amp;rft.aufirst=R.M.&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AExpectation%E2%80%93maximization+algorithm"></span><link href="mw-data:TemplateStyles:r935243608" rel="mw-deduplicated-inline-style"/></span>
</li>
<li id="cite_note-Sundberg1974-3"><span class="mw-cite-backlink"><b><a href="#cite_ref-Sundberg1974_3-0">^</a></b></span> <span class="reference-text"><cite class="citation journal">Sundberg, Rolf (1974). "Maximum likelihood theory for incomplete data from an exponential family". <i>Scandinavian Journal of Statistics</i>. <b>1</b> (2): 49–58. <a href="/wiki/JSTOR" title="JSTOR">JSTOR</a> <a class="external text" href="//www.jstor.org/stable/4615553" rel="nofollow">4615553</a>. <a href="/wiki/Mathematical_Reviews" title="Mathematical Reviews">MR</a> <a class="external text" href="//www.ams.org/mathscinet-getitem?mr=0381110" rel="nofollow">0381110</a>.</cite><span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Scandinavian+Journal+of+Statistics&amp;rft.atitle=Maximum+likelihood+theory+for+incomplete+data+from+an+exponential+family&amp;rft.volume=1&amp;rft.issue=2&amp;rft.pages=49-58&amp;rft.date=1974&amp;rft_id=%2F%2Fwww.jstor.org%2Fstable%2F4615553&amp;rft_id=%2F%2Fwww.ams.org%2Fmathscinet-getitem%3Fmr%3D381110&amp;rft.aulast=Sundberg&amp;rft.aufirst=Rolf&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AExpectation%E2%80%93maximization+algorithm"></span><link href="mw-data:TemplateStyles:r935243608" rel="mw-deduplicated-inline-style"/></span>
</li>
<li id="cite_note-Sundberg1971-4"><span class="mw-cite-backlink">^ <a href="#cite_ref-Sundberg1971_4-0"><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-Sundberg1971_4-1"><sup><i><b>b</b></i></sup></a></span> <span class="reference-text">
Rolf Sundberg. 1971. <i>Maximum likelihood theory and applications for distributions generated when observing a function of an exponential family variable</i>. Dissertation, Institute for Mathematical Statistics, Stockholm University.</span>
</li>
<li id="cite_note-Sundberg1976-5"><span class="mw-cite-backlink">^ <a href="#cite_ref-Sundberg1976_5-0"><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-Sundberg1976_5-1"><sup><i><b>b</b></i></sup></a></span> <span class="reference-text"><cite class="citation journal">Sundberg, Rolf (1976). "An iterative method for solution of the likelihood equations for incomplete data from exponential families". <i>Communications in Statistics – Simulation and Computation</i>. <b>5</b> (1): 55–64. <a href="/wiki/Digital_object_identifier" title="Digital object identifier">doi</a>:<a class="external text" href="https://doi.org/10.1080%2F03610917608812007" rel="nofollow">10.1080/03610917608812007</a>. <a href="/wiki/Mathematical_Reviews" title="Mathematical Reviews">MR</a> <a class="external text" href="//www.ams.org/mathscinet-getitem?mr=0443190" rel="nofollow">0443190</a>.</cite><span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Communications+in+Statistics+%E2%80%93+Simulation+and+Computation&amp;rft.atitle=An+iterative+method+for+solution+of+the+likelihood+equations+for+incomplete+data+from+exponential+families&amp;rft.volume=5&amp;rft.issue=1&amp;rft.pages=55-64&amp;rft.date=1976&amp;rft_id=info%3Adoi%2F10.1080%2F03610917608812007&amp;rft_id=%2F%2Fwww.ams.org%2Fmathscinet-getitem%3Fmr%3D443190&amp;rft.aulast=Sundberg&amp;rft.aufirst=Rolf&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AExpectation%E2%80%93maximization+algorithm"></span><link href="mw-data:TemplateStyles:r935243608" rel="mw-deduplicated-inline-style"/></span>
</li>
<li id="cite_note-6"><span class="mw-cite-backlink"><b><a href="#cite_ref-6">^</a></b></span> <span class="reference-text">See the acknowledgement by Dempster, Laird and Rubin on pages 3, 5 and 11.</span>
</li>
<li id="cite_note-7"><span class="mw-cite-backlink"><b><a href="#cite_ref-7">^</a></b></span> <span class="reference-text">G. Kulldorff. 1961.<i> Contributions to the theory of estimation from grouped and partially grouped samples</i>. Almqvist &amp; Wiksell.</span>
</li>
<li id="cite_note-Martin-Löf1963-8"><span class="mw-cite-backlink">^ <a href="#cite_ref-Martin-Löf1963_8-0"><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-Martin-Löf1963_8-1"><sup><i><b>b</b></i></sup></a></span> <span class="reference-text">Anders Martin-Löf. 1963. "Utvärdering av livslängder i subnanosekundsområdet" ("Evaluation of sub-nanosecond lifetimes"). ("Sundberg formula")</span>
</li>
<li id="cite_note-Martin-Löf1966-9"><span class="mw-cite-backlink">^ <a href="#cite_ref-Martin-Löf1966_9-0"><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-Martin-Löf1966_9-1"><sup><i><b>b</b></i></sup></a></span> <span class="reference-text"><a href="/wiki/Per_Martin-L%C3%B6f" title="Per Martin-Löf">Per Martin-Löf</a>. 1966. <i>Statistics from the point of view of statistical mechanics</i>. Lecture notes, Mathematical Institute, Aarhus University. ("Sundberg formula" credited to Anders Martin-Löf).</span>
</li>
<li id="cite_note-Martin-Löf1970-10"><span class="mw-cite-backlink">^ <a href="#cite_ref-Martin-Löf1970_10-0"><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-Martin-Löf1970_10-1"><sup><i><b>b</b></i></sup></a></span> <span class="reference-text"><a href="/wiki/Per_Martin-L%C3%B6f" title="Per Martin-Löf">Per Martin-Löf</a>. 1970. <i>Statistika Modeller (Statistical Models): Anteckningar från seminarier läsåret 1969–1970 (Notes from seminars in the academic year 1969-1970), with the assistance of Rolf Sundberg.</i> Stockholm University. ("Sundberg formula")</span>
</li>
<li id="cite_note-Martin-Löf1974a-11"><span class="mw-cite-backlink">^ <a href="#cite_ref-Martin-Löf1974a_11-0"><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-Martin-Löf1974a_11-1"><sup><i><b>b</b></i></sup></a></span> <span class="reference-text">Martin-Löf, P. The notion of redundancy and its use as a quantitative measure of the deviation between a statistical hypothesis and a set of observational data. With a discussion by F. Abildgård, <a href="/wiki/Arthur_P._Dempster" title="Arthur P. Dempster">A. P. Dempster</a>, <a class="mw-redirect" href="/wiki/D._Basu" title="D. Basu">D. Basu</a>, <a class="mw-redirect" href="/wiki/D._R._Cox" title="D. R. Cox">D. R. Cox</a>, <a href="/wiki/A._W._F._Edwards" title="A. W. F. Edwards">A. W. F. Edwards</a>, D. A. Sprott, <a class="mw-redirect" href="/wiki/George_A._Barnard" title="George A. Barnard">G. A. Barnard</a>, O. Barndorff-Nielsen, J. D. Kalbfleisch and <a href="/wiki/Rasch_model" title="Rasch model">G. Rasch</a> and a reply by the author. <i>Proceedings of Conference on Foundational Questions in Statistical Inference</i> (Aarhus, 1973), pp. 1–42. Memoirs, No. 1, Dept. Theoret. Statist., Inst. Math., Univ. Aarhus, Aarhus, 1974.</span>
</li>
<li id="cite_note-Martin-Löf1974b-12"><span class="mw-cite-backlink">^ <a href="#cite_ref-Martin-Löf1974b_12-0"><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-Martin-Löf1974b_12-1"><sup><i><b>b</b></i></sup></a></span> <span class="reference-text"><cite class="citation journal">Martin-Löf, Per (1974). "The notion of redundancy and its use as a quantitative measure of the discrepancy between a statistical hypothesis and a set of observational data". <i>Scand. J. Statist</i>. <b>1</b> (1): 3–18.</cite><span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Scand.+J.+Statist.&amp;rft.atitle=The+notion+of+redundancy+and+its+use+as+a+quantitative+measure+of+the+discrepancy+between+a+statistical+hypothesis+and+a+set+of+observational+data&amp;rft.volume=1&amp;rft.issue=1&amp;rft.pages=3-18&amp;rft.date=1974&amp;rft.aulast=Martin-L%C3%B6f&amp;rft.aufirst=Per&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AExpectation%E2%80%93maximization+algorithm"></span><link href="mw-data:TemplateStyles:r935243608" rel="mw-deduplicated-inline-style"/></span>
</li>
<li id="cite_note-Wu-13"><span class="mw-cite-backlink">^ <a href="#cite_ref-Wu_13-0"><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-Wu_13-1"><sup><i><b>b</b></i></sup></a> <a href="#cite_ref-Wu_13-2"><sup><i><b>c</b></i></sup></a></span> <span class="reference-text">
<cite class="citation journal">Wu, C. F. Jeff (Mar 1983). "On the Convergence Properties of the EM Algorithm". <i><a href="/wiki/Annals_of_Statistics" title="Annals of Statistics">Annals of Statistics</a></i>. <b>11</b> (1): 95–103. <a href="/wiki/Digital_object_identifier" title="Digital object identifier">doi</a>:<a class="external text" href="https://doi.org/10.1214%2Faos%2F1176346060" rel="nofollow">10.1214/aos/1176346060</a>. <a href="/wiki/JSTOR" title="JSTOR">JSTOR</a> <a class="external text" href="//www.jstor.org/stable/2240463" rel="nofollow">2240463</a>. <a href="/wiki/Mathematical_Reviews" title="Mathematical Reviews">MR</a> <a class="external text" href="//www.ams.org/mathscinet-getitem?mr=0684867" rel="nofollow">0684867</a>.</cite><span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Annals+of+Statistics&amp;rft.atitle=On+the+Convergence+Properties+of+the+EM+Algorithm&amp;rft.volume=11&amp;rft.issue=1&amp;rft.pages=95-103&amp;rft.date=1983-03&amp;rft_id=%2F%2Fwww.ams.org%2Fmathscinet-getitem%3Fmr%3D684867&amp;rft_id=%2F%2Fwww.jstor.org%2Fstable%2F2240463&amp;rft_id=info%3Adoi%2F10.1214%2Faos%2F1176346060&amp;rft.aulast=Wu&amp;rft.aufirst=C.+F.+Jeff&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AExpectation%E2%80%93maximization+algorithm"></span><link href="mw-data:TemplateStyles:r935243608" rel="mw-deduplicated-inline-style"/></span>
</li>
<li id="cite_note-Little1987-14"><span class="mw-cite-backlink"><b><a href="#cite_ref-Little1987_14-0">^</a></b></span> <span class="reference-text"><cite class="citation book">Little, Roderick J.A.; <a href="/wiki/Donald_Rubin" title="Donald Rubin">Rubin, Donald B.</a> (1987). <i>Statistical Analysis with Missing Data</i>. Wiley Series in Probability and Mathematical Statistics. New York: John Wiley &amp; Sons. pp. 134–136. <a href="/wiki/International_Standard_Book_Number" title="International Standard Book Number">ISBN</a> <a href="/wiki/Special:BookSources/978-0-471-80254-9" title="Special:BookSources/978-0-471-80254-9"><bdi>978-0-471-80254-9</bdi></a>.</cite><span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=Statistical+Analysis+with+Missing+Data&amp;rft.place=New+York&amp;rft.series=Wiley+Series+in+Probability+and+Mathematical+Statistics&amp;rft.pages=134-136&amp;rft.pub=John+Wiley+%26+Sons&amp;rft.date=1987&amp;rft.isbn=978-0-471-80254-9&amp;rft.aulast=Little&amp;rft.aufirst=Roderick+J.A.&amp;rft.au=Rubin%2C+Donald+B.&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AExpectation%E2%80%93maximization+algorithm"></span><link href="mw-data:TemplateStyles:r935243608" rel="mw-deduplicated-inline-style"/></span>
</li>
<li id="cite_note-neal1999-15"><span class="mw-cite-backlink">^ <a href="#cite_ref-neal1999_15-0"><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-neal1999_15-1"><sup><i><b>b</b></i></sup></a></span> <span class="reference-text"><cite class="citation book">Neal, Radford; <a href="/wiki/Geoffrey_Hinton" title="Geoffrey Hinton">Hinton, Geoffrey</a> (1999).  <a href="/wiki/Michael_I._Jordan" title="Michael I. Jordan">Michael I. Jordan</a> (ed.). <a class="external text" href="ftp://ftp.cs.toronto.edu/pub/radford/emk.pdf" rel="nofollow"><i>A view of the EM algorithm that justifies incremental, sparse, and other variants</i></a> <span class="cs1-format">(PDF)</span>. <i>Learning in Graphical Models</i>. Cambridge, MA: MIT Press. pp. 355–368. <a href="/wiki/International_Standard_Book_Number" title="International Standard Book Number">ISBN</a> <a href="/wiki/Special:BookSources/978-0-262-60032-3" title="Special:BookSources/978-0-262-60032-3"><bdi>978-0-262-60032-3</bdi></a><span class="reference-accessdate">. Retrieved <span class="nowrap">2009-03-22</span></span>.</cite><span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=A+view+of+the+EM+algorithm+that+justifies+incremental%2C+sparse%2C+and+other+variants&amp;rft.place=Cambridge%2C+MA&amp;rft.pages=355-368&amp;rft.pub=MIT+Press&amp;rft.date=1999&amp;rft.isbn=978-0-262-60032-3&amp;rft.aulast=Neal&amp;rft.aufirst=Radford&amp;rft.au=Hinton%2C+Geoffrey&amp;rft_id=ftp%3A%2F%2Fftp.cs.toronto.edu%2Fpub%2Fradford%2Femk.pdf&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AExpectation%E2%80%93maximization+algorithm"></span><link href="mw-data:TemplateStyles:r935243608" rel="mw-deduplicated-inline-style"/></span>
</li>
<li id="cite_note-hastie2001-16"><span class="mw-cite-backlink">^ <a href="#cite_ref-hastie2001_16-0"><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-hastie2001_16-1"><sup><i><b>b</b></i></sup></a></span> <span class="reference-text"><cite class="citation book"><a href="/wiki/Trevor_Hastie" title="Trevor Hastie">Hastie, Trevor</a>; <a href="/wiki/Robert_Tibshirani" title="Robert Tibshirani">Tibshirani, Robert</a>; Friedman, Jerome (2001). "8.5 The EM algorithm". <i>The Elements of Statistical Learning</i>. New York: Springer. pp. 236–243. <a href="/wiki/International_Standard_Book_Number" title="International Standard Book Number">ISBN</a> <a href="/wiki/Special:BookSources/978-0-387-95284-0" title="Special:BookSources/978-0-387-95284-0"><bdi>978-0-387-95284-0</bdi></a>.</cite><span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=bookitem&amp;rft.atitle=8.5+The+EM+algorithm&amp;rft.btitle=The+Elements+of+Statistical+Learning&amp;rft.place=New+York&amp;rft.pages=236-243&amp;rft.pub=Springer&amp;rft.date=2001&amp;rft.isbn=978-0-387-95284-0&amp;rft.aulast=Hastie&amp;rft.aufirst=Trevor&amp;rft.au=Tibshirani%2C+Robert&amp;rft.au=Friedman%2C+Jerome&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AExpectation%E2%80%93maximization+algorithm"></span><link href="mw-data:TemplateStyles:r935243608" rel="mw-deduplicated-inline-style"/></span>
</li>
<li id="cite_note-17"><span class="mw-cite-backlink"><b><a href="#cite_ref-17">^</a></b></span> <span class="reference-text"><cite class="citation journal">Lindstrom, Mary J; Bates, Douglas M (1988). "Newton—Raphson and EM Algorithms for Linear Mixed-Effects Models for Repeated-Measures Data". <i>Journal of the American Statistical Association</i>. <b>83</b> (404): 1014. <a href="/wiki/Digital_object_identifier" title="Digital object identifier">doi</a>:<a class="external text" href="https://doi.org/10.1080%2F01621459.1988.10478693" rel="nofollow">10.1080/01621459.1988.10478693</a>.</cite><span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Journal+of+the+American+Statistical+Association&amp;rft.atitle=Newton%E2%80%94Raphson+and+EM+Algorithms+for+Linear+Mixed-Effects+Models+for+Repeated-Measures+Data&amp;rft.volume=83&amp;rft.issue=404&amp;rft.pages=1014&amp;rft.date=1988&amp;rft_id=info%3Adoi%2F10.1080%2F01621459.1988.10478693&amp;rft.aulast=Lindstrom&amp;rft.aufirst=Mary+J&amp;rft.au=Bates%2C+Douglas+M&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AExpectation%E2%80%93maximization+algorithm"></span><link href="mw-data:TemplateStyles:r935243608" rel="mw-deduplicated-inline-style"/></span>
</li>
<li id="cite_note-18"><span class="mw-cite-backlink"><b><a href="#cite_ref-18">^</a></b></span> <span class="reference-text"><cite class="citation journal">Van Dyk, David A (2000). "Fitting Mixed-Effects Models Using Efficient EM-Type Algorithms". <i>Journal of Computational and Graphical Statistics</i>. <b>9</b> (1): 78–98. <a href="/wiki/Digital_object_identifier" title="Digital object identifier">doi</a>:<a class="external text" href="https://doi.org/10.2307%2F1390614" rel="nofollow">10.2307/1390614</a>. <a href="/wiki/JSTOR" title="JSTOR">JSTOR</a> <a class="external text" href="//www.jstor.org/stable/1390614" rel="nofollow">1390614</a>.</cite><span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Journal+of+Computational+and+Graphical+Statistics&amp;rft.atitle=Fitting+Mixed-Effects+Models+Using+Efficient+EM-Type+Algorithms&amp;rft.volume=9&amp;rft.issue=1&amp;rft.pages=78-98&amp;rft.date=2000&amp;rft_id=info%3Adoi%2F10.2307%2F1390614&amp;rft_id=%2F%2Fwww.jstor.org%2Fstable%2F1390614&amp;rft.aulast=Van+Dyk&amp;rft.aufirst=David+A&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AExpectation%E2%80%93maximization+algorithm"></span><link href="mw-data:TemplateStyles:r935243608" rel="mw-deduplicated-inline-style"/></span>
</li>
<li id="cite_note-19"><span class="mw-cite-backlink"><b><a href="#cite_ref-19">^</a></b></span> <span class="reference-text"><cite class="citation journal">Diffey, S. M; Smith, A. B; Welsh, A. H; Cullis, B. R (2017). "A new REML (parameter expanded) EM algorithm for linear mixed models". <i>Australian &amp; New Zealand Journal of Statistics</i>. <b>59</b> (4): 433. <a href="/wiki/Digital_object_identifier" title="Digital object identifier">doi</a>:<a class="external text" href="https://doi.org/10.1111%2Fanzs.12208" rel="nofollow">10.1111/anzs.12208</a>.</cite><span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Australian+%26+New+Zealand+Journal+of+Statistics&amp;rft.atitle=A+new+REML+%28parameter+expanded%29+EM+algorithm+for+linear+mixed+models&amp;rft.volume=59&amp;rft.issue=4&amp;rft.pages=433&amp;rft.date=2017&amp;rft_id=info%3Adoi%2F10.1111%2Fanzs.12208&amp;rft.aulast=Diffey&amp;rft.aufirst=S.+M&amp;rft.au=Smith%2C+A.+B&amp;rft.au=Welsh%2C+A.+H&amp;rft.au=Cullis%2C+B.+R&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AExpectation%E2%80%93maximization+algorithm"></span><link href="mw-data:TemplateStyles:r935243608" rel="mw-deduplicated-inline-style"/></span>
</li>
<li id="cite_note-20"><span class="mw-cite-backlink"><b><a href="#cite_ref-20">^</a></b></span> <span class="reference-text">Matarazzo, T. J., and Pakzad, S. N. (2016). “STRIDE for Structural Identification using Expectation Maximization: Iterative Output-Only Method for Modal Identification.” Journal of Engineering Mechanics.<a class="external free" href="http://ascelibrary.org/doi/abs/10.1061/(ASCE)EM.1943-7889.0000951" rel="nofollow">http://ascelibrary.org/doi/abs/10.1061/(ASCE)EM.1943-7889.0000951</a></span>
</li>
<li id="cite_note-21"><span class="mw-cite-backlink"><b><a href="#cite_ref-21">^</a></b></span> <span class="reference-text"><cite class="citation journal">Einicke, G.A.; Malos, J.T.; Reid, D.C.; Hainsworth, D.W. (January 2009). "Riccati Equation and EM Algorithm Convergence for Inertial Navigation Alignment". <i>IEEE Trans. Signal Process</i>. <b>57</b> (1): 370–375. <a href="/wiki/Bibcode" title="Bibcode">Bibcode</a>:<a class="external text" href="https://ui.adsabs.harvard.edu/abs/2009ITSP...57..370E" rel="nofollow">2009ITSP...57..370E</a>. <a href="/wiki/Digital_object_identifier" title="Digital object identifier">doi</a>:<a class="external text" href="https://doi.org/10.1109%2FTSP.2008.2007090" rel="nofollow">10.1109/TSP.2008.2007090</a>.</cite><span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=IEEE+Trans.+Signal+Process.&amp;rft.atitle=Riccati+Equation+and+EM+Algorithm+Convergence+for+Inertial+Navigation+Alignment&amp;rft.volume=57&amp;rft.issue=1&amp;rft.pages=370-375&amp;rft.date=2009-01&amp;rft_id=info%3Adoi%2F10.1109%2FTSP.2008.2007090&amp;rft_id=info%3Abibcode%2F2009ITSP...57..370E&amp;rft.aulast=Einicke&amp;rft.aufirst=G.A.&amp;rft.au=Malos%2C+J.T.&amp;rft.au=Reid%2C+D.C.&amp;rft.au=Hainsworth%2C+D.W.&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AExpectation%E2%80%93maximization+algorithm"></span><link href="mw-data:TemplateStyles:r935243608" rel="mw-deduplicated-inline-style"/></span>
</li>
<li id="cite_note-22"><span class="mw-cite-backlink"><b><a href="#cite_ref-22">^</a></b></span> <span class="reference-text"><cite class="citation journal">Einicke, G.A.; Falco, G.; Malos, J.T. (May 2010). "EM Algorithm State Matrix Estimation for Navigation". <i>IEEE Signal Processing Letters</i>. <b>17</b> (5): 437–440. <a href="/wiki/Bibcode" title="Bibcode">Bibcode</a>:<a class="external text" href="https://ui.adsabs.harvard.edu/abs/2010ISPL...17..437E" rel="nofollow">2010ISPL...17..437E</a>. <a href="/wiki/Digital_object_identifier" title="Digital object identifier">doi</a>:<a class="external text" href="https://doi.org/10.1109%2FLSP.2010.2043151" rel="nofollow">10.1109/LSP.2010.2043151</a>.</cite><span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=IEEE+Signal+Processing+Letters&amp;rft.atitle=EM+Algorithm+State+Matrix+Estimation+for+Navigation&amp;rft.volume=17&amp;rft.issue=5&amp;rft.pages=437-440&amp;rft.date=2010-05&amp;rft_id=info%3Adoi%2F10.1109%2FLSP.2010.2043151&amp;rft_id=info%3Abibcode%2F2010ISPL...17..437E&amp;rft.aulast=Einicke&amp;rft.aufirst=G.A.&amp;rft.au=Falco%2C+G.&amp;rft.au=Malos%2C+J.T.&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AExpectation%E2%80%93maximization+algorithm"></span><link href="mw-data:TemplateStyles:r935243608" rel="mw-deduplicated-inline-style"/></span>
</li>
<li id="cite_note-23"><span class="mw-cite-backlink"><b><a href="#cite_ref-23">^</a></b></span> <span class="reference-text"><cite class="citation journal">Einicke, G.A.; Falco, G.; Dunn, M.T.; Reid, D.C. (May 2012). "Iterative Smoother-Based Variance Estimation". <i>IEEE Signal Processing Letters</i>. <b>19</b> (5): 275–278. <a href="/wiki/Bibcode" title="Bibcode">Bibcode</a>:<a class="external text" href="https://ui.adsabs.harvard.edu/abs/2012ISPL...19..275E" rel="nofollow">2012ISPL...19..275E</a>. <a href="/wiki/Digital_object_identifier" title="Digital object identifier">doi</a>:<a class="external text" href="https://doi.org/10.1109%2FLSP.2012.2190278" rel="nofollow">10.1109/LSP.2012.2190278</a>.</cite><span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=IEEE+Signal+Processing+Letters&amp;rft.atitle=Iterative+Smoother-Based+Variance+Estimation&amp;rft.volume=19&amp;rft.issue=5&amp;rft.pages=275-278&amp;rft.date=2012-05&amp;rft_id=info%3Adoi%2F10.1109%2FLSP.2012.2190278&amp;rft_id=info%3Abibcode%2F2012ISPL...19..275E&amp;rft.aulast=Einicke&amp;rft.aufirst=G.A.&amp;rft.au=Falco%2C+G.&amp;rft.au=Dunn%2C+M.T.&amp;rft.au=Reid%2C+D.C.&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AExpectation%E2%80%93maximization+algorithm"></span><link href="mw-data:TemplateStyles:r935243608" rel="mw-deduplicated-inline-style"/></span>
</li>
<li id="cite_note-24"><span class="mw-cite-backlink"><b><a href="#cite_ref-24">^</a></b></span> <span class="reference-text"><cite class="citation journal">Einicke, G.A. (Sep 2015). "Iterative Filtering and Smoothing of Measurements Possessing Poisson Noise". <i>IEEE Transactions on Aerospace and Electronic Systems</i>. <b>51</b> (3): 2205–2011. <a href="/wiki/Bibcode" title="Bibcode">Bibcode</a>:<a class="external text" href="https://ui.adsabs.harvard.edu/abs/2015ITAES..51.2205E" rel="nofollow">2015ITAES..51.2205E</a>. <a href="/wiki/Digital_object_identifier" title="Digital object identifier">doi</a>:<a class="external text" href="https://doi.org/10.1109%2FTAES.2015.140843" rel="nofollow">10.1109/TAES.2015.140843</a>.</cite><span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=IEEE+Transactions+on+Aerospace+and+Electronic+Systems&amp;rft.atitle=Iterative+Filtering+and+Smoothing+of+Measurements+Possessing+Poisson+Noise&amp;rft.volume=51&amp;rft.issue=3&amp;rft.pages=2205-2011&amp;rft.date=2015-09&amp;rft_id=info%3Adoi%2F10.1109%2FTAES.2015.140843&amp;rft_id=info%3Abibcode%2F2015ITAES..51.2205E&amp;rft.aulast=Einicke&amp;rft.aufirst=G.A.&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AExpectation%E2%80%93maximization+algorithm"></span><link href="mw-data:TemplateStyles:r935243608" rel="mw-deduplicated-inline-style"/></span>
</li>
<li id="cite_note-25"><span class="mw-cite-backlink"><b><a href="#cite_ref-25">^</a></b></span> <span class="reference-text"><cite class="citation journal">Jamshidian, Mortaza; Jennrich, Robert I. (1997). "Acceleration of the EM Algorithm by using Quasi-Newton Methods". <i><a class="mw-redirect" href="/wiki/Journal_of_the_Royal_Statistical_Society,_Series_B" title="Journal of the Royal Statistical Society, Series B">Journal of the Royal Statistical Society, Series B</a></i>. <b>59</b> (2): 569–587. <a href="/wiki/Digital_object_identifier" title="Digital object identifier">doi</a>:<a class="external text" href="https://doi.org/10.1111%2F1467-9868.00083" rel="nofollow">10.1111/1467-9868.00083</a>. <a href="/wiki/Mathematical_Reviews" title="Mathematical Reviews">MR</a> <a class="external text" href="//www.ams.org/mathscinet-getitem?mr=1452026" rel="nofollow">1452026</a>.</cite><span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Journal+of+the+Royal+Statistical+Society%2C+Series+B&amp;rft.atitle=Acceleration+of+the+EM+Algorithm+by+using+Quasi-Newton+Methods&amp;rft.volume=59&amp;rft.issue=2&amp;rft.pages=569-587&amp;rft.date=1997&amp;rft_id=info%3Adoi%2F10.1111%2F1467-9868.00083&amp;rft_id=%2F%2Fwww.ams.org%2Fmathscinet-getitem%3Fmr%3D1452026&amp;rft.aulast=Jamshidian&amp;rft.aufirst=Mortaza&amp;rft.au=Jennrich%2C+Robert+I.&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AExpectation%E2%80%93maximization+algorithm"></span><link href="mw-data:TemplateStyles:r935243608" rel="mw-deduplicated-inline-style"/></span>
</li>
<li id="cite_note-26"><span class="mw-cite-backlink"><b><a href="#cite_ref-26">^</a></b></span> <span class="reference-text"><cite class="citation journal">Liu, C (1998). "Parameter expansion to accelerate EM: The PX-EM algorithm". <i>Biometrika</i>. <b>85</b> (4): 755–770. <a href="/wiki/CiteSeerX" title="CiteSeerX">CiteSeerX</a> <span class="cs1-lock-free" title="Freely accessible"><a class="external text" href="//citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.134.9617" rel="nofollow">10.1.1.134.9617</a></span>. <a href="/wiki/Digital_object_identifier" title="Digital object identifier">doi</a>:<a class="external text" href="https://doi.org/10.1093%2Fbiomet%2F85.4.755" rel="nofollow">10.1093/biomet/85.4.755</a>.</cite><span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Biometrika&amp;rft.atitle=Parameter+expansion+to+accelerate+EM%3A+The+PX-EM+algorithm&amp;rft.volume=85&amp;rft.issue=4&amp;rft.pages=755-770&amp;rft.date=1998&amp;rft_id=%2F%2Fciteseerx.ist.psu.edu%2Fviewdoc%2Fsummary%3Fdoi%3D10.1.1.134.9617&amp;rft_id=info%3Adoi%2F10.1093%2Fbiomet%2F85.4.755&amp;rft.aulast=Liu&amp;rft.aufirst=C&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AExpectation%E2%80%93maximization+algorithm"></span><link href="mw-data:TemplateStyles:r935243608" rel="mw-deduplicated-inline-style"/></span>
</li>
<li id="cite_note-27"><span class="mw-cite-backlink"><b><a href="#cite_ref-27">^</a></b></span> <span class="reference-text"><cite class="citation journal">Meng, Xiao-Li; <a href="/wiki/Donald_Rubin" title="Donald Rubin">Rubin, Donald B.</a> (1993). <a class="external text" href="https://semanticscholar.org/paper/721b25ffad2623a8d1e8044882f66e0dbe678f1d" rel="nofollow">"Maximum likelihood estimation via the ECM algorithm: A general framework"</a>. <i><a href="/wiki/Biometrika" title="Biometrika">Biometrika</a></i>. <b>80</b> (2): 267–278. <a href="/wiki/Digital_object_identifier" title="Digital object identifier">doi</a>:<a class="external text" href="https://doi.org/10.1093%2Fbiomet%2F80.2.267" rel="nofollow">10.1093/biomet/80.2.267</a>. <a href="/wiki/Mathematical_Reviews" title="Mathematical Reviews">MR</a> <a class="external text" href="//www.ams.org/mathscinet-getitem?mr=1243503" rel="nofollow">1243503</a>.</cite><span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Biometrika&amp;rft.atitle=Maximum+likelihood+estimation+via+the+ECM+algorithm%3A+A+general+framework&amp;rft.volume=80&amp;rft.issue=2&amp;rft.pages=267-278&amp;rft.date=1993&amp;rft_id=info%3Adoi%2F10.1093%2Fbiomet%2F80.2.267&amp;rft_id=%2F%2Fwww.ams.org%2Fmathscinet-getitem%3Fmr%3D1243503&amp;rft.aulast=Meng&amp;rft.aufirst=Xiao-Li&amp;rft.au=Rubin%2C+Donald+B.&amp;rft_id=https%3A%2F%2Fsemanticscholar.org%2Fpaper%2F721b25ffad2623a8d1e8044882f66e0dbe678f1d&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AExpectation%E2%80%93maximization+algorithm"></span><link href="mw-data:TemplateStyles:r935243608" rel="mw-deduplicated-inline-style"/></span>
</li>
<li id="cite_note-28"><span class="mw-cite-backlink"><b><a href="#cite_ref-28">^</a></b></span> <span class="reference-text"><cite class="citation journal">Liu, Chuanhai; Rubin, Donald B (1994). "The ECME Algorithm: A Simple Extension of EM and ECM with Faster Monotone Convergence". <i>Biometrika</i>. <b>81</b> (4): 633. <a href="/wiki/Digital_object_identifier" title="Digital object identifier">doi</a>:<a class="external text" href="https://doi.org/10.1093%2Fbiomet%2F81.4.633" rel="nofollow">10.1093/biomet/81.4.633</a>. <a href="/wiki/JSTOR" title="JSTOR">JSTOR</a> <a class="external text" href="//www.jstor.org/stable/2337067" rel="nofollow">2337067</a>.</cite><span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Biometrika&amp;rft.atitle=The+ECME+Algorithm%3A+A+Simple+Extension+of+EM+and+ECM+with+Faster+Monotone+Convergence&amp;rft.volume=81&amp;rft.issue=4&amp;rft.pages=633&amp;rft.date=1994&amp;rft_id=info%3Adoi%2F10.1093%2Fbiomet%2F81.4.633&amp;rft_id=%2F%2Fwww.jstor.org%2Fstable%2F2337067&amp;rft.aulast=Liu&amp;rft.aufirst=Chuanhai&amp;rft.au=Rubin%2C+Donald+B&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AExpectation%E2%80%93maximization+algorithm"></span><link href="mw-data:TemplateStyles:r935243608" rel="mw-deduplicated-inline-style"/></span>
</li>
<li id="cite_note-29"><span class="mw-cite-backlink"><b><a href="#cite_ref-29">^</a></b></span> <span class="reference-text">
<cite class="citation journal">Jiangtao Yin; Yanfeng Zhang; Lixin Gao (2012). <a class="external text" href="http://rio.ecs.umass.edu/mnilpub/papers/cluster2012-yin.pdf" rel="nofollow">"Accelerating Expectation-Maximization Algorithms with Frequent Updates"</a> <span class="cs1-format">(PDF)</span>. <i>Proceedings of the IEEE International Conference on Cluster Computing</i>.</cite><span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Proceedings+of+the+IEEE+International+Conference+on+Cluster+Computing&amp;rft.atitle=Accelerating+Expectation-Maximization+Algorithms+with+Frequent+Updates&amp;rft.date=2012&amp;rft.au=Jiangtao+Yin&amp;rft.au=Yanfeng+Zhang&amp;rft.au=Lixin+Gao&amp;rft_id=http%3A%2F%2Frio.ecs.umass.edu%2Fmnilpub%2Fpapers%2Fcluster2012-yin.pdf&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AExpectation%E2%80%93maximization+algorithm"></span><link href="mw-data:TemplateStyles:r935243608" rel="mw-deduplicated-inline-style"/></span>
</li>
<li id="cite_note-30"><span class="mw-cite-backlink"><b><a href="#cite_ref-30">^</a></b></span> <span class="reference-text">Hunter DR and Lange K (2004), <a class="external text" href="http://www.stat.psu.edu/~dhunter/papers/mmtutorial.pdf" rel="nofollow">A Tutorial on MM Algorithms</a>, The American Statistician, 58: 30-37</span>
</li>
<li id="cite_note-31"><span class="mw-cite-backlink"><b><a href="#cite_ref-31">^</a></b></span> <span class="reference-text">
<cite class="citation journal">Matsuyama, Yasuo (2003). "The α-EM algorithm: Surrogate likelihood maximization using α-logarithmic information measures". <i>IEEE Transactions on Information Theory</i>. <b>49</b> (3): 692–706. <a href="/wiki/Digital_object_identifier" title="Digital object identifier">doi</a>:<a class="external text" href="https://doi.org/10.1109%2FTIT.2002.808105" rel="nofollow">10.1109/TIT.2002.808105</a>.</cite><span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=IEEE+Transactions+on+Information+Theory&amp;rft.atitle=The+%CE%B1-EM+algorithm%3A+Surrogate+likelihood+maximization+using+%CE%B1-logarithmic+information+measures&amp;rft.volume=49&amp;rft.issue=3&amp;rft.pages=692-706&amp;rft.date=2003&amp;rft_id=info%3Adoi%2F10.1109%2FTIT.2002.808105&amp;rft.aulast=Matsuyama&amp;rft.aufirst=Yasuo&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AExpectation%E2%80%93maximization+algorithm"></span><link href="mw-data:TemplateStyles:r935243608" rel="mw-deduplicated-inline-style"/></span>
</li>
<li id="cite_note-32"><span class="mw-cite-backlink"><b><a href="#cite_ref-32">^</a></b></span> <span class="reference-text">
<cite class="citation journal">Matsuyama, Yasuo (2011). "Hidden Markov model estimation based on alpha-EM algorithm: Discrete and continuous alpha-HMMs". <i>International Joint Conference on Neural Networks</i>: 808–816.</cite><span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=International+Joint+Conference+on+Neural+Networks&amp;rft.atitle=Hidden+Markov+model+estimation+based+on+alpha-EM+algorithm%3A+Discrete+and+continuous+alpha-HMMs&amp;rft.pages=808-816&amp;rft.date=2011&amp;rft.aulast=Matsuyama&amp;rft.aufirst=Yasuo&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AExpectation%E2%80%93maximization+algorithm"></span><link href="mw-data:TemplateStyles:r935243608" rel="mw-deduplicated-inline-style"/></span>
</li>
<li id="cite_note-Wolynetz-33"><span class="mw-cite-backlink">^ <a href="#cite_ref-Wolynetz_33-0"><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-Wolynetz_33-1"><sup><i><b>b</b></i></sup></a></span> <span class="reference-text"><cite class="citation journal">Wolynetz, M.S. (1979). "Maximum likelihood estimation in a linear model from confined and censored normal data". <i><a class="mw-redirect" href="/wiki/Journal_of_the_Royal_Statistical_Society,_Series_C" title="Journal of the Royal Statistical Society, Series C">Journal of the Royal Statistical Society, Series C</a></i>. <b>28</b> (2): 195–206. <a href="/wiki/Digital_object_identifier" title="Digital object identifier">doi</a>:<a class="external text" href="https://doi.org/10.2307%2F2346749" rel="nofollow">10.2307/2346749</a>. <a href="/wiki/JSTOR" title="JSTOR">JSTOR</a> <a class="external text" href="//www.jstor.org/stable/2346749" rel="nofollow">2346749</a>.</cite><span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Journal+of+the+Royal+Statistical+Society%2C+Series+C&amp;rft.atitle=Maximum+likelihood+estimation+in+a+linear+model+from+confined+and+censored+normal+data&amp;rft.volume=28&amp;rft.issue=2&amp;rft.pages=195-206&amp;rft.date=1979&amp;rft_id=info%3Adoi%2F10.2307%2F2346749&amp;rft_id=%2F%2Fwww.jstor.org%2Fstable%2F2346749&amp;rft.aulast=Wolynetz&amp;rft.aufirst=M.S.&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AExpectation%E2%80%93maximization+algorithm"></span><link href="mw-data:TemplateStyles:r935243608" rel="mw-deduplicated-inline-style"/></span>
</li>
<li id="cite_note-34"><span class="mw-cite-backlink"><b><a href="#cite_ref-34">^</a></b></span> <span class="reference-text"><cite class="citation journal">Pearson, Karl (1894). "Contributions to the Mathematical Theory of Evolution". <i>Philosophical Transactions of the Royal Society of London A</i>. <b>185</b>: 71–110. <a href="/wiki/Bibcode" title="Bibcode">Bibcode</a>:<a class="external text" href="https://ui.adsabs.harvard.edu/abs/1894RSPTA.185...71P" rel="nofollow">1894RSPTA.185...71P</a>. <a href="/wiki/Digital_object_identifier" title="Digital object identifier">doi</a>:<a class="external text" href="https://doi.org/10.1098%2Frsta.1894.0003" rel="nofollow">10.1098/rsta.1894.0003</a>. <a href="/wiki/International_Standard_Serial_Number" title="International Standard Serial Number">ISSN</a> <a class="external text" href="//www.worldcat.org/issn/0264-3820" rel="nofollow">0264-3820</a>. <a href="/wiki/JSTOR" title="JSTOR">JSTOR</a> <a class="external text" href="//www.jstor.org/stable/90667" rel="nofollow">90667</a>.</cite><span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Philosophical+Transactions+of+the+Royal+Society+of+London+A&amp;rft.atitle=Contributions+to+the+Mathematical+Theory+of+Evolution&amp;rft.volume=185&amp;rft.pages=71-110&amp;rft.date=1894&amp;rft_id=info%3Adoi%2F10.1098%2Frsta.1894.0003&amp;rft.issn=0264-3820&amp;rft_id=%2F%2Fwww.jstor.org%2Fstable%2F90667&amp;rft_id=info%3Abibcode%2F1894RSPTA.185...71P&amp;rft.aulast=Pearson&amp;rft.aufirst=Karl&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AExpectation%E2%80%93maximization+algorithm"></span><link href="mw-data:TemplateStyles:r935243608" rel="mw-deduplicated-inline-style"/></span>
</li>
<li id="cite_note-35"><span class="mw-cite-backlink"><b><a href="#cite_ref-35">^</a></b></span> <span class="reference-text"><cite class="citation journal">Shaban, Amirreza; Mehrdad, Farajtabar; Bo, Xie; Le, Song; Byron, Boots (2015). <a class="external text" href="https://www.cc.gatech.edu/~bboots3/files/SpectralExteriorPoint-NIPSWorkshop.pdf" rel="nofollow">"Learning Latent Variable Models by Improving Spectral Solutions with Exterior Point Method"</a> <span class="cs1-format">(PDF)</span>. <i>UAI</i>: 792–801.</cite><span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=UAI&amp;rft.atitle=Learning+Latent+Variable+Models+by+Improving+Spectral+Solutions+with+Exterior+Point+Method&amp;rft.pages=792-801&amp;rft.date=2015&amp;rft.aulast=Shaban&amp;rft.aufirst=Amirreza&amp;rft.au=Mehrdad%2C+Farajtabar&amp;rft.au=Bo%2C+Xie&amp;rft.au=Le%2C+Song&amp;rft.au=Byron%2C+Boots&amp;rft_id=https%3A%2F%2Fwww.cc.gatech.edu%2F~bboots3%2Ffiles%2FSpectralExteriorPoint-NIPSWorkshop.pdf&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AExpectation%E2%80%93maximization+algorithm"></span><link href="mw-data:TemplateStyles:r935243608" rel="mw-deduplicated-inline-style"/></span>
</li>
<li id="cite_note-36"><span class="mw-cite-backlink"><b><a href="#cite_ref-36">^</a></b></span> <span class="reference-text"><cite class="citation book">Balle, Borja Quattoni, Ariadna Carreras, Xavier (2012-06-27). <i>Local Loss Optimization in Operator Models: A New Insight into Spectral Learning</i>. <a href="/wiki/OCLC" title="OCLC">OCLC</a> <a class="external text" href="//www.worldcat.org/oclc/815865081" rel="nofollow">815865081</a>.</cite><span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=Local+Loss+Optimization+in+Operator+Models%3A+A+New+Insight+into+Spectral+Learning&amp;rft.date=2012-06-27&amp;rft_id=info%3Aoclcnum%2F815865081&amp;rft.au=Balle%2C+Borja+Quattoni%2C+Ariadna+Carreras%2C+Xavier&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AExpectation%E2%80%93maximization+algorithm"></span><span class="cs1-maint citation-comment">CS1 maint: multiple names: authors list (<a href="/wiki/Category:CS1_maint:_multiple_names:_authors_list" title="Category:CS1 maint: multiple names: authors list">link</a>)</span><link href="mw-data:TemplateStyles:r935243608" rel="mw-deduplicated-inline-style"/></span>
</li>
<li id="cite_note-37"><span class="mw-cite-backlink"><b><a href="#cite_ref-37">^</a></b></span> <span class="reference-text"><cite class="citation web">Lange, Kenneth. <a class="external text" href="http://www.stat.berkeley.edu/~aldous/Colloq/lange-talk.pdf" rel="nofollow">"The MM Algorithm"</a> <span class="cs1-format">(PDF)</span>.</cite><span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=The+MM+Algorithm&amp;rft.aulast=Lange&amp;rft.aufirst=Kenneth&amp;rft_id=http%3A%2F%2Fwww.stat.berkeley.edu%2F~aldous%2FColloq%2Flange-talk.pdf&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AExpectation%E2%80%93maximization+algorithm"></span><link href="mw-data:TemplateStyles:r935243608" rel="mw-deduplicated-inline-style"/></span>
</li>
</ol></div></div>
<h2><span class="mw-headline" id="Further_reading">Further reading</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Expectation%E2%80%93maximization_algorithm&amp;action=edit&amp;section=23" title="Edit section: Further reading">edit</a><span class="mw-editsection-bracket">]</span></span></h2>
<ul><li><cite class="citation book">Hogg, Robert; McKean, Joseph; <a href="/wiki/Allen_Craig" title="Allen Craig">Craig, Allen</a> (2005). <i>Introduction to Mathematical Statistics</i>. Upper Saddle River, NJ: Pearson Prentice Hall. pp. 359–364.</cite><span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=Introduction+to+Mathematical+Statistics&amp;rft.place=Upper+Saddle+River%2C+NJ&amp;rft.pages=359-364&amp;rft.pub=Pearson+Prentice+Hall&amp;rft.date=2005&amp;rft.aulast=Hogg&amp;rft.aufirst=Robert&amp;rft.au=McKean%2C+Joseph&amp;rft.au=Craig%2C+Allen&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AExpectation%E2%80%93maximization+algorithm"></span><link href="mw-data:TemplateStyles:r935243608" rel="mw-deduplicated-inline-style"/></li>
<li><cite class="citation journal"><a href="/wiki/Frank_Dellaert" title="Frank Dellaert">Dellaert, Frank</a> (2002). "The Expectation Maximization Algorithm". <a href="/wiki/CiteSeerX" title="CiteSeerX">CiteSeerX</a> <span class="cs1-lock-free" title="Freely accessible"><a class="external text" href="//citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.9.9735" rel="nofollow">10.1.1.9.9735</a></span>.</cite><span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.atitle=The+Expectation+Maximization+Algorithm&amp;rft.date=2002&amp;rft_id=%2F%2Fciteseerx.ist.psu.edu%2Fviewdoc%2Fsummary%3Fdoi%3D10.1.1.9.9735&amp;rft.aulast=Dellaert&amp;rft.aufirst=Frank&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AExpectation%E2%80%93maximization+algorithm"></span> <span class="cs1-hidden-error error citation-comment">Cite journal requires <code class="cs1-code">|journal=</code> (<a href="/wiki/Help:CS1_errors#missing_periodical" title="Help:CS1 errors">help</a>)</span><link href="mw-data:TemplateStyles:r935243608" rel="mw-deduplicated-inline-style"/> gives an easier explanation of EM algorithm as to lowerbound maximization.</li>
<li><cite class="citation book" id="CITEREFBishop2006"><a href="/wiki/Christopher_Bishop" title="Christopher Bishop">Bishop, Christopher M.</a> (2006). <i>Pattern Recognition and Machine Learning</i>. Springer. <a href="/wiki/International_Standard_Book_Number" title="International Standard Book Number">ISBN</a> <a href="/wiki/Special:BookSources/978-0-387-31073-2" title="Special:BookSources/978-0-387-31073-2"><bdi>978-0-387-31073-2</bdi></a>.</cite><span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=Pattern+Recognition+and+Machine+Learning&amp;rft.pub=Springer&amp;rft.date=2006&amp;rft.isbn=978-0-387-31073-2&amp;rft.aulast=Bishop&amp;rft.aufirst=Christopher+M.&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AExpectation%E2%80%93maximization+algorithm"></span><link href="mw-data:TemplateStyles:r935243608" rel="mw-deduplicated-inline-style"/></li>
<li><cite class="citation journal">Gupta, M. R.; Chen, Y. (2010). "Theory and Use of the EM Algorithm". <i>Foundations and Trends in Signal Processing</i>. <b>4</b> (3): 223–296. <a href="/wiki/CiteSeerX" title="CiteSeerX">CiteSeerX</a> <span class="cs1-lock-free" title="Freely accessible"><a class="external text" href="//citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.219.6830" rel="nofollow">10.1.1.219.6830</a></span>. <a href="/wiki/Digital_object_identifier" title="Digital object identifier">doi</a>:<a class="external text" href="https://doi.org/10.1561%2F2000000034" rel="nofollow">10.1561/2000000034</a>.</cite><span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Foundations+and+Trends+in+Signal+Processing&amp;rft.atitle=Theory+and+Use+of+the+EM+Algorithm&amp;rft.volume=4&amp;rft.issue=3&amp;rft.pages=223-296&amp;rft.date=2010&amp;rft_id=%2F%2Fciteseerx.ist.psu.edu%2Fviewdoc%2Fsummary%3Fdoi%3D10.1.1.219.6830&amp;rft_id=info%3Adoi%2F10.1561%2F2000000034&amp;rft.aulast=Gupta&amp;rft.aufirst=M.+R.&amp;rft.au=Chen%2C+Y.&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AExpectation%E2%80%93maximization+algorithm"></span><link href="mw-data:TemplateStyles:r935243608" rel="mw-deduplicated-inline-style"/> A well-written short book on EM, including detailed derivation of EM for GMMs, HMMs, and Dirichlet.</li>
<li><cite class="citation journal">Bilmes, Jeff (1998). "A Gentle Tutorial of the EM Algorithm and its Application to Parameter Estimation for Gaussian Mixture and Hidden Markov Models". <a href="/wiki/CiteSeerX" title="CiteSeerX">CiteSeerX</a> <span class="cs1-lock-free" title="Freely accessible"><a class="external text" href="//citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.28.613" rel="nofollow">10.1.1.28.613</a></span>.</cite><span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.atitle=A+Gentle+Tutorial+of+the+EM+Algorithm+and+its+Application+to+Parameter+Estimation+for+Gaussian+Mixture+and+Hidden+Markov+Models&amp;rft.date=1998&amp;rft_id=%2F%2Fciteseerx.ist.psu.edu%2Fviewdoc%2Fsummary%3Fdoi%3D10.1.1.28.613&amp;rft.aulast=Bilmes&amp;rft.aufirst=Jeff&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AExpectation%E2%80%93maximization+algorithm"></span> <span class="cs1-hidden-error error citation-comment">Cite journal requires <code class="cs1-code">|journal=</code> (<a href="/wiki/Help:CS1_errors#missing_periodical" title="Help:CS1 errors">help</a>)</span><link href="mw-data:TemplateStyles:r935243608" rel="mw-deduplicated-inline-style"/> includes a simplified derivation of the EM equations for Gaussian Mixtures and Gaussian Mixture Hidden Markov Models.</li>
<li><cite class="citation book">McLachlan, Geoffrey J.; Krishnan, Thriyambakam (2008). <i>The EM Algorithm and Extensions</i> (2nd ed.). Hoboken: Wiley. <a href="/wiki/International_Standard_Book_Number" title="International Standard Book Number">ISBN</a> <a href="/wiki/Special:BookSources/978-0-471-20170-0" title="Special:BookSources/978-0-471-20170-0"><bdi>978-0-471-20170-0</bdi></a>.</cite><span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=The+EM+Algorithm+and+Extensions&amp;rft.place=Hoboken&amp;rft.edition=2nd&amp;rft.pub=Wiley&amp;rft.date=2008&amp;rft.isbn=978-0-471-20170-0&amp;rft.aulast=McLachlan&amp;rft.aufirst=Geoffrey+J.&amp;rft.au=Krishnan%2C+Thriyambakam&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AExpectation%E2%80%93maximization+algorithm"></span><link href="mw-data:TemplateStyles:r935243608" rel="mw-deduplicated-inline-style"/></li></ul>
<h2><span class="mw-headline" id="External_links">External links</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Expectation%E2%80%93maximization_algorithm&amp;action=edit&amp;section=24" title="Edit section: External links">edit</a><span class="mw-editsection-bracket">]</span></span></h2>
<ul><li>Various 1D, 2D and 3D <a class="external text" href="http://wiki.stat.ucla.edu/socr/index.php/SOCR_EduMaterials_Activities_2D_PointSegmentation_EM_Mixture" rel="nofollow">demonstrations of EM together with Mixture Modeling</a> are provided as part of the paired <a class="mw-redirect" href="/wiki/SOCR" title="SOCR">SOCR</a> activities and applets. These applets and activities show empirically the properties of the EM algorithm for parameter estimation in diverse settings.</li>
<li><a class="external text" href="https://arxiv.org/abs/1203.5181" rel="nofollow">k-MLE: A fast algorithm for learning statistical mixture models</a></li>
<li><a class="external text" href="https://github.com/l-/CommonDataAnalysis" rel="nofollow">Class hierarchy in </a><a href="/wiki/C%2B%2B" title="C++">C++</a> (GPL) including Gaussian Mixtures</li>
<li><a class="external text" href="http://www.inference.phy.cam.ac.uk/mackay/itila/" rel="nofollow">The on-line textbook: Information Theory, Inference, and Learning Algorithms</a>, by <a class="mw-redirect" href="/wiki/David_J.C._MacKay" title="David J.C. MacKay">David J.C. MacKay</a> includes simple examples of the EM algorithm such as clustering using the soft <i>k</i>-means algorithm, and emphasizes the variational view of the EM algorithm, as described in Chapter 33.7 of version 7.2 (fourth edition).</li>
<li><a class="external text" href="http://www.cse.buffalo.edu/faculty/mbeal/papers/beal03.pdf" rel="nofollow">Variational Algorithms for Approximate Bayesian Inference</a>, by M. J. Beal includes comparisons of EM to Variational Bayesian EM and derivations of several models including Variational Bayesian HMMs  (<a class="external text" href="http://www.cse.buffalo.edu/faculty/mbeal/thesis/index.html" rel="nofollow">chapters</a>).</li>
<li><a class="external text" href="http://www.seanborman.com/publications/EM_algorithm.pdf" rel="nofollow">The Expectation Maximization Algorithm: A short tutorial</a>, A self-contained derivation of the EM Algorithm by Sean Borman.</li>
<li><a class="external text" href="http://pages.cs.wisc.edu/~jerryzhu/cs838/EM.pdf" rel="nofollow">The EM Algorithm</a>, by Xiaojin Zhu.</li>
<li><a class="external text" href="https://arxiv.org/pdf/1105.1476.pdf" rel="nofollow">EM algorithm and variants: an informal tutorial</a> by Alexis Roche.  A concise and very clear description of EM and many interesting variants.</li></ul>
<!-- 
NewPP limit report
Parsed by mw1373
Cached time: 20200407175517
Cache expiry: 2592000
Dynamic content: false
Complications: [vary‐revision‐sha1]
CPU time usage: 0.752 seconds
Real time usage: 1.141 seconds
Preprocessor visited node count: 2929/1000000
Post‐expand include size: 96754/2097152 bytes
Template argument size: 2576/2097152 bytes
Highest expansion depth: 12/40
Expensive parser function count: 9/500
Unstrip recursion depth: 1/20
Unstrip post‐expand size: 116300/5000000 bytes
Number of Wikibase entities loaded: 7/400
Lua time usage: 0.354/10.000 seconds
Lua memory usage: 6 MB/50 MB
-->
<!--
Transclusion expansion time report (%,ms,calls,template)
100.00%  668.364      1 -total
 60.94%  407.269      1 Template:Reflist
 48.20%  322.153     26 Template:Cite_journal
 10.22%   68.336      7 Template:Cite_book
  9.76%   65.209      3 Template:Citation_needed
  8.47%   56.606      1 Template:Short_description
  8.04%   53.764      3 Template:Fix
  7.62%   50.951      1 Template:Machine_learning_bar
  7.10%   47.478      1 Template:Sidebar_with_collapsible_lists
  5.85%   39.106      1 Template:Pagetype
-->
<!-- Saved in parser cache with key enwiki:pcache:idhash:470752-0!canonical!math=5 and timestamp 20200407175515 and revision id 949604842
 -->
</div><noscript><img alt="" height="1" src="//en.wikipedia.org/wiki/Special:CentralAutoLogin/start?type=1x1" style="border: none; position: absolute;" title="" width="1"/></noscript></div>
<div class="printfooter">Retrieved from "<a dir="ltr" href="https://en.wikipedia.org/w/index.php?title=Expectation–maximization_algorithm&amp;oldid=949604842">https://en.wikipedia.org/w/index.php?title=Expectation–maximization_algorithm&amp;oldid=949604842</a>"</div>
<div class="catlinks" data-mw="interface" id="catlinks"><div class="mw-normal-catlinks" id="mw-normal-catlinks"><a href="/wiki/Help:Category" title="Help:Category">Categories</a>: <ul><li><a href="/wiki/Category:Estimation_methods" title="Category:Estimation methods">Estimation methods</a></li><li><a href="/wiki/Category:Machine_learning_algorithms" title="Category:Machine learning algorithms">Machine learning algorithms</a></li><li><a href="/wiki/Category:Missing_data" title="Category:Missing data">Missing data</a></li><li><a href="/wiki/Category:Statistical_algorithms" title="Category:Statistical algorithms">Statistical algorithms</a></li><li><a href="/wiki/Category:Optimization_algorithms_and_methods" title="Category:Optimization algorithms and methods">Optimization algorithms and methods</a></li><li><a href="/wiki/Category:Cluster_analysis_algorithms" title="Category:Cluster analysis algorithms">Cluster analysis algorithms</a></li></ul></div><div class="mw-hidden-catlinks mw-hidden-cats-hidden" id="mw-hidden-catlinks">Hidden categories: <ul><li><a href="/wiki/Category:CS1_maint:_multiple_names:_authors_list" title="Category:CS1 maint: multiple names: authors list">CS1 maint: multiple names: authors list</a></li><li><a href="/wiki/Category:Articles_with_short_description" title="Category:Articles with short description">Articles with short description</a></li><li><a href="/wiki/Category:All_articles_with_unsourced_statements" title="Category:All articles with unsourced statements">All articles with unsourced statements</a></li><li><a href="/wiki/Category:Articles_with_unsourced_statements_from_November_2017" title="Category:Articles with unsourced statements from November 2017">Articles with unsourced statements from November 2017</a></li><li><a href="/wiki/Category:Articles_with_unsourced_statements_from_April_2019" title="Category:Articles with unsourced statements from April 2019">Articles with unsourced statements from April 2019</a></li><li><a href="/wiki/Category:CS1_errors:_missing_periodical" title="Category:CS1 errors: missing periodical">CS1 errors: missing periodical</a></li></ul></div></div>
<div class="visualClear"></div>
</div>
</div>
<div id="mw-data-after-content">
<div class="read-more-container"></div>
</div>
<div id="mw-navigation">
<h2>Navigation menu</h2>
<div id="mw-head">
<div aria-labelledby="p-personal-label" class="" id="p-personal" role="navigation">
<h3 id="p-personal-label">Personal tools</h3>
<ul>
<li id="pt-anonuserpage">Not logged in</li>
<li id="pt-anontalk"><a accesskey="n" href="/wiki/Special:MyTalk" title="Discussion about edits from this IP address [n]">Talk</a></li><li id="pt-anoncontribs"><a accesskey="y" href="/wiki/Special:MyContributions" title="A list of edits made from this IP address [y]">Contributions</a></li><li id="pt-createaccount"><a href="/w/index.php?title=Special:CreateAccount&amp;returnto=Expectation%E2%80%93maximization+algorithm" title="You are encouraged to create an account and log in; however, it is not mandatory">Create account</a></li><li id="pt-login"><a accesskey="o" href="/w/index.php?title=Special:UserLogin&amp;returnto=Expectation%E2%80%93maximization+algorithm" title="You're encouraged to log in; however, it's not mandatory. [o]">Log in</a></li>
</ul>
</div>
<div id="left-navigation">
<div aria-labelledby="p-namespaces-label" class="vectorTabs" id="p-namespaces" role="navigation">
<h3 id="p-namespaces-label">Namespaces</h3>
<ul>
<li class="selected" id="ca-nstab-main"><a accesskey="c" href="/wiki/Expectation%E2%80%93maximization_algorithm" title="View the content page [c]">Article</a></li><li id="ca-talk"><a accesskey="t" href="/wiki/Talk:Expectation%E2%80%93maximization_algorithm" rel="discussion" title="Discussion about the content page [t]">Talk</a></li>
</ul>
</div>
<div aria-labelledby="p-variants-label" class="vectorMenu emptyPortlet" id="p-variants" role="navigation">
<input aria-labelledby="p-variants-label" class="vectorMenuCheckbox" type="checkbox"/>
<h3 id="p-variants-label">
<span>Variants</span>
</h3>
<ul class="menu">
</ul>
</div>
</div>
<div id="right-navigation">
<div aria-labelledby="p-views-label" class="vectorTabs" id="p-views" role="navigation">
<h3 id="p-views-label">Views</h3>
<ul>
<li class="collapsible selected" id="ca-view"><a href="/wiki/Expectation%E2%80%93maximization_algorithm">Read</a></li><li class="collapsible" id="ca-edit"><a accesskey="e" href="/w/index.php?title=Expectation%E2%80%93maximization_algorithm&amp;action=edit" title="Edit this page [e]">Edit</a></li><li class="collapsible" id="ca-history"><a accesskey="h" href="/w/index.php?title=Expectation%E2%80%93maximization_algorithm&amp;action=history" title="Past revisions of this page [h]">View history</a></li>
</ul>
</div>
<div aria-labelledby="p-cactions-label" class="vectorMenu emptyPortlet" id="p-cactions" role="navigation">
<input aria-labelledby="p-cactions-label" class="vectorMenuCheckbox" type="checkbox"/>
<h3 id="p-cactions-label">
<span>More</span>
</h3>
<ul class="menu">
</ul>
</div>
<div id="p-search" role="search">
<h3>
<label for="searchInput">Search</label>
</h3>
<form action="/w/index.php" id="searchform">
<div id="simpleSearch">
<input accesskey="f" id="searchInput" name="search" placeholder="Search Wikipedia" title="Search Wikipedia [f]" type="search"/>
<input name="title" type="hidden" value="Special:Search"/>
<input class="searchButton mw-fallbackSearchButton" id="mw-searchButton" name="fulltext" title="Search Wikipedia for this text" type="submit" value="Search"/>
<input class="searchButton" id="searchButton" name="go" title="Go to a page with this exact name if it exists" type="submit" value="Go"/>
</div>
</form>
</div>
</div>
</div>
<div id="mw-panel">
<div id="p-logo" role="banner">
<a class="mw-wiki-logo" href="/wiki/Main_Page" title="Visit the main page"></a>
</div>
<div aria-labelledby="p-navigation-label" class="portal" id="p-navigation" role="navigation">
<h3 id="p-navigation-label">
    			Navigation
    		</h3>
<div class="body">
<ul><li id="n-mainpage-description"><a accesskey="z" href="/wiki/Main_Page" title="Visit the main page [z]">Main page</a></li><li id="n-contents"><a href="/wiki/Wikipedia:Contents" title="Guides to browsing Wikipedia">Contents</a></li><li id="n-featuredcontent"><a href="/wiki/Wikipedia:Featured_content" title="Featured content – the best of Wikipedia">Featured content</a></li><li id="n-currentevents"><a href="/wiki/Portal:Current_events" title="Find background information on current events">Current events</a></li><li id="n-randompage"><a accesskey="x" href="/wiki/Special:Random" title="Load a random article [x]">Random article</a></li><li id="n-sitesupport"><a href="https://donate.wikimedia.org/wiki/Special:FundraiserRedirector?utm_source=donate&amp;utm_medium=sidebar&amp;utm_campaign=C13_en.wikipedia.org&amp;uselang=en" title="Support us">Donate to Wikipedia</a></li><li id="n-shoplink"><a href="//shop.wikimedia.org" title="Visit the Wikipedia store">Wikipedia store</a></li></ul>
</div>
</div>
<div aria-labelledby="p-interaction-label" class="portal" id="p-interaction" role="navigation">
<h3 id="p-interaction-label">
    			Interaction
    		</h3>
<div class="body">
<ul><li id="n-help"><a href="/wiki/Help:Contents" title="Guidance on how to use and edit Wikipedia">Help</a></li><li id="n-aboutsite"><a href="/wiki/Wikipedia:About" title="Find out about Wikipedia">About Wikipedia</a></li><li id="n-portal"><a href="/wiki/Wikipedia:Community_portal" title="About the project, what you can do, where to find things">Community portal</a></li><li id="n-recentchanges"><a accesskey="r" href="/wiki/Special:RecentChanges" title="A list of recent changes in the wiki [r]">Recent changes</a></li><li id="n-contactpage"><a href="//en.wikipedia.org/wiki/Wikipedia:Contact_us" title="How to contact Wikipedia">Contact page</a></li></ul>
</div>
</div>
<div aria-labelledby="p-tb-label" class="portal" id="p-tb" role="navigation">
<h3 id="p-tb-label">
    			Tools
    		</h3>
<div class="body">
<ul><li id="t-whatlinkshere"><a accesskey="j" href="/wiki/Special:WhatLinksHere/Expectation%E2%80%93maximization_algorithm" title="List of all English Wikipedia pages containing links to this page [j]">What links here</a></li><li id="t-recentchangeslinked"><a accesskey="k" href="/wiki/Special:RecentChangesLinked/Expectation%E2%80%93maximization_algorithm" rel="nofollow" title="Recent changes in pages linked from this page [k]">Related changes</a></li><li id="t-upload"><a accesskey="u" href="/wiki/Wikipedia:File_Upload_Wizard" title="Upload files [u]">Upload file</a></li><li id="t-specialpages"><a accesskey="q" href="/wiki/Special:SpecialPages" title="A list of all special pages [q]">Special pages</a></li><li id="t-permalink"><a href="/w/index.php?title=Expectation%E2%80%93maximization_algorithm&amp;oldid=949604842" title="Permanent link to this revision of the page">Permanent link</a></li><li id="t-info"><a href="/w/index.php?title=Expectation%E2%80%93maximization_algorithm&amp;action=info" title="More information about this page">Page information</a></li><li id="t-wikibase"><a accesskey="g" href="https://www.wikidata.org/wiki/Special:EntityPage/Q1275153" title="Link to connected data repository item [g]">Wikidata item</a></li><li id="t-cite"><a href="/w/index.php?title=Special:CiteThisPage&amp;page=Expectation%E2%80%93maximization_algorithm&amp;id=949604842&amp;wpFormIdentifier=titleform" title="Information on how to cite this page">Cite this page</a></li></ul>
</div>
</div>
<div aria-labelledby="p-coll-print_export-label" class="portal" id="p-coll-print_export" role="navigation">
<h3 id="p-coll-print_export-label">
    			Print/export
    		</h3>
<div class="body">
<ul><li id="coll-create_a_book"><a href="/w/index.php?title=Special:Book&amp;bookcmd=book_creator&amp;referer=Expectation%E2%80%93maximization+algorithm">Create a book</a></li><li id="coll-download-as-rl"><a href="/w/index.php?title=Special:ElectronPdf&amp;page=Expectation%E2%80%93maximization+algorithm&amp;action=show-download-screen">Download as PDF</a></li><li id="t-print"><a accesskey="p" href="/w/index.php?title=Expectation%E2%80%93maximization_algorithm&amp;printable=yes" title="Printable version of this page [p]">Printable version</a></li></ul>
</div>
</div>
<div aria-labelledby="p-lang-label" class="portal" id="p-lang" role="navigation">
<h3 id="p-lang-label">
    			Languages
    		</h3>
<div class="body">
<ul><li class="interlanguage-link interwiki-ar"><a class="interlanguage-link-target" href="https://ar.wikipedia.org/wiki/%D8%AA%D8%AD%D9%82%D9%8A%D9%82_%D8%A3%D9%82%D8%B5%D9%89_%D9%82%D8%AF%D8%B1_%D9%84%D9%84%D8%AA%D9%88%D9%82%D8%B9_(EM)" hreflang="ar" lang="ar" title="تحقيق أقصى قدر للتوقع (EM) – Arabic">العربية</a></li><li class="interlanguage-link interwiki-cs"><a class="interlanguage-link-target" href="https://cs.wikipedia.org/wiki/EM_algoritmus" hreflang="cs" lang="cs" title="EM algoritmus – Czech">Čeština</a></li><li class="interlanguage-link interwiki-de"><a class="interlanguage-link-target" href="https://de.wikipedia.org/wiki/EM-Algorithmus" hreflang="de" lang="de" title="EM-Algorithmus – German">Deutsch</a></li><li class="interlanguage-link interwiki-es"><a class="interlanguage-link-target" href="https://es.wikipedia.org/wiki/Algoritmo_esperanza-maximizaci%C3%B3n" hreflang="es" lang="es" title="Algoritmo esperanza-maximización – Spanish">Español</a></li><li class="interlanguage-link interwiki-fa"><a class="interlanguage-link-target" href="https://fa.wikipedia.org/wiki/%D8%A7%D9%84%DA%AF%D9%88%D8%B1%DB%8C%D8%AA%D9%85_%D8%A7%D9%85%DB%8C%D8%AF_%D8%B1%DB%8C%D8%A7%D8%B6%DB%8C%E2%80%93%D8%A8%DB%8C%D8%B4%DB%8C%D9%86%D9%87_%DA%A9%D8%B1%D8%AF%D9%86" hreflang="fa" lang="fa" title="الگوریتم امید ریاضی–بیشینه کردن – Persian">فارسی</a></li><li class="interlanguage-link interwiki-fr"><a class="interlanguage-link-target" href="https://fr.wikipedia.org/wiki/Algorithme_esp%C3%A9rance-maximisation" hreflang="fr" lang="fr" title="Algorithme espérance-maximisation – French">Français</a></li><li class="interlanguage-link interwiki-ko"><a class="interlanguage-link-target" href="https://ko.wikipedia.org/wiki/%EA%B8%B0%EB%8C%93%EA%B0%92_%EC%B5%9C%EB%8C%80%ED%99%94_%EC%95%8C%EA%B3%A0%EB%A6%AC%EC%A6%98" hreflang="ko" lang="ko" title="기댓값 최대화 알고리즘 – Korean">한국어</a></li><li class="interlanguage-link interwiki-he"><a class="interlanguage-link-target" href="https://he.wikipedia.org/wiki/%D7%90%D7%9C%D7%92%D7%95%D7%A8%D7%99%D7%AA%D7%9D_%D7%9E%D7%99%D7%A7%D7%A1%D7%95%D7%9D_%D7%94%D7%AA%D7%95%D7%97%D7%9C%D7%AA" hreflang="he" lang="he" title="אלגוריתם מיקסום התוחלת – Hebrew">עברית</a></li><li class="interlanguage-link interwiki-ja"><a class="interlanguage-link-target" href="https://ja.wikipedia.org/wiki/EM%E3%82%A2%E3%83%AB%E3%82%B4%E3%83%AA%E3%82%BA%E3%83%A0" hreflang="ja" lang="ja" title="EMアルゴリズム – Japanese">日本語</a></li><li class="interlanguage-link interwiki-ru"><a class="interlanguage-link-target" href="https://ru.wikipedia.org/wiki/EM-%D0%B0%D0%BB%D0%B3%D0%BE%D1%80%D0%B8%D1%82%D0%BC" hreflang="ru" lang="ru" title="EM-алгоритм – Russian">Русский</a></li><li class="interlanguage-link interwiki-sr"><a class="interlanguage-link-target" href="https://sr.wikipedia.org/wiki/%D0%90%D0%BB%D0%B3%D0%BE%D1%80%D0%B8%D1%82%D0%B0%D0%BC_%D0%BE%D1%87%D0%B5%D0%BA%D0%B8%D0%B2%D0%B0%D1%9A%D0%B0-%D0%BC%D0%B0%D0%BA%D1%81%D0%B8%D0%BC%D0%B8%D0%B7%D0%B0%D1%86%D0%B8%D1%98%D0%B5" hreflang="sr" lang="sr" title="Алгоритам очекивања-максимизације – Serbian">Српски / srpski</a></li><li class="interlanguage-link interwiki-su"><a class="interlanguage-link-target" href="https://su.wikipedia.org/wiki/Expectation-maximization_algorithm" hreflang="su" lang="su" title="Expectation-maximization algorithm – Sundanese">Sunda</a></li><li class="interlanguage-link interwiki-fi"><a class="interlanguage-link-target" href="https://fi.wikipedia.org/wiki/EM-algoritmi" hreflang="fi" lang="fi" title="EM-algoritmi – Finnish">Suomi</a></li><li class="interlanguage-link interwiki-tr"><a class="interlanguage-link-target" href="https://tr.wikipedia.org/wiki/Beklenti_maksimizasyon" hreflang="tr" lang="tr" title="Beklenti maksimizasyon – Turkish">Türkçe</a></li><li class="interlanguage-link interwiki-uk"><a class="interlanguage-link-target" href="https://uk.wikipedia.org/wiki/%D0%95%D0%9C-%D0%B0%D0%BB%D0%B3%D0%BE%D1%80%D0%B8%D1%82%D0%BC" hreflang="uk" lang="uk" title="ЕМ-алгоритм – Ukrainian">Українська</a></li><li class="interlanguage-link interwiki-vi"><a class="interlanguage-link-target" href="https://vi.wikipedia.org/wiki/Thu%E1%BA%ADt_to%C3%A1n_c%E1%BB%B1c_%C4%91%E1%BA%A1i_h%C3%B3a_k%E1%BB%B3_v%E1%BB%8Dng" hreflang="vi" lang="vi" title="Thuật toán cực đại hóa kỳ vọng – Vietnamese">Tiếng Việt</a></li><li class="interlanguage-link interwiki-zh"><a class="interlanguage-link-target" href="https://zh.wikipedia.org/wiki/%E6%9C%80%E5%A4%A7%E6%9C%9F%E6%9C%9B%E7%AE%97%E6%B3%95" hreflang="zh" lang="zh" title="最大期望算法 – Chinese">中文</a></li></ul>
<div class="after-portlet after-portlet-lang"><span class="wb-langlinks-edit wb-langlinks-link"><a class="wbc-editpage" href="https://www.wikidata.org/wiki/Special:EntityPage/Q1275153#sitelinks-wikipedia" title="Edit interlanguage links">Edit links</a></span></div>
</div>
</div>
</div>
</div>
<div id="footer" role="contentinfo">
<ul class="" id="footer-info">
<li id="footer-info-lastmod"> This page was last edited on 7 April 2020, at 13:21<span class="anonymous-show"> (UTC)</span>.</li>
<li id="footer-info-copyright">Text is available under the <a href="//en.wikipedia.org/wiki/Wikipedia:Text_of_Creative_Commons_Attribution-ShareAlike_3.0_Unported_License" rel="license">Creative Commons Attribution-ShareAlike License</a><a href="//creativecommons.org/licenses/by-sa/3.0/" rel="license" style="display:none;"></a>;
additional terms may apply.  By using this site, you agree to the <a href="//foundation.wikimedia.org/wiki/Terms_of_Use">Terms of Use</a> and <a href="//foundation.wikimedia.org/wiki/Privacy_policy">Privacy Policy</a>. Wikipedia® is a registered trademark of the <a href="//www.wikimediafoundation.org/">Wikimedia Foundation, Inc.</a>, a non-profit organization.</li>
</ul>
<ul class="" id="footer-places">
<li id="footer-places-privacy"><a class="extiw" href="https://foundation.wikimedia.org/wiki/Privacy_policy" title="wmf:Privacy policy">Privacy policy</a></li>
<li id="footer-places-about"><a href="/wiki/Wikipedia:About" title="Wikipedia:About">About Wikipedia</a></li>
<li id="footer-places-disclaimer"><a href="/wiki/Wikipedia:General_disclaimer" title="Wikipedia:General disclaimer">Disclaimers</a></li>
<li id="footer-places-contact"><a href="//en.wikipedia.org/wiki/Wikipedia:Contact_us">Contact Wikipedia</a></li>
<li id="footer-places-developers"><a href="https://www.mediawiki.org/wiki/Special:MyLanguage/How_to_contribute">Developers</a></li>
<li id="footer-places-statslink"><a href="https://stats.wikimedia.org/#/en.wikipedia.org">Statistics</a></li>
<li id="footer-places-cookiestatement"><a href="https://foundation.wikimedia.org/wiki/Cookie_statement">Cookie statement</a></li>
<li id="footer-places-mobileview"><a class="noprint stopMobileRedirectToggle" href="//en.m.wikipedia.org/w/index.php?title=Expectation%E2%80%93maximization_algorithm&amp;mobileaction=toggle_view_mobile">Mobile view</a></li>
</ul>
<ul class="noprint" id="footer-icons">
<li id="footer-copyrightico"><a href="https://wikimediafoundation.org/"><img alt="Wikimedia Foundation" height="31" src="/static/images/wikimedia-button.png" srcset="/static/images/wikimedia-button-1.5x.png 1.5x, /static/images/wikimedia-button-2x.png 2x" width="88"/></a></li>
<li id="footer-poweredbyico"><a href="https://www.mediawiki.org/"><img alt="Powered by MediaWiki" height="31" src="/static/images/poweredby_mediawiki_88x31.png" srcset="/static/images/poweredby_mediawiki_132x47.png 1.5x, /static/images/poweredby_mediawiki_176x62.png 2x" width="88"/></a></li>
</ul>
<div style="clear: both;"></div>
</div>
<script>(RLQ=window.RLQ||[]).push(function(){mw.config.set({"wgPageParseReport":{"limitreport":{"cputime":"0.752","walltime":"1.141","ppvisitednodes":{"value":2929,"limit":1000000},"postexpandincludesize":{"value":96754,"limit":2097152},"templateargumentsize":{"value":2576,"limit":2097152},"expansiondepth":{"value":12,"limit":40},"expensivefunctioncount":{"value":9,"limit":500},"unstrip-depth":{"value":1,"limit":20},"unstrip-size":{"value":116300,"limit":5000000},"entityaccesscount":{"value":7,"limit":400},"timingprofile":["100.00%  668.364      1 -total"," 60.94%  407.269      1 Template:Reflist"," 48.20%  322.153     26 Template:Cite_journal"," 10.22%   68.336      7 Template:Cite_book","  9.76%   65.209      3 Template:Citation_needed","  8.47%   56.606      1 Template:Short_description","  8.04%   53.764      3 Template:Fix","  7.62%   50.951      1 Template:Machine_learning_bar","  7.10%   47.478      1 Template:Sidebar_with_collapsible_lists","  5.85%   39.106      1 Template:Pagetype"]},"scribunto":{"limitreport-timeusage":{"value":"0.354","limit":"10.000"},"limitreport-memusage":{"value":6292602,"limit":52428800}},"cachereport":{"origin":"mw1373","timestamp":"20200407175517","ttl":2592000,"transientcontent":false}}});});</script>
<script type="application/ld+json">{"@context":"https:\/\/schema.org","@type":"Article","name":"Expectation\u2013maximization algorithm","url":"https:\/\/en.wikipedia.org\/wiki\/Expectation%E2%80%93maximization_algorithm","sameAs":"http:\/\/www.wikidata.org\/entity\/Q1275153","mainEntity":"http:\/\/www.wikidata.org\/entity\/Q1275153","author":{"@type":"Organization","name":"Contributors to Wikimedia projects"},"publisher":{"@type":"Organization","name":"Wikimedia Foundation, Inc.","logo":{"@type":"ImageObject","url":"https:\/\/www.wikimedia.org\/static\/images\/wmf-hor-googpub.png"}},"datePublished":"2004-02-15T18:39:48Z","dateModified":"2020-04-07T13:21:58Z","image":"https:\/\/upload.wikimedia.org\/wikipedia\/commons\/6\/69\/EM_Clustering_of_Old_Faithful_data.gif","headline":"iterative method for finding maximum likelihood estimates in statistical models"}</script>
<script>(RLQ=window.RLQ||[]).push(function(){mw.config.set({"wgBackendResponseTime":107,"wgHostname":"mw1329"});});</script></body></html>
