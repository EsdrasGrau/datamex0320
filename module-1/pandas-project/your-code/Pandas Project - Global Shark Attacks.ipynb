{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas Project - Global Shark Attacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from datetime import datetime\n",
    "from datetime import date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Case Number</th>\n",
       "      <th>Date</th>\n",
       "      <th>Year</th>\n",
       "      <th>Type</th>\n",
       "      <th>Country</th>\n",
       "      <th>Area</th>\n",
       "      <th>Location</th>\n",
       "      <th>Activity</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Injury</th>\n",
       "      <th>Fatal (Y/N)</th>\n",
       "      <th>Time</th>\n",
       "      <th>Species</th>\n",
       "      <th>Investigator or Source</th>\n",
       "      <th>pdf</th>\n",
       "      <th>href formula</th>\n",
       "      <th>href</th>\n",
       "      <th>Case Number.1</th>\n",
       "      <th>Case Number.2</th>\n",
       "      <th>original order</th>\n",
       "      <th>Unnamed: 22</th>\n",
       "      <th>Unnamed: 23</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018.06.25</td>\n",
       "      <td>25-Jun-2018</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>Boating</td>\n",
       "      <td>USA</td>\n",
       "      <td>California</td>\n",
       "      <td>Oceanside, San Diego County</td>\n",
       "      <td>Paddling</td>\n",
       "      <td>Julie Wolfe</td>\n",
       "      <td>F</td>\n",
       "      <td>57</td>\n",
       "      <td>No injury to occupant, outrigger canoe and pad...</td>\n",
       "      <td>N</td>\n",
       "      <td>18h00</td>\n",
       "      <td>White shark</td>\n",
       "      <td>R. Collier, GSAF</td>\n",
       "      <td>2018.06.25-Wolfe.pdf</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>2018.06.25</td>\n",
       "      <td>2018.06.25</td>\n",
       "      <td>6303.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018.06.18</td>\n",
       "      <td>18-Jun-2018</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>Unprovoked</td>\n",
       "      <td>USA</td>\n",
       "      <td>Georgia</td>\n",
       "      <td>St. Simon Island, Glynn County</td>\n",
       "      <td>Standing</td>\n",
       "      <td>Adyson McNeely</td>\n",
       "      <td>F</td>\n",
       "      <td>11</td>\n",
       "      <td>Minor injury to left thigh</td>\n",
       "      <td>N</td>\n",
       "      <td>14h00  -15h00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>K.McMurray, TrackingSharks.com</td>\n",
       "      <td>2018.06.18-McNeely.pdf</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>2018.06.18</td>\n",
       "      <td>2018.06.18</td>\n",
       "      <td>6302.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018.06.09</td>\n",
       "      <td>09-Jun-2018</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>Invalid</td>\n",
       "      <td>USA</td>\n",
       "      <td>Hawaii</td>\n",
       "      <td>Habush, Oahu</td>\n",
       "      <td>Surfing</td>\n",
       "      <td>John Denges</td>\n",
       "      <td>M</td>\n",
       "      <td>48</td>\n",
       "      <td>Injury to left lower leg from surfboard skeg</td>\n",
       "      <td>N</td>\n",
       "      <td>07h45</td>\n",
       "      <td>NaN</td>\n",
       "      <td>K.McMurray, TrackingSharks.com</td>\n",
       "      <td>2018.06.09-Denges.pdf</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>2018.06.09</td>\n",
       "      <td>2018.06.09</td>\n",
       "      <td>6301.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018.06.08</td>\n",
       "      <td>08-Jun-2018</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>Unprovoked</td>\n",
       "      <td>AUSTRALIA</td>\n",
       "      <td>New South Wales</td>\n",
       "      <td>Arrawarra Headland</td>\n",
       "      <td>Surfing</td>\n",
       "      <td>male</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Minor injury to lower leg</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2 m shark</td>\n",
       "      <td>B. Myatt, GSAF</td>\n",
       "      <td>2018.06.08-Arrawarra.pdf</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>2018.06.08</td>\n",
       "      <td>2018.06.08</td>\n",
       "      <td>6300.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018.06.04</td>\n",
       "      <td>04-Jun-2018</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>Provoked</td>\n",
       "      <td>MEXICO</td>\n",
       "      <td>Colima</td>\n",
       "      <td>La Ticla</td>\n",
       "      <td>Free diving</td>\n",
       "      <td>Gustavo Ramos</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Lacerations to leg &amp; hand shark PROVOKED INCIDENT</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tiger shark, 3m</td>\n",
       "      <td>A .Kipper</td>\n",
       "      <td>2018.06.04-Ramos.pdf</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>2018.06.04</td>\n",
       "      <td>2018.06.04</td>\n",
       "      <td>6299.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Case Number         Date    Year        Type    Country             Area  \\\n",
       "0  2018.06.25  25-Jun-2018  2018.0     Boating        USA       California   \n",
       "1  2018.06.18  18-Jun-2018  2018.0  Unprovoked        USA          Georgia   \n",
       "2  2018.06.09  09-Jun-2018  2018.0     Invalid        USA           Hawaii   \n",
       "3  2018.06.08  08-Jun-2018  2018.0  Unprovoked  AUSTRALIA  New South Wales   \n",
       "4  2018.06.04  04-Jun-2018  2018.0    Provoked     MEXICO           Colima   \n",
       "\n",
       "                         Location     Activity             Name Sex   Age  \\\n",
       "0     Oceanside, San Diego County     Paddling      Julie Wolfe    F   57   \n",
       "1  St. Simon Island, Glynn County     Standing  Adyson McNeely     F   11   \n",
       "2                    Habush, Oahu      Surfing      John Denges    M   48   \n",
       "3              Arrawarra Headland      Surfing             male    M  NaN   \n",
       "4                        La Ticla  Free diving   Gustavo Ramos     M  NaN   \n",
       "\n",
       "                                              Injury Fatal (Y/N)  \\\n",
       "0  No injury to occupant, outrigger canoe and pad...           N   \n",
       "1                         Minor injury to left thigh           N   \n",
       "2       Injury to left lower leg from surfboard skeg           N   \n",
       "3                          Minor injury to lower leg           N   \n",
       "4  Lacerations to leg & hand shark PROVOKED INCIDENT           N   \n",
       "\n",
       "            Time         Species           Investigator or Source  \\\n",
       "0          18h00      White shark                R. Collier, GSAF   \n",
       "1  14h00  -15h00              NaN  K.McMurray, TrackingSharks.com   \n",
       "2          07h45              NaN  K.McMurray, TrackingSharks.com   \n",
       "3            NaN        2 m shark                  B. Myatt, GSAF   \n",
       "4            NaN  Tiger shark, 3m                       A .Kipper   \n",
       "\n",
       "                        pdf  \\\n",
       "0      2018.06.25-Wolfe.pdf   \n",
       "1    2018.06.18-McNeely.pdf   \n",
       "2     2018.06.09-Denges.pdf   \n",
       "3  2018.06.08-Arrawarra.pdf   \n",
       "4      2018.06.04-Ramos.pdf   \n",
       "\n",
       "                                        href formula  \\\n",
       "0  http://sharkattackfile.net/spreadsheets/pdf_di...   \n",
       "1  http://sharkattackfile.net/spreadsheets/pdf_di...   \n",
       "2  http://sharkattackfile.net/spreadsheets/pdf_di...   \n",
       "3  http://sharkattackfile.net/spreadsheets/pdf_di...   \n",
       "4  http://sharkattackfile.net/spreadsheets/pdf_di...   \n",
       "\n",
       "                                                href Case Number.1  \\\n",
       "0  http://sharkattackfile.net/spreadsheets/pdf_di...    2018.06.25   \n",
       "1  http://sharkattackfile.net/spreadsheets/pdf_di...    2018.06.18   \n",
       "2  http://sharkattackfile.net/spreadsheets/pdf_di...    2018.06.09   \n",
       "3  http://sharkattackfile.net/spreadsheets/pdf_di...    2018.06.08   \n",
       "4  http://sharkattackfile.net/spreadsheets/pdf_di...    2018.06.04   \n",
       "\n",
       "  Case Number.2  original order Unnamed: 22 Unnamed: 23  \n",
       "0    2018.06.25          6303.0         NaN         NaN  \n",
       "1    2018.06.18          6302.0         NaN         NaN  \n",
       "2    2018.06.09          6301.0         NaN         NaN  \n",
       "3    2018.06.08          6300.0         NaN         NaN  \n",
       "4    2018.06.04          6299.0         NaN         NaN  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df = pd.read_csv(\"attacks.csv\") #open CVS, first try had an encode problem\n",
    "df = pd.read_csv(\"attacks.csv\", encoding='latin-1')\n",
    "\n",
    "df.head() #to start exploring the df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 25723 entries, 0 to 25722\n",
      "Data columns (total 24 columns):\n",
      " #   Column                  Non-Null Count  Dtype  \n",
      "---  ------                  --------------  -----  \n",
      " 0   Case Number             8702 non-null   object \n",
      " 1   Date                    6302 non-null   object \n",
      " 2   Year                    6300 non-null   float64\n",
      " 3   Type                    6298 non-null   object \n",
      " 4   Country                 6252 non-null   object \n",
      " 5   Area                    5847 non-null   object \n",
      " 6   Location                5762 non-null   object \n",
      " 7   Activity                5758 non-null   object \n",
      " 8   Name                    6092 non-null   object \n",
      " 9   Sex                     5737 non-null   object \n",
      " 10  Age                     3471 non-null   object \n",
      " 11  Injury                  6274 non-null   object \n",
      " 12  Fatal (Y/N)             5763 non-null   object \n",
      " 13  Time                    2948 non-null   object \n",
      " 14  Species                 3464 non-null   object \n",
      " 15  Investigator or Source  6285 non-null   object \n",
      " 16  pdf                     6302 non-null   object \n",
      " 17  href formula            6301 non-null   object \n",
      " 18  href                    6302 non-null   object \n",
      " 19  Case Number.1           6302 non-null   object \n",
      " 20  Case Number.2           6302 non-null   object \n",
      " 21  original order          6309 non-null   float64\n",
      " 22  Unnamed: 22             1 non-null      object \n",
      " 23  Unnamed: 23             2 non-null      object \n",
      "dtypes: float64(2), object(22)\n",
      "memory usage: 4.7+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info() #to check the types of data of each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([nan, 'stopped here'], dtype=object)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Unnamed: 22'].unique() #comfirming unique values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing Nan values to Unknown\n",
    "df[['Unnamed: 22']]= df[['Unnamed: 22']].fillna('Unknown')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing Nan values to Unknown\n",
    "df[['Unnamed: 23']]= df[['Unnamed: 23']].fillna('Unknown')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['Case Number'].isna() #exploring Nan values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Case Number</th>\n",
       "      <th>Date</th>\n",
       "      <th>Year</th>\n",
       "      <th>Type</th>\n",
       "      <th>Country</th>\n",
       "      <th>Area</th>\n",
       "      <th>Location</th>\n",
       "      <th>Activity</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Injury</th>\n",
       "      <th>Fatal (Y/N)</th>\n",
       "      <th>Time</th>\n",
       "      <th>Species</th>\n",
       "      <th>Investigator or Source</th>\n",
       "      <th>pdf</th>\n",
       "      <th>href formula</th>\n",
       "      <th>href</th>\n",
       "      <th>Case Number.1</th>\n",
       "      <th>Case Number.2</th>\n",
       "      <th>original order</th>\n",
       "      <th>Unnamed: 22</th>\n",
       "      <th>Unnamed: 23</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25718</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25719</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25720</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25721</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25722</th>\n",
       "      <td>xx</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Case Number Date  Year Type Country Area Location Activity Name Sex   \\\n",
       "25718         NaN  NaN   NaN  NaN     NaN  NaN      NaN      NaN  NaN  NaN   \n",
       "25719         NaN  NaN   NaN  NaN     NaN  NaN      NaN      NaN  NaN  NaN   \n",
       "25720         NaN  NaN   NaN  NaN     NaN  NaN      NaN      NaN  NaN  NaN   \n",
       "25721         NaN  NaN   NaN  NaN     NaN  NaN      NaN      NaN  NaN  NaN   \n",
       "25722          xx  NaN   NaN  NaN     NaN  NaN      NaN      NaN  NaN  NaN   \n",
       "\n",
       "       Age Injury Fatal (Y/N) Time Species  Investigator or Source  pdf  \\\n",
       "25718  NaN    NaN         NaN  NaN      NaN                    NaN  NaN   \n",
       "25719  NaN    NaN         NaN  NaN      NaN                    NaN  NaN   \n",
       "25720  NaN    NaN         NaN  NaN      NaN                    NaN  NaN   \n",
       "25721  NaN    NaN         NaN  NaN      NaN                    NaN  NaN   \n",
       "25722  NaN    NaN         NaN  NaN      NaN                    NaN  NaN   \n",
       "\n",
       "      href formula href Case Number.1 Case Number.2  original order  \\\n",
       "25718          NaN  NaN           NaN           NaN             NaN   \n",
       "25719          NaN  NaN           NaN           NaN             NaN   \n",
       "25720          NaN  NaN           NaN           NaN             NaN   \n",
       "25721          NaN  NaN           NaN           NaN             NaN   \n",
       "25722          NaN  NaN           NaN           NaN             NaN   \n",
       "\n",
       "      Unnamed: 22 Unnamed: 23  \n",
       "25718     Unknown     Unknown  \n",
       "25719     Unknown     Unknown  \n",
       "25720     Unknown     Unknown  \n",
       "25721     Unknown     Unknown  \n",
       "25722     Unknown     Unknown  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail() #exploring Nan values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=df.copy() #Security copy: por aquello de no te enfries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(df.index[6302:25723], inplace = True) #To delete Unnecesary rows with no data.\n",
    "#df.dropna(thresh=10) other method to drop rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['2018.06.25', '2018.06.18', '2018.06.09', ..., 'ND.0003',\n",
       "       'ND.0002', 'ND.0001'], dtype=object)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Case Number'].unique() #identifiying elements to clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.loc[(df['Case Number'] == 'ND.0001'),'Case Number']='Unknow date' #renaming values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df[‘Case Number’].str.startswith(‘ND’)=‘Unknow date’\n",
    "#df['Case Number'].apply(lambda x: re.sub('ND\\w+', 'Unknow date', x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['Case Number'] = df['Case Number'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['Case Number'].apply(lambda x: re.sub('ND\\w+', 'Unknow date', x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['Case Number'].str.startswith('ND')='Unknow date'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.replace({'Case Number': r'^ND.$'}, {'Case Number': 'Unkown'}, regex=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['Case Number'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['Year']]= df[['Year']].fillna('Unknown') #Changing NA values\n",
    "df[['Type']]= df[['Type']].fillna('Unknown reason') #Changing NA values\n",
    "df[['Country']]= df[['Country']].fillna('Unknown area') #Changing NA values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Case Number                  1\n",
       "Area                       455\n",
       "Location                   540\n",
       "Activity                   544\n",
       "Name                       210\n",
       "Sex                        565\n",
       "Age                       2831\n",
       "Injury                      28\n",
       "Fatal (Y/N)                539\n",
       "Time                      3354\n",
       "Species                   2838\n",
       "Investigator or Source      17\n",
       "href formula                 1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "null_cols = df.isnull().sum() #checking for other null and related values \n",
    "null_cols[null_cols>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "null_displ = df[(df['Location'].isnull()==True)] #checking null values related with Location\n",
    "null_displ = null_displ[['Location', 'Activity', 'Name', 'Age', 'Injury', 'Fatal (Y/N)', 'Time', 'Investigator or Source', 'href formula']]\n",
    "#null_displ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['Location']] = df[['Location']].fillna(\"Unknow Location\") #changing null values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['Time']] = df[['Time']].fillna(\"Unknow Time\") #changing null values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['Age']] = df[['Age']].fillna(\"Age\") #changing null values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Case Number                  1\n",
       "Area                       455\n",
       "Activity                   544\n",
       "Name                       210\n",
       "Sex                        565\n",
       "Injury                      28\n",
       "Fatal (Y/N)                539\n",
       "Species                   2838\n",
       "Investigator or Source      17\n",
       "href formula                 1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "null_cols = df.isnull().sum() #checking for other null and related values \n",
    "null_cols[null_cols>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "null_displ = df[(df['Area'].isnull()==True)] #checking null values related with Location\n",
    "null_displ = null_displ[['Activity', 'Name','Injury', 'Fatal (Y/N)', 'Investigator or Source', 'href formula']]\n",
    "#null_displ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['Activity', 'Name', 'Investigator or Source', 'href formula']] = df[['Activity', 'Name', 'Investigator or Source', 'href formula']].fillna(\"Not specified\") #changing null values in multiple columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['Area', 'Injury']] = df[['Area', 'Injury']].fillna(\"Not specified\") #changing null values in multiple columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['Fatal (Y/N)']] = df[['Fatal (Y/N)']].fillna(\"Unknow\") #changing null values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Case Number       1\n",
       "Sex             565\n",
       "Species        2838\n",
       "dtype: int64"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "null_cols = df.isnull().sum() #checking for other null and related values \n",
    "null_cols[null_cols>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = df.columns.to_series().apply(lambda x: x.strip()) #fixing the columns names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['Sex', 'Species']] = df[['Sex', 'Species']].fillna(\"Not specified\") #changing null values in multiple columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Year\"].replace({0: \"Time Frame\"}, inplace=True) #changing the column year 0 to specify a time frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None) #to show all the columns \n",
    "pd.set_option(\"display.max_rows\", None) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['25-Jun-2018', '18-Jun-2018', '09-Jun-2018', ..., '1900-1905',\n",
       "       '1883-1889', '1845-1853'], dtype=object)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Date'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replacing very specific dates\n",
    "df[\"Date\"].replace({'Last incident of 1994 in Hong Kong': 1994}, inplace=True)\n",
    "df[\"Date\"].replace({'1954 (same day as 1954.00.00.f)': 1954}, inplace=True)\n",
    "df[\"Date\"].replace({'Mar-1949 or Apr-1949': 'Between Mar & Apr'}, inplace=True)\n",
    "df[\"Date\"].replace({'Some time between 08-Jan-1928 & 21-Jan-1928': 'Between 08-Jan & 21-Jan'}, inplace=True)\n",
    "df[\"Date\"].replace({'1899 During the Seige of Ladysmith': '1899'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Date']=df['Date'].str.replace('Reported ', '')\n",
    "df['Date']=df['Date'].str.replace('Ca. ', '')\n",
    "df['Date']=df['Date'].str.replace('.b', '')\n",
    "df['Date']=df['Date'].str.replace('.a', '')\n",
    "df['Date']=df['Date'].str.replace(' to have happened \"on the weekend\"', '')\n",
    "df['Date']=df['Date'].str.replace('Reported', '')\n",
    "df['Date']=df['Date'].str.replace(' (same day as 1954.00.00.f)', '')\n",
    "df['Date']=df['Date'].str.replace('\\n1951.12.15.R', '15-Dec-1951')\n",
    "df['Date']=df['Date'].str.replace('\"Bitten last weekend', '')\n",
    "df['Date']=df['Date'].str.replace('\"Some time b', 'B')\n",
    "df['Date']=df['Date'].str.replace('Woirld War II', '1939')\n",
    "df['Date']=df['Date'].str.replace('to have taken place in ', '1919')\n",
    "df['Date']=df['Date'].str.replace('Reportd ', '')\n",
    "df['Date']=df['Date'].str.replace('(probably happened Ca. 1843/1844)', '')\n",
    "df['Date']=df['Date'].str.replace('Reprted ', '')\n",
    "#df['Date']=df['Date'].str.replace(' (?)', '') #somehow didn't work\n",
    "df['Date']=df['Date'].str.replace('\"Anniversary Day\" 22-Jan-1850 or 1852', '22-Jan-1852')\n",
    "df['Date']=df['Date'].str.replace('.R', '')\n",
    "#df['Date']=df['Date'].str.replace('.00.', '') #deletes somes years between 1000 and 2000\n",
    "df['Date']=df['Date'].str.replace('24-Oct-1888,ut took pceround 1868', '24-Oct-1868')\n",
    "df['Date']=df['Date'].str.replace('(prly ppened 1843/1844)', '')\n",
    "df['Date']=df['Date'].str.replace('(soonfter the close of the Snish-Amerin r)', '')\n",
    "df['Date']=df['Date'].str.replace('to ve ken pce in ', '')\n",
    "df['Date']=df['Date'].str.replace('Some timeetween ', 'Between')\n",
    "df['Date']=df['Date'].str.replace('(me ys 195400.f)', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[187,'Year']=2017 #changing specific dates in Year\n",
    "df.loc[6079,'Year']=1836"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Type']=df['Type'].str.replace('Invalid', 'Unknown') #fixing ambiguous values\n",
    "df['Type']=df['Type'].str.replace('Questionable', 'Unknown')\n",
    "df['Country']=df['Country'].str.replace('MEXICO ', 'MEXICO')\n",
    "df['Country']=df['Country'].str.replace('OKINAWA', 'JAPAN')\n",
    "df['Country']=df['Country'].str.replace('Usa', 'USA')\n",
    "df['Country']=df['Country'].str.replace('Sudan?', 'Sudan')\n",
    "df['Country']=df['Country'].str.replace('United Arab Emirates (Uae)', 'United Arab Emirates (UAE)')\n",
    "df[\"Country\"]= df[\"Country\"].str.upper().str.title() #fixing country names as titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={'Country': 'Region'}, inplace=True) \n",
    "#changing the name of the column to reflect a region and not only countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fixing all uncodified area names \n",
    "df['Area']=df['Area'].str.replace('M�laga ', 'Malaga')\n",
    "df['Area']=df['Area'].str.replace('C�te', 'Cote')\n",
    "df['Area']=df['Area'].str.replace('Kh�nh H�a', 'Khanh Hoa province')\n",
    "df['Area']=df['Area'].str.replace('Sal�', 'Sale')\n",
    "df['Area']=df['Area'].str.replace('C�diz', 'Cadiz')\n",
    "df['Area']=df['Area'].str.replace('Andr�s', 'Andres')\n",
    "df['Area']=df['Area'].str.replace('Castell�n', 'Castellon')\n",
    "df['Area']=df['Area'].str.replace('Cort�s', 'Cortes')\n",
    "df['Area']=df['Area'].str.replace('Balne�rio Cambori�', 'Balnerio Camboriu')\n",
    "df['Area']=df['Area'].str.replace('35�39 : 165�8', 'Unknown')\n",
    "df['Area']=df['Area'].str.replace('Col�n', 'Colon')\n",
    "df['Area']=df['Area'].str.replace('Maranh�o', 'Maranhao')\n",
    "df['Area']=df['Area'].str.replace('10�S, 142�E', 'Unknown')\n",
    "df['Area']=df['Area'].str.replace('Vava�u', 'Vavau')\n",
    "df['Area']=df['Area'].str.replace('d��', 'D ')\n",
    "df['Area']=df['Area'].str.replace('Conservat�ria', 'Conservatoria')\n",
    "df['Area']=df['Area'].str.replace('Saint-Beno�t', 'Saint-Benoit')\n",
    "df['Area']=df['Area'].str.replace('Saman�', 'Saman')\n",
    "df['Area']=df['Area'].str.replace('Ma�shur', 'Ma\\'shur')\n",
    "df['Area']=df['Area'].str.replace('Lim�n', 'Limon')\n",
    "df['Area']=df['Area'].str.replace('22�N, 88�E', 'Unknown')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fixing location names \n",
    "df['Location']=df['Location'].str.replace('Mar�', 'Mar')\n",
    "df['Location']=df['Location'].str.replace('Caba�a ', 'Cabana')\n",
    "df['Location']=df['Location'].str.replace('Coff�s Harbor', 'Coffs Harbor')\n",
    "df['Location']=df['Location'].str.replace('Jeffrey�s', 'Jeffrey\\'s')\n",
    "df['Location']=df['Location'].str.replace('�Southern Wharf�', 'Southern Wharf')\n",
    "df['Location']=df['Location'].str.replace('Mark�s', 'Mark\\'s')\n",
    "df['Location']=df['Location'].str.replace('St. Thom�', 'St. Thomas')\n",
    "df['Location']=df['Location'].str.replace('Gordon�s Bay', 'Gordon\\'s Bay')\n",
    "df['Location']=df['Location'].str.replace('Ouv�a', 'Ouv\\'a')\n",
    "df['Location']=df['Location'].str.replace('36�17\\'N\\,  126�31\\'E', 'Unknown')\n",
    "df['Location']=df['Location'].str.replace('George�s', 'George\\'s')\n",
    "df['Location']=df['Location'].str.replace('Ca�o', 'Ca\\'s')\n",
    "df['Location']=df['Location'].str.replace('C�diz', 'Cadiz')\n",
    "df['Location']=df['Location'].str.replace('Poindimi�', 'Poindimie')\n",
    "df['Location']=df['Location'].str.replace('Trench�s', 'Trench\\'s')\n",
    "df['Location']=df['Location'].str.replace('Fisherman�s', 'Fisherman\\'s')\n",
    "df['Location']=df['Location'].str.replace('Dumb�a', 'Dumb a')\n",
    "df['Location']=df['Location'].str.replace('Anstey�s', 'Anstey\\'s')\n",
    "df['Location']=df['Location'].str.replace('Scott�s', 'Scott\\'s')\n",
    "df['Location']=df['Location'].str.replace('S�nchez', 'Sanchez')\n",
    "df['Location']=df['Location'].str.replace('C�rdenas', 'Cardenas')\n",
    "df['Location']=df['Location'].str.replace('Shaka�s', 'Shaka\\'s')\n",
    "df['Location']=df['Location'].str.replace('Shipwreck�s', 'Shipwreck\\'s')\n",
    "df['Location']=df['Location'].str.replace('S�o', 'S\\'o')\n",
    "df['Location']=df['Location'].str.replace('Monta�a', 'Montana')\n",
    "df['Location']=df['Location'].str.replace('�gua', 'Agua')\n",
    "df['Location']=df['Location'].str.replace('Ka�anapali', 'Kaanapali')\n",
    "df['Location']=df['Location'].str.replace('Sewell�s', 'Sewell\\'s')\n",
    "df['Location']=df['Location'].str.replace('Barand�a', 'Veranda Beach')\n",
    "df['Location']=df['Location'].str.replace('Nelson�s', 'Nelson\\'s')\n",
    "df['Location']=df['Location'].str.replace('Moku�auia', 'Mokuauia')\n",
    "df['Location']=df['Location'].str.replace('Maha�ulepu', 'Mahaulepu')\n",
    "df['Location']=df['Location'].str.replace('Brown�s', 'Brown\\'s')\n",
    "df['Location']=df['Location'].str.replace('�le', 'Le')\n",
    "df['Location']=df['Location'].str.replace('Campbell�s', 'Campbell\\'s')\n",
    "df['Location']=df['Location'].str.replace('Ah� Atoll', 'Ah Atoll')\n",
    "df['Location']=df['Location'].str.replace('d�Empuries', 'd\\'Empuries')\n",
    "df['Location']=df['Location'].str.replace('L�Escala', 'L\\'Escala')\n",
    "df['Location']=df['Location'].str.replace('Boca de la Le�a', 'Boca de la Le\\'a')\n",
    "df['Location']=df['Location'].str.replace('Uni�n', 'Union')\n",
    "df['Location']=df['Location'].str.replace('V?ng T�u', 'Unknown')\n",
    "df['Location']=df['Location'].str.replace('G�ldar', 'G ldar')\n",
    "df['Location']=df['Location'].str.replace('Yorkey�s', 'Yorkey\\'s')\n",
    "df['Location']=df['Location'].str.replace('Her�y', 'Herry') \n",
    "df['Location']=df['Location'].str.replace('Reef�', 'Reef')\n",
    "df['Location']=df['Location'].str.replace('Petite-�le', 'Le Petite')\n",
    "df['Location']=df['Location'].str.replace('Jaboat�o', 'Jaboato')\n",
    "df['Location']=df['Location'].str.replace('Woodman�s', 'Woodman\\'s')\n",
    "df['Location']=df['Location'].str.replace('22�08\\'S  : 178�06\\'W', 'Unknown')\n",
    "df['Location']=df['Location'].str.replace('Black�s', 'Black\\'s')\n",
    "df['Location']=df['Location'].str.replace('Wiseman�s', 'Wiseman\\'s')\n",
    "df['Location']=df['Location'].str.replace('Hadrian�s', 'Hadrian\\'s')\n",
    "df['Location']=df['Location'].str.replace('Kama�ole', 'Kamaole')                                  \n",
    "df['Location']=df['Location'].str.replace('Tu�anuku', 'Tu\\'anuku')\n",
    "df['Location']=df['Location'].str.replace('Vetch�s', 'Vetch\\'s')                                  \n",
    "df['Location']=df['Location'].str.replace('Pawley�s', 'Pawley\\'s')                                  \n",
    "df['Location']=df['Location'].str.replace('Lambert�s', 'Lambert\\'s')                                  \n",
    "df['Location']=df['Location'].str.replace('Sha�ab', 'Shaab')\n",
    "df['Location']=df['Location'].str.replace('Smith�s', 'Smith\\'s')                                  \n",
    "df['Location']=df['Location'].str.replace('One week out of P�pete', 'Unknown')                                  \n",
    "df['Location']=df['Location'].str.replace('Macei�', 'Macei')                                  \n",
    "df['Location']=df['Location'].str.replace('Ye?ilk�y', 'Unknown')\n",
    "df['Location']=df['Location'].str.replace('Sj�strand', 'Sj\\'strand')                                  \n",
    "df['Location']=df['Location'].str.replace('Gay�s', 'Gay\\'s')                                   \n",
    "df['Location']=df['Location'].str.replace('King�s', 'King\\'s')                                  \n",
    "df['Location']=df['Location'].str.replace('Pawley�s', 'Pawley\\'s')\n",
    "df['Location']=df['Location'].str.replace('Ile Yand� (between Poum and B�lep)', 'Ile Yand')                                  \n",
    "df['Location']=df['Location'].str.replace('C�te', 'Cote')                                   \n",
    "df['Location']=df['Location'].str.replace('Noum�a', 'Nouma')                                  \n",
    "df['Location']=df['Location'].str.replace('Lev�que', 'Lev\\'que')\n",
    "df['Location']=df['Location'].str.replace('� mile offshore & 9 miles north of Fort Pierce', 'Fort Pierce')                                  \n",
    "df['Location']=df['Location'].str.replace('Saua�uhy', 'Sauauhy')                                   \n",
    "df['Location']=df['Location'].str.replace('Saua�uhy', 'Sauauhy')                                  \n",
    "df['Location']=df['Location'].str.replace('Nu�ulua', 'Nuulua')\n",
    "df['Location']=df['Location'].str.replace('Mo�?eni?ka', 'Moscenicka')                                  \n",
    "df['Location']=df['Location'].str.replace('Hy�res', 'Unknown')                                   \n",
    "df['Location']=df['Location'].str.replace('Florida Keys 25�N,82�W', 'Florida Keys')                                  \n",
    "df['Location']=df['Location'].str.replace('Col�n', 'Colon')\n",
    "df['Location']=df['Location'].str.replace('Lind�ralique', 'Linda ralique')                                  \n",
    "df['Location']=df['Location'].str.replace('Hiengh�ne', 'Unknown')\n",
    "df['Location']=df['Location'].str.replace('Mazatl�n', 'Mazatlan')\n",
    "df['Location']=df['Location'].str.replace('Ye?ilk�y', 'Unknown')\n",
    "df['Location']=df['Location'].str.replace('10 miles west of Walker�s Cay', 'Walker\\'s Cay')\n",
    "df['Location']=df['Location'].str.replace('Mo�?eni?ka', 'Unknown')\n",
    "df['Location']=df['Location'].str.replace('Bull�s', 'Bull\\'s')\n",
    "df['Location']=df['Location'].str.replace('Quinn�s', 'Quinn\\'s')\n",
    "df['Location']=df['Location'].str.replace('Itamarac�', 'Itamarac')\n",
    "df['Location']=df['Location'].str.replace('Oah�u', 'Oah\\'u')\n",
    "df['Location']=df['Location'].str.replace('Granny�s', 'Granny\\'s')\n",
    "df['Location']=df['Location'].str.replace('Miller�s', 'Miller\\'s')\n",
    "df['Location']=df['Location'].str.replace('d�en', 'd\\'en')\n",
    "df['Location']=df['Location'].str.replace('In Los Angeles � Honolulu yacht race', 'Los Angeles')                                          \n",
    "df['Location']=df['Location'].str.replace('Left break at the �Hot Spot� at Sheringa Beach', 'Sheringa Beach')\n",
    "df['Location']=df['Location'].str.replace('Barber�s', 'Barber\\'s')\n",
    "df['Location']=df['Location'].str.replace('Vall�e', 'Valle')                                          \n",
    "df['Location']=df['Location'].str.replace('O�ahu', 'O\\'ahu')\n",
    "df['Location']=df['Location'].str.replace('Balne�rio Cambori�', 'Balneario Camboriu')\n",
    "df['Location']=df['Location'].str.replace('Ilh�us', 'Ilhus')                                          \n",
    "df['Location']=df['Location'].str.replace('Gor�e', 'Goree')                                          \n",
    "df['Location']=df['Location'].str.replace('B�zios', 'Bazios')\n",
    "df['Location']=df['Location'].str.replace('Ka�eleki�I', 'Ka\\'eleki\\'i')                                          \n",
    "df['Location']=df['Location'].str.replace('Kidd�s', 'Kidd\\'s')                                          \n",
    "df['Location']=df['Location'].str.replace('Le�n', 'Leon')\n",
    "df['Location']=df['Location'].str.replace('Grey�s', 'Grey\\'s')                                          \n",
    "df['Location']=df['Location'].str.replace(' 8�N, 79�W', '')                                          \n",
    "df['Location']=df['Location'].str.replace('Bohusl�n', 'Bohuslan')\n",
    "df['Location']=df['Location'].str.replace('Bakurk�y', 'Bakurk\\'y')                                          \n",
    "df['Location']=df['Location'].str.replace('�tang', 'tang')                                          \n",
    "df['Location']=df['Location'].str.replace('Simon�s', 'Simon\\'s') \n",
    "df['Location']=df['Location'].str.replace('Yand�', 'Yand')   \n",
    "df['Location']=df['Location'].str.replace('Martin�s', 'Martin\\'s')                                          \n",
    "df['Location']=df['Location'].str.replace('Fuller�s', 'Fuller\\'s')                                          \n",
    "df['Location']=df['Location'].str.replace('College�s', 'College\\'s')                                          \n",
    "df['Location']=df['Location'].str.replace('cimeti�re', 'cimetire')                                          \n",
    "df['Location']=df['Location'].str.replace('K�rkira', 'K\\'rkira')                                          \n",
    "df['Location']=df['Location'].str.replace('la�Marine', 'la Marine')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fixing Activity names\n",
    "df['Activity']=df['Activity'].str.replace('38�', '38')\n",
    "df['Activity']=df['Activity'].str.replace('Agust�n', 'Aguston')\n",
    "df['Activity']=df['Activity'].str.replace('netter�s', 'netter\\'s')\n",
    "df['Activity']=df['Activity'].str.replace('Ide�s', 'Ide\\'s')\n",
    "df['Activity']=df['Activity'].str.replace('shark�s', 'shark\\'s')\n",
    "df['Activity']=df['Activity'].str.replace('restaurant�s', 'restaurant\\'s')\n",
    "df['Activity']=df['Activity'].str.replace('Onda�s', 'Onda\\'s')\n",
    "df['Activity']=df['Activity'].str.replace('p�cheur', 'p\\'cheur')\n",
    "df['Activity']=df['Activity'].str.replace('�shark-back riding�', 'shark-back riding')\n",
    "df['Activity']=df['Activity'].str.replace('�swallowed�', 'swallowed')\n",
    "df['Activity']=df['Activity'].str.replace('didn�t', 'didn\\'t')\n",
    "df['Activity']=df['Activity'].str.replace('5�', '5\"')\n",
    "df['Activity']=df['Activity'].str.replace(' � ', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Fixing \"sex\" column with only 3 options\n",
    "df['Sex']=df['Sex'].str.replace('.', 'Not Specified')\n",
    "df['Sex']=df['Sex'].str.replace('lli', 'Not Specified')\n",
    "df['Sex']=df['Sex'].str.replace('M ', 'M')\n",
    "#df['Sex']=df['Sex'].str.replace('N', 'null')\n",
    "#df['Sex']=df['Sex'].str.replace('NULLOT SPECIFIED', 'Not Specified')\n",
    "df.loc[4938,'Sex']='NOT SPECIFIED'\n",
    "df.loc[6131,'Sex']='NOT SPECIFIED'\n",
    "df[\"Sex\"]= df[\"Sex\"].str.upper().str.title() \n",
    "\n",
    "#df['Sex']=df['Sex'].str.replace('null', 'Not Specified')\n",
    "#df['Sex']=df['Sex'].str.replace('Not Specifiedot specified', 'Not Specified')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "#changing the name of the column to reflect a time frame and not age\n",
    "#df.rename(columns={'Age': 'Time Frame'}, inplace=True) \n",
    "#df.rename(columns={'Time': 'Duplicated TF'}, inplace=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fixing not related time frame comments\n",
    "df['Age']=df['Age'].str.replace('� ', 'Unknown')\n",
    "df['Age']=df['Age'].str.replace('FATAL  (Wire netting installed at local beaches after this incident.)', 'Unknown')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fixing injury unnecessary terms and other misspells \n",
    "#df['Injury']=df['Injury'].str.replace('FATAL,', '')\n",
    "#df['Injury']=df['Injury'].str.replace('FATAL', '')\n",
    "df['Injury']=df['Injury'].str.replace(' PROVOKED INCIDENT', '')\n",
    "df['Injury']=df['Injury'].str.replace('PROVOKED ACCIDENT', '')\n",
    "df['Injury']=df['Injury'].str.replace('Barber�s', 'Barber\\'s')\n",
    "df['Injury']=df['Injury'].str.replace('�forequarter amputation�', 'forequarter amputation')\n",
    "df['Injury']=df['Injury'].str.replace('�shoal', 'shoal')\n",
    "df['Injury']=df['Injury'].str.replace('PROVOKED INCIDENT        ', '')\n",
    "df['Injury']=df['Injury'].str.replace('Uhlbrecht�s', 'Uhlbrecht\\'s')\n",
    "df['Injury']=df['Injury'].str.replace('�Put hand through hatch, shark nearly bit off thumb�', 'Put hand through hatch, shark nearly bit off thumb')\n",
    "df['Injury']=df['Injury'].str.replace('�huge shark�', 'huge shark')\n",
    "df['Injury']=df['Injury'].str.replace('Baker�s', 'Baker\\'s')\n",
    "df['Injury']=df['Injury'].str.replace('boat�s', 'boat\\'s')\n",
    "df['Injury']=df['Injury'].str.replace('�deep hole�', 'deep hole')\n",
    "df['Injury']=df['Injury'].str.replace('�presumed taken by a shark�', 'presumed taken by a shark')\n",
    "df['Injury']=df['Injury'].str.replace('Lev�que', 'Levque')\n",
    "df['Injury']=df['Injury'].str.replace('tubar�o', 'tubaro')\n",
    "df['Injury']=df['Injury'].str.replace('Shark�s', 'Shark\\'s')\n",
    "df['Injury']=df['Injury'].str.replace('PROVOKED INCIDENT', '')\n",
    "df['Injury']=df['Injury'].str.replace('man�s', 'man\\'s')\n",
    "df['Injury']=df['Injury'].str.replace('�gummy�', 'gummy')\n",
    "df['Injury']=df['Injury'].str.replace('Sharks�s', 'Shark\\'s')\n",
    "df['Injury']=df['Injury'].str.replace('Jeppsen�s', 'Jeppsen\\'s')\n",
    "df['Injury']=df['Injury'].str.replace('diver�s', 'diver\\'s')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fixing Fatal options to only 2\n",
    "df[\"Fatal (Y/N)\"]=df[\"Fatal (Y/N)\"].str.upper()\n",
    "df['Fatal (Y/N)']=df['Fatal (Y/N)'].str.replace('M', 'N')\n",
    "df['Fatal (Y/N)']=df['Fatal (Y/N)'].str.replace('2017', 'N')\n",
    "df['Fatal (Y/N)']=df['Fatal (Y/N)'].str.replace('UNKNOWN', 'N')\n",
    "df['Fatal (Y/N)']=df['Fatal (Y/N)'].str.replace('UNKNOW', 'N')\n",
    "df[\"Fatal (Y/N)\"]=df[\"Fatal (Y/N)\"].str.upper()\n",
    "df['Fatal (Y/N)']=df['Fatal (Y/N)'].str.replace('N ', 'N')\n",
    "df['Fatal (Y/N)']=df['Fatal (Y/N)'].str.replace(' N', 'N')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'def clean_species(entry):\\n    if isinstance(entry, float) or (len(entry.split(\" \")) == 1):\\n        return \"Not identified\"\\n    else:\\n        species = entry.split(\\' \\')\\n        s = \" \".join([species[i] for i in range(len(species)-1) if species[i+1] == \\'shark\\' or species[i+1] == \\'shark,\\'])\\n        if len(s) < 3:\\n            return \"Not identified\"\\n        else:\\n            return s'"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#function to clean species v1.0\n",
    "'''def clean_species(entry):\n",
    "    if isinstance(entry, float) or (len(entry.split(\" \")) == 1):\n",
    "        return \"Not identified\"\n",
    "    else:\n",
    "        species = entry.split(' ')\n",
    "        s = \" \".join([species[i] for i in range(len(species)-1) if species[i+1] == 'shark' or species[i+1] == 'shark,'])\n",
    "        if len(s) < 3:\n",
    "            return \"Not identified\"\n",
    "        else:\n",
    "            return s'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clenaing function\n",
    "def clean_species(entry):\n",
    "    if isinstance(entry, float) or (len(entry.split(\" \")) == 1):\n",
    "        return \"Not identified\"\n",
    "    else:\n",
    "        species = entry.split(' ')\n",
    "        s = \" \".join([species[i] for i in range(len(species)-1) if species[i+1] == 'shark' or species[i+1] == 'shark,'])\n",
    "        if len(s) < 3:\n",
    "            return \"Not identified\"\n",
    "        elif ord(s[0].lower()) not in range(ord('a'), ord('z')):\n",
    "            return \"Not identified\"\n",
    "        else:\n",
    "            return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cleaning species column\n",
    "df['Species']=df['Species'].apply(clean_species)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fixing name syntax\n",
    "df[\"Name\"]= df[\"Name\"].str.upper().str.title() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fixing column name\n",
    "df.rename(columns={'Case Number.2': 'Case Month'}, inplace=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/dateutil/parser/_parser.py:1218: UnknownTimezoneWarning: tzname D identified but not understood.  Pass `tzinfos` argument in order to correctly return a timezone-aware datetime.  In a future version, this will raise an exception.\n",
      "  category=UnknownTimezoneWarning)\n"
     ]
    }
   ],
   "source": [
    "#fixing case month to show the month of the incidents\n",
    "df['Case Month'] = pd.to_datetime(df.Date, errors='coerce')\n",
    "df['Case Month'] = pd.DatetimeIndex(df['Case Month']).month\n",
    "df['Case Month']=df['Case Month'].replace('NaN', 'Unknown')\n",
    "df[['Case Month']]= df[['Case Month']].fillna('Unknown')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Time']=df['Time'].str.replace('h', ':')\n",
    "#df['Time'] = df['Time'].astype(int)\n",
    "df['Time']=df['Time'].replace(to_replace ='\\D', value = '', regex = True) \n",
    "df[['Time']]= df[['Time']].fillna('Unknown')\n",
    "#df['Time']=df['Time'][df['Time'].str.len() <5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list(df['Case Number.1'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.filter([\"href formula\", \"Yona, repetida\"]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={'href': 'Yona, repetida'}, inplace=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
